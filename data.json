{
"title": "torch.nn",
"heading": "These are the basic building blocks for graphs:",
"documents": [
{
  "title": "Buffer",
  "page_text": "Buffer\n¶\nclass\ntorch.nn.parameter.\nBuffer\n(\ndata\n=\nNone\n,\n*\n,\npersistent\n=\nTrue\n)\n[source]\n[source]\n¶\nA kind of Tensor that should not be considered a model\nparameter. For example, BatchNorm’s\nrunning_mean\nis not a parameter, but is part of the module’s state.\nBuffers are\nTensor\nsubclasses, that have a\nvery special property when used with\nModule\ns – when they’re\nassigned as Module attributes they are automatically added to the list of\nits buffers, and will appear e.g. in\nbuffers()\niterator.\nAssigning a Tensor doesn’t have such effect. One can still assign a Tensor as explicitly by using\nthe\nregister_buffer()\nfunction.\nParameters\ndata\n(\nTensor\n) – buffer tensor.\npersistent\n(\nbool\n,\noptional\n) – whether the buffer is part of the module’s\nstate_dict\n. Default:\nTrue\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Buffer.html#buffer",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parameter.html#Buffer",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parameter.py#L225",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Buffer.html#torch.nn.parameter.Buffer",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.buffers",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html",
    "https://pytorch.org/docs/stable/nn.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "Parameter",
  "page_text": "Parameter\n¶\nclass\ntorch.nn.parameter.\nParameter\n(\ndata\n=\nNone\n,\nrequires_grad\n=\nTrue\n)\n[source]\n[source]\n¶\nA kind of Tensor that is to be considered a module parameter.\nParameters are\nTensor\nsubclasses, that have a\nvery special property when used with\nModule\ns - when they’re\nassigned as Module attributes they are automatically added to the list of\nits parameters, and will appear e.g. in\nparameters()\niterator.\nAssigning a Tensor doesn’t have such effect. This is because one might\nwant to cache some temporary state, like last hidden state of the RNN, in\nthe model. If there was no such class as\nParameter\n, these\ntemporaries would get registered too.\nParameters\ndata\n(\nTensor\n) – parameter tensor.\nrequires_grad\n(\nbool\n,\noptional\n) – if the parameter requires gradient. Note that\nthe torch.no_grad() context does NOT affect the default behavior of\nParameter creation–the Parameter will still have\nrequires_grad=True\nin\nno_grad\nmode. See\nLocally disabling gradient computation\nfor more\ndetails. Default:\nTrue\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parameter.html#Parameter",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parameter.py#L19",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedParameter.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Buffer.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "UninitializedParameter",
  "page_text": "UninitializedParameter\n¶\nclass\ntorch.nn.parameter.\nUninitializedParameter\n(\nrequires_grad\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA parameter that is not initialized.\nUninitialized Parameters are a special case of\ntorch.nn.Parameter\nwhere the shape of the data is still unknown.\nUnlike a\ntorch.nn.Parameter\n, uninitialized parameters\nhold no data and attempting to access some properties, like their shape,\nwill throw a runtime error. The only operations that can be performed on a uninitialized\nparameter are changing its datatype, moving it to a different device and\nconverting it to a regular\ntorch.nn.Parameter\n.\nThe default device or dtype to use when the parameter is materialized can be set\nduring construction using e.g.\ndevice='cuda'\n.\ncls_to_become\n[source]\n¶\nalias of\nParameter\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedParameter.html#uninitializedparameter",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parameter.html#UninitializedParameter",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parameter.py#L181",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parameter.py#L19",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedBuffer.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "UninitializedBuffer",
  "page_text": "UninitializedBuffer\n¶\nclass\ntorch.nn.parameter.\nUninitializedBuffer\n(\nrequires_grad\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n,\npersistent\n=\nTrue\n)\n[source]\n[source]\n¶\nA buffer that is not initialized.\nUninitialized Buffer is a a special case of\ntorch.Tensor\nwhere the shape of the data is still unknown.\nUnlike a\ntorch.Tensor\n, uninitialized parameters\nhold no data and attempting to access some properties, like their shape,\nwill throw a runtime error. The only operations that can be performed on a uninitialized\nparameter are changing its datatype, moving it to a different device and\nconverting it to a regular\ntorch.Tensor\n.\nThe default device or dtype to use when the buffer is materialized can be set\nduring construction using e.g.\ndevice='cuda'\n.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedBuffer.html#uninitializedbuffer",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parameter.html#UninitializedBuffer",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parameter.py#L254",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedBuffer.html#torch.nn.parameter.UninitializedBuffer",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedParameter.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "Module",
  "page_text": "Module\n¶\nclass\ntorch.nn.\nModule\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing them to be nested in\na tree structure. You can assign the submodules as regular attributes:\nimport\ntorch.nn\nas\nnn\nimport\ntorch.nn.functional\nas\nF\nclass\nModel\n(\nnn\n.\nModule\n):\ndef\n__init__\n(\nself\n)\n->\nNone\n:\nsuper\n()\n.\n__init__\n()\nself\n.\nconv1\n=\nnn\n.\nConv2d\n(\n1\n,\n20\n,\n5\n)\nself\n.\nconv2\n=\nnn\n.\nConv2d\n(\n20\n,\n20\n,\n5\n)\ndef\nforward\n(\nself\n,\nx\n):\nx\n=\nF\n.\nrelu\n(\nself\n.\nconv1\n(\nx\n))\nreturn\nF\n.\nrelu\n(\nself\n.\nconv2\n(\nx\n))\nSubmodules assigned in this way will be registered, and will also have their\nparameters converted when you call\nto()\n, etc.\nNote\nAs per the example above, an\n__init__()\ncall to the parent class\nmust be made before assignment on the child.\nVariables\ntraining\n(\nbool\n) – Boolean represents whether this module is in training or\nevaluation mode.\nadd_module\n(\nname\n,\nmodule\n)\n[source]\n[source]\n¶\nAdd a child module to the current module.\nThe module can be accessed as an attribute using the given name.\nParameters\nname\n(\nstr\n) – name of the child module. The child module can be\naccessed from this module using the given name\nmodule\n(\nModule\n) – child module to be added to the module.\napply\n(\nfn\n)\n[source]\n[source]\n¶\nApply\nfn\nrecursively to every submodule (as returned by\n.children()\n) as well as self.\nTypical use includes initializing the parameters of a model\n(see also\ntorch.nn.init\n).\nParameters\nfn\n(\nModule\n-> None) – function to be applied to each submodule\nReturns\nself\nReturn type\nModule\nExample:\n>>>\n@torch\n.\nno_grad\n()\n>>>\ndef\ninit_weights\n(\nm\n):\n>>>\nprint\n(\nm\n)\n>>>\nif\ntype\n(\nm\n)\n==\nnn\n.\nLinear\n:\n>>>\nm\n.\nweight\n.\nfill_\n(\n1.0\n)\n>>>\nprint\n(\nm\n.\nweight\n)\n>>>\nnet\n=\nnn\n.\nSequential\n(\nnn\n.\nLinear\n(\n2\n,\n2\n),\nnn\n.\nLinear\n(\n2\n,\n2\n))\n>>>\nnet\n.\napply\n(\ninit_weights\n)\nLinear(in_features=2, out_features=2, bias=True)\nParameter containing:\ntensor([[1., 1.],\n[1., 1.]], requires_grad=True)\nLinear(in_features=2, out_features=2, bias=True)\nParameter containing:\ntensor([[1., 1.],\n[1., 1.]], requires_grad=True)\nSequential(\n(0): Linear(in_features=2, out_features=2, bias=True)\n(1): Linear(in_features=2, out_features=2, bias=True)\n)\nbfloat16\n(\n)\n[source]\n[source]\n¶\nCasts all floating point parameters and buffers to\nbfloat16\ndatatype.\nNote\nThis method modifies the module in-place.\nReturns\nself\nReturn type\nModule\nbuffers\n(\nrecurse\n=\nTrue\n)\n[source]\n[source]\n¶\nReturn an iterator over module buffers.\nParameters\nrecurse\n(\nbool\n) – if True, then yields buffers of this module\nand all submodules. Otherwise, yields only buffers that\nare direct members of this module.\nYields\ntorch.Tensor\n– module buffer\nReturn type\nIterator\n[\nTensor\n]\nExample:\n>>>\nfor\nbuf\nin\nmodel\n.\nbuffers\n():\n>>>\nprint\n(\ntype\n(\nbuf\n),\nbuf\n.\nsize\n())\n<class 'torch.Tensor'> (20L,)\n<class 'torch.Tensor'> (20L, 1L, 5L, 5L)\nchildren\n(\n)\n[source]\n[source]\n¶\nReturn an iterator over immediate children modules.\nYields\nModule\n– a child module\nReturn type\nIterator\n[\nModule\n]\ncompile\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nCompile this Module’s forward using\ntorch.compile()\n.\nThis Module’s\n__call__\nmethod is compiled and all arguments are passed as-is\nto\ntorch.compile()\n.\nSee\ntorch.compile()\nfor details on the arguments for this function.\ncpu\n(\n)\n[source]\n[source]\n¶\nMove all model parameters and buffers to the CPU.\nNote\nThis method modifies the module in-place.\nReturns\nself\nReturn type\nModule\ncuda\n(\ndevice\n=\nNone\n)\n[source]\n[source]\n¶\nMove all model parameters and buffers to the GPU.\nThis also makes associated parameters and buffers different objects. So\nit should be called before constructing the optimizer if the module will\nlive on GPU while being optimized.\nNote\nThis method modifies the module in-place.\nParameters\ndevice\n(\nint\n,\noptional\n) – if specified, all parameters will be\ncopied to that device\nReturns\nself\nReturn type\nModule\ndouble\n(\n)\n[source]\n[source]\n¶\nCasts all floating point parameters and buffers to\ndouble\ndatatype.\nNote\nThis method modifies the module in-place.\nReturns\nself\nReturn type\nModule\neval\n(\n)\n[source]\n[source]\n¶\nSet the module in evaluation mode.\nThis has an effect only on certain modules. See the documentation of\nparticular modules for details of their behaviors in training/evaluation\nmode, i.e. whether they are affected, e.g.\nDropout\n,\nBatchNorm\n,\netc.\nThis is equivalent with\nself.train(False)\n.\nSee\nLocally disabling gradient computation\nfor a comparison between\n.eval()\nand several similar mechanisms that may be confused with it.\nReturns\nself\nReturn type\nModule\nextra_repr\n(\n)\n[source]\n[source]\n¶\nReturn the extra representation of the module.\nTo print customized extra information, you should re-implement\nthis method in your own modules. Both single-line and multi-line\nstrings are acceptable.\nReturn type\nstr\nfloat\n(\n)\n[source]\n[source]\n¶\nCasts all floating point parameters and buffers to\nfloat\ndatatype.\nNote\nThis method modifies the module in-place.\nReturns\nself\nReturn type\nModule\nforward\n(\n*\ninput\n)\n[source]\n¶\nDefine the computation performed at every call.\nShould be overridden by all subclasses.\nNote\nAlthough the recipe for forward pass needs to be defined within\nthis function, one should call the\nModule\ninstance afterwards\ninstead of this since the former takes care of running the\nregistered hooks while the latter silently ignores them.\nget_buffer\n(\ntarget\n)\n[source]\n[source]\n¶\nReturn the buffer given by\ntarget\nif it exists, otherwise throw an error.\nSee the docstring for\nget_submodule\nfor a more detailed\nexplanation of this method’s functionality as well as how to\ncorrectly specify\ntarget\n.\nParameters\ntarget\n(\nstr\n) – The fully-qualified string name of the buffer\nto look for. (See\nget_submodule\nfor how to specify a\nfully-qualified string.)\nReturns\nThe buffer referenced by\ntarget\nReturn type\ntorch.Tensor\nRaises\nAttributeError\n– If the target string references an invalid\n    path or resolves to something that is not a\n    buffer\nget_extra_state\n(\n)\n[source]\n[source]\n¶\nReturn any extra state to include in the module’s state_dict.\nImplement this and a corresponding\nset_extra_state()\nfor your module\nif you need to store extra state. This function is called when building the\nmodule’s\nstate_dict()\n.\nNote that extra state should be picklable to ensure working serialization\nof the state_dict. We only provide backwards compatibility guarantees\nfor serializing Tensors; other objects may break backwards compatibility if\ntheir serialized pickled form changes.\nReturns\nAny extra state to store in the module’s state_dict\nReturn type\nobject\nget_parameter\n(\ntarget\n)\n[source]\n[source]\n¶\nReturn the parameter given by\ntarget\nif it exists, otherwise throw an error.\nSee the docstring for\nget_submodule\nfor a more detailed\nexplanation of this method’s functionality as well as how to\ncorrectly specify\ntarget\n.\nParameters\ntarget\n(\nstr\n) – The fully-qualified string name of the Parameter\nto look for. (See\nget_submodule\nfor how to specify a\nfully-qualified string.)\nReturns\nThe Parameter referenced by\ntarget\nReturn type\ntorch.nn.Parameter\nRaises\nAttributeError\n– If the target string references an invalid\n    path or resolves to something that is not an\nnn.Parameter\nget_submodule\n(\ntarget\n)\n[source]\n[source]\n¶\nReturn the submodule given by\ntarget\nif it exists, otherwise throw an error.\nFor example, let’s say you have an\nnn.Module\nA\nthat\nlooks like this:\nA(\n    (net_b): Module(\n        (net_c): Module(\n            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n        )\n        (linear): Linear(in_features=100, out_features=200, bias=True)\n    )\n)\n(The diagram shows an\nnn.Module\nA\n.\nA\nwhich has a nested\nsubmodule\nnet_b\n, which itself has two submodules\nnet_c\nand\nlinear\n.\nnet_c\nthen has a submodule\nconv\n.)\nTo check whether or not we have the\nlinear\nsubmodule, we\nwould call\nget_submodule(\"net_b.linear\")\n. To check whether\nwe have the\nconv\nsubmodule, we would call\nget_submodule(\"net_b.net_c.conv\")\n.\nThe runtime of\nget_submodule\nis bounded by the degree\nof module nesting in\ntarget\n. A query against\nnamed_modules\nachieves the same result, but it is O(N) in\nthe number of transitive modules. So, for a simple check to see\nif some submodule exists,\nget_submodule\nshould always be\nused.\nParameters\ntarget\n(\nstr\n) – The fully-qualified string name of the submodule\nto look for. (See above example for how to specify a\nfully-qualified string.)\nReturns\nThe submodule referenced by\ntarget\nReturn type\ntorch.nn.Module\nRaises\nAttributeError\n– If the target string references an invalid\n    path or resolves to something that is not an\nnn.Module\nhalf\n(\n)\n[source]\n[source]\n¶\nCasts all floating point parameters and buffers to\nhalf\ndatatype.\nNote\nThis method modifies the module in-place.\nReturns\nself\nReturn type\nModule\nipu\n(\ndevice\n=\nNone\n)\n[source]\n[source]\n¶\nMove all model parameters and buffers to the IPU.\nThis also makes associated parameters and buffers different objects. So\nit should be called before constructing the optimizer if the module will\nlive on IPU while being optimized.\nNote\nThis method modifies the module in-place.\nParameters\ndevice\n(\nint\n,\noptional\n) – if specified, all parameters will be\ncopied to that device\nReturns\nself\nReturn type\nModule\nload_state_dict\n(\nstate_dict\n,\nstrict\n=\nTrue\n,\nassign\n=\nFalse\n)\n[source]\n[source]\n¶\nCopy parameters and buffers from\nstate_dict\ninto this module and its descendants.\nIf\nstrict\nis\nTrue\n, then\nthe keys of\nstate_dict\nmust exactly match the keys returned\nby this module’s\nstate_dict()\nfunction.\nWarning\nIf\nassign\nis\nTrue\nthe optimizer must be created after\nthe call to\nload_state_dict\nunless\nget_swap_module_params_on_conversion()\nis\nTrue\n.\nParameters\nstate_dict\n(\ndict\n) – a dict containing parameters and\npersistent buffers.\nstrict\n(\nbool\n,\noptional\n) – whether to strictly enforce that the keys\nin\nstate_dict\nmatch the keys returned by this module’s\nstate_dict()\nfunction. Default:\nTrue\nassign\n(\nbool\n,\noptional\n) – When set to\nFalse\n, the properties of the tensors\nin the current module are preserved whereas setting it to\nTrue\npreserves\nproperties of the Tensors in the state dict. The only\nexception is the\nrequires_grad\nfield of\nDefault:\n``False`\nReturns\nmissing_keys\nis a list of str containing any keys that are expected\nby this module but missing from the provided\nstate_dict\n.\nunexpected_keys\nis a list of str containing the keys that are not\nexpected by this module but present in the provided\nstate_dict\n.\nReturn type\nNamedTuple\nwith\nmissing_keys\nand\nunexpected_keys\nfields\nNote\nIf a parameter or buffer is registered as\nNone\nand its corresponding key\nexists in\nstate_dict\n,\nload_state_dict()\nwill raise a\nRuntimeError\n.\nmodules\n(\n)\n[source]\n[source]\n¶\nReturn an iterator over all modules in the network.\nYields\nModule\n– a module in the network\nReturn type\nIterator\n[\nModule\n]\nNote\nDuplicate modules are returned only once. In the following\nexample,\nl\nwill be returned only once.\nExample:\n>>>\nl\n=\nnn\n.\nLinear\n(\n2\n,\n2\n)\n>>>\nnet\n=\nnn\n.\nSequential\n(\nl\n,\nl\n)\n>>>\nfor\nidx\n,\nm\nin\nenumerate\n(\nnet\n.\nmodules\n()):\n...\nprint\n(\nidx\n,\n'->'\n,\nm\n)\n0 -> Sequential(\n(0): Linear(in_features=2, out_features=2, bias=True)\n(1): Linear(in_features=2, out_features=2, bias=True)\n)\n1 -> Linear(in_features=2, out_features=2, bias=True)\nmtia\n(\ndevice\n=\nNone\n)\n[source]\n[source]\n¶\nMove all model parameters and buffers to the MTIA.\nThis also makes associated parameters and buffers different objects. So\nit should be called before constructing the optimizer if the module will\nlive on MTIA while being optimized.\nNote\nThis method modifies the module in-place.\nParameters\ndevice\n(\nint\n,\noptional\n) – if specified, all parameters will be\ncopied to that device\nReturns\nself\nReturn type\nModule\nnamed_buffers\n(\nprefix\n=\n''\n,\nrecurse\n=\nTrue\n,\nremove_duplicate\n=\nTrue\n)\n[source]\n[source]\n¶\nReturn an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.\nParameters\nprefix\n(\nstr\n) – prefix to prepend to all buffer names.\nrecurse\n(\nbool\n,\noptional\n) – if True, then yields buffers of this module\nand all submodules. Otherwise, yields only buffers that\nare direct members of this module. Defaults to True.\nremove_duplicate\n(\nbool\n,\noptional\n) – whether to remove the duplicated buffers in the result. Defaults to True.\nYields\n(str, torch.Tensor)\n– Tuple containing the name and buffer\nReturn type\nIterator\n[\nTuple\n[\nstr\n,\nTensor\n]]\nExample:\n>>>\nfor\nname\n,\nbuf\nin\nself\n.\nnamed_buffers\n():\n>>>\nif\nname\nin\n[\n'running_var'\n]:\n>>>\nprint\n(\nbuf\n.\nsize\n())\nnamed_children\n(\n)\n[source]\n[source]\n¶\nReturn an iterator over immediate children modules, yielding both the name of the module as well as the module itself.\nYields\n(str, Module)\n– Tuple containing a name and child module\nReturn type\nIterator\n[\nTuple\n[\nstr\n,\nModule\n]]\nExample:\n>>>\nfor\nname\n,\nmodule\nin\nmodel\n.\nnamed_children\n():\n>>>\nif\nname\nin\n[\n'conv4'\n,\n'conv5'\n]:\n>>>\nprint\n(\nmodule\n)\nnamed_modules\n(\nmemo\n=\nNone\n,\nprefix\n=\n''\n,\nremove_duplicate\n=\nTrue\n)\n[source]\n[source]\n¶\nReturn an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\nParameters\nmemo\n(\nOptional\n[\nSet\n[\nModule\n]\n]\n) – a memo to store the set of modules already added to the result\nprefix\n(\nstr\n) – a prefix that will be added to the name of the module\nremove_duplicate\n(\nbool\n) – whether to remove the duplicated module instances in the result\nor not\nYields\n(str, Module)\n– Tuple of name and module\nNote\nDuplicate modules are returned only once. In the following\nexample,\nl\nwill be returned only once.\nExample:\n>>>\nl\n=\nnn\n.\nLinear\n(\n2\n,\n2\n)\n>>>\nnet\n=\nnn\n.\nSequential\n(\nl\n,\nl\n)\n>>>\nfor\nidx\n,\nm\nin\nenumerate\n(\nnet\n.\nnamed_modules\n()):\n...\nprint\n(\nidx\n,\n'->'\n,\nm\n)\n0 -> ('', Sequential(\n(0): Linear(in_features=2, out_features=2, bias=True)\n(1): Linear(in_features=2, out_features=2, bias=True)\n))\n1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\nnamed_parameters\n(\nprefix\n=\n''\n,\nrecurse\n=\nTrue\n,\nremove_duplicate\n=\nTrue\n)\n[source]\n[source]\n¶\nReturn an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\nParameters\nprefix\n(\nstr\n) – prefix to prepend to all parameter names.\nrecurse\n(\nbool\n) – if True, then yields parameters of this module\nand all submodules. Otherwise, yields only parameters that\nare direct members of this module.\nremove_duplicate\n(\nbool\n,\noptional\n) – whether to remove the duplicated\nparameters in the result. Defaults to True.\nYields\n(str, Parameter)\n– Tuple containing the name and parameter\nReturn type\nIterator\n[\nTuple\n[\nstr\n,\nParameter\n]]\nExample:\n>>>\nfor\nname\n,\nparam\nin\nself\n.\nnamed_parameters\n():\n>>>\nif\nname\nin\n[\n'bias'\n]:\n>>>\nprint\n(\nparam\n.\nsize\n())\nparameters\n(\nrecurse\n=\nTrue\n)\n[source]\n[source]\n¶\nReturn an iterator over module parameters.\nThis is typically passed to an optimizer.\nParameters\nrecurse\n(\nbool\n) – if True, then yields parameters of this module\nand all submodules. Otherwise, yields only parameters that\nare direct members of this module.\nYields\nParameter\n– module parameter\nReturn type\nIterator\n[\nParameter\n]\nExample:\n>>>\nfor\nparam\nin\nmodel\n.\nparameters\n():\n>>>\nprint\n(\ntype\n(\nparam\n),\nparam\n.\nsize\n())\n<class 'torch.Tensor'> (20L,)\n<class 'torch.Tensor'> (20L, 1L, 5L, 5L)\nregister_backward_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a backward hook on the module.\nThis function is deprecated in favor of\nregister_full_backward_hook()\nand\nthe behavior of this function will change in future versions.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nregister_buffer\n(\nname\n,\ntensor\n,\npersistent\n=\nTrue\n)\n[source]\n[source]\n¶\nAdd a buffer to the module.\nThis is typically used to register a buffer that should not to be\nconsidered a model parameter. For example, BatchNorm’s\nrunning_mean\nis not a parameter, but is part of the module’s state. Buffers, by\ndefault, are persistent and will be saved alongside parameters. This\nbehavior can be changed by setting\npersistent\nto\nFalse\n. The\nonly difference between a persistent buffer and a non-persistent buffer\nis that the latter will not be a part of this module’s\nstate_dict\n.\nBuffers can be accessed as attributes using given names.\nParameters\nname\n(\nstr\n) – name of the buffer. The buffer can be accessed\nfrom this module using the given name\ntensor\n(\nTensor\nor\nNone\n) – buffer to be registered. If\nNone\n, then operations\nthat run on buffers, such as\ncuda\n, are ignored. If\nNone\n,\nthe buffer is\nnot\nincluded in the module’s\nstate_dict\n.\npersistent\n(\nbool\n) – whether the buffer is part of this module’s\nstate_dict\n.\nExample:\n>>>\nself\n.\nregister_buffer\n(\n'running_mean'\n,\ntorch\n.\nzeros\n(\nnum_features\n))\nregister_forward_hook\n(\nhook\n,\n*\n,\nprepend\n=\nFalse\n,\nwith_kwargs\n=\nFalse\n,\nalways_call\n=\nFalse\n)\n[source]\n[source]\n¶\nRegister a forward hook on the module.\nThe hook will be called every time after\nforward()\nhas computed an output.\nIf\nwith_kwargs\nis\nFalse\nor not specified, the input contains only\nthe positional arguments given to the module. Keyword arguments won’t be\npassed to the hooks and only to the\nforward\n. The hook can modify the\noutput. It can modify the input inplace but it will not have effect on\nforward since this is called after\nforward()\nis called. The hook\nshould have the following signature:\nhook\n(\nmodule\n,\nargs\n,\noutput\n)\n->\nNone\nor\nmodified\noutput\nIf\nwith_kwargs\nis\nTrue\n, the forward hook will be passed the\nkwargs\ngiven to the forward function and be expected to return the\noutput possibly modified. The hook should have the following signature:\nhook\n(\nmodule\n,\nargs\n,\nkwargs\n,\noutput\n)\n->\nNone\nor\nmodified\noutput\nParameters\nhook\n(\nCallable\n) – The user defined hook to be registered.\nprepend\n(\nbool\n) – If\nTrue\n, the provided\nhook\nwill be fired\nbefore all existing\nforward\nhooks on this\ntorch.nn.modules.Module\n. Otherwise, the provided\nhook\nwill be fired after all existing\nforward\nhooks on\nthis\ntorch.nn.modules.Module\n. Note that global\nforward\nhooks registered with\nregister_module_forward_hook()\nwill fire before all hooks\nregistered by this method.\nDefault:\nFalse\nwith_kwargs\n(\nbool\n) – If\nTrue\n, the\nhook\nwill be passed the\nkwargs given to the forward function.\nDefault:\nFalse\nalways_call\n(\nbool\n) – If\nTrue\nthe\nhook\nwill be run regardless of\nwhether an exception is raised while calling the Module.\nDefault:\nFalse\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nregister_forward_pre_hook\n(\nhook\n,\n*\n,\nprepend\n=\nFalse\n,\nwith_kwargs\n=\nFalse\n)\n[source]\n[source]\n¶\nRegister a forward pre-hook on the module.\nThe hook will be called every time before\nforward()\nis invoked.\nIf\nwith_kwargs\nis false or not specified, the input contains only\nthe positional arguments given to the module. Keyword arguments won’t be\npassed to the hooks and only to the\nforward\n. The hook can modify the\ninput. User can either return a tuple or a single modified value in the\nhook. We will wrap the value into a tuple if a single value is returned\n(unless that value is already a tuple). The hook should have the\nfollowing signature:\nhook\n(\nmodule\n,\nargs\n)\n->\nNone\nor\nmodified\ninput\nIf\nwith_kwargs\nis true, the forward pre-hook will be passed the\nkwargs given to the forward function. And if the hook modifies the\ninput, both the args and kwargs should be returned. The hook should have\nthe following signature:\nhook\n(\nmodule\n,\nargs\n,\nkwargs\n)\n->\nNone\nor\na\ntuple\nof\nmodified\ninput\nand\nkwargs\nParameters\nhook\n(\nCallable\n) – The user defined hook to be registered.\nprepend\n(\nbool\n) – If true, the provided\nhook\nwill be fired before\nall existing\nforward_pre\nhooks on this\ntorch.nn.modules.Module\n. Otherwise, the provided\nhook\nwill be fired after all existing\nforward_pre\nhooks\non this\ntorch.nn.modules.Module\n. Note that global\nforward_pre\nhooks registered with\nregister_module_forward_pre_hook()\nwill fire before all\nhooks registered by this method.\nDefault:\nFalse\nwith_kwargs\n(\nbool\n) – If true, the\nhook\nwill be passed the kwargs\ngiven to the forward function.\nDefault:\nFalse\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nregister_full_backward_hook\n(\nhook\n,\nprepend\n=\nFalse\n)\n[source]\n[source]\n¶\nRegister a backward hook on the module.\nThe hook will be called every time the gradients with respect to a module\nare computed, i.e. the hook will execute if and only if the gradients with\nrespect to module outputs are computed. The hook should have the following\nsignature:\nhook\n(\nmodule\n,\ngrad_input\n,\ngrad_output\n)\n->\ntuple\n(\nTensor\n)\nor\nNone\nThe\ngrad_input\nand\ngrad_output\nare tuples that contain the gradients\nwith respect to the inputs and outputs respectively. The hook should\nnot modify its arguments, but it can optionally return a new gradient with\nrespect to the input that will be used in place of\ngrad_input\nin\nsubsequent computations.\ngrad_input\nwill only correspond to the inputs given\nas positional arguments and all kwarg arguments are ignored. Entries\nin\ngrad_input\nand\ngrad_output\nwill be\nNone\nfor all non-Tensor\narguments.\nFor technical reasons, when this hook is applied to a Module, its forward function will\nreceive a view of each Tensor passed to the Module. Similarly the caller will receive a view\nof each Tensor returned by the Module’s forward function.\nWarning\nModifying inputs or outputs inplace is not allowed when using backward hooks and\nwill raise an error.\nParameters\nhook\n(\nCallable\n) – The user-defined hook to be registered.\nprepend\n(\nbool\n) – If true, the provided\nhook\nwill be fired before\nall existing\nbackward\nhooks on this\ntorch.nn.modules.Module\n. Otherwise, the provided\nhook\nwill be fired after all existing\nbackward\nhooks on\nthis\ntorch.nn.modules.Module\n. Note that global\nbackward\nhooks registered with\nregister_module_full_backward_hook()\nwill fire before\nall hooks registered by this method.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nregister_full_backward_pre_hook\n(\nhook\n,\nprepend\n=\nFalse\n)\n[source]\n[source]\n¶\nRegister a backward pre-hook on the module.\nThe hook will be called every time the gradients for the module are computed.\nThe hook should have the following signature:\nhook\n(\nmodule\n,\ngrad_output\n)\n->\ntuple\n[\nTensor\n]\nor\nNone\nThe\ngrad_output\nis a tuple. The hook should\nnot modify its arguments, but it can optionally return a new gradient with\nrespect to the output that will be used in place of\ngrad_output\nin\nsubsequent computations. Entries in\ngrad_output\nwill be\nNone\nfor\nall non-Tensor arguments.\nFor technical reasons, when this hook is applied to a Module, its forward function will\nreceive a view of each Tensor passed to the Module. Similarly the caller will receive a view\nof each Tensor returned by the Module’s forward function.\nWarning\nModifying inputs inplace is not allowed when using backward hooks and\nwill raise an error.\nParameters\nhook\n(\nCallable\n) – The user-defined hook to be registered.\nprepend\n(\nbool\n) – If true, the provided\nhook\nwill be fired before\nall existing\nbackward_pre\nhooks on this\ntorch.nn.modules.Module\n. Otherwise, the provided\nhook\nwill be fired after all existing\nbackward_pre\nhooks\non this\ntorch.nn.modules.Module\n. Note that global\nbackward_pre\nhooks registered with\nregister_module_full_backward_pre_hook()\nwill fire before\nall hooks registered by this method.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nregister_load_state_dict_post_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a post-hook to be run after module’s\nload_state_dict()\nis called.\nIt should have the following signature::\nhook(module, incompatible_keys) -> None\nThe\nmodule\nargument is the current module that this hook is registered\non, and the\nincompatible_keys\nargument is a\nNamedTuple\nconsisting\nof attributes\nmissing_keys\nand\nunexpected_keys\n.\nmissing_keys\nis a\nlist\nof\nstr\ncontaining the missing keys and\nunexpected_keys\nis a\nlist\nof\nstr\ncontaining the unexpected keys.\nThe given incompatible_keys can be modified inplace if needed.\nNote that the checks performed when calling\nload_state_dict()\nwith\nstrict=True\nare affected by modifications the hook makes to\nmissing_keys\nor\nunexpected_keys\n, as expected. Additions to either\nset of keys will result in an error being thrown when\nstrict=True\n, and\nclearing out both missing and unexpected keys will avoid an error.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nregister_load_state_dict_pre_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a pre-hook to be run before module’s\nload_state_dict()\nis called.\nIt should have the following signature::\nhook(module, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs) -> None  # noqa: B950\nParameters\nhook\n(\nCallable\n) – Callable hook that will be invoked before\nloading the state dict.\nregister_module\n(\nname\n,\nmodule\n)\n[source]\n[source]\n¶\nAlias for\nadd_module()\n.\nregister_parameter\n(\nname\n,\nparam\n)\n[source]\n[source]\n¶\nAdd a parameter to the module.\nThe parameter can be accessed as an attribute using given name.\nParameters\nname\n(\nstr\n) – name of the parameter. The parameter can be accessed\nfrom this module using the given name\nparam\n(\nParameter\nor\nNone\n) – parameter to be added to the module. If\nNone\n, then operations that run on parameters, such as\ncuda\n,\nare ignored. If\nNone\n, the parameter is\nnot\nincluded in the\nmodule’s\nstate_dict\n.\nregister_state_dict_post_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a post-hook for the\nstate_dict()\nmethod.\nIt should have the following signature::\nhook(module, state_dict, prefix, local_metadata) -> None\nThe registered hooks can modify the\nstate_dict\ninplace.\nregister_state_dict_pre_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a pre-hook for the\nstate_dict()\nmethod.\nIt should have the following signature::\nhook(module, prefix, keep_vars) -> None\nThe registered hooks can be used to perform pre-processing before the\nstate_dict\ncall is made.\nrequires_grad_\n(\nrequires_grad\n=\nTrue\n)\n[source]\n[source]\n¶\nChange if autograd should record operations on parameters in this module.\nThis method sets the parameters’\nrequires_grad\nattributes\nin-place.\nThis method is helpful for freezing part of the module for finetuning\nor training parts of a model individually (e.g., GAN training).\nSee\nLocally disabling gradient computation\nfor a comparison between\n.requires_grad_()\nand several similar mechanisms that may be confused with it.\nParameters\nrequires_grad\n(\nbool\n) – whether autograd should record operations on\nparameters in this module. Default:\nTrue\n.\nReturns\nself\nReturn type\nModule\nset_extra_state\n(\nstate\n)\n[source]\n[source]\n¶\nSet extra state contained in the loaded\nstate_dict\n.\nThis function is called from\nload_state_dict()\nto handle any extra state\nfound within the\nstate_dict\n. Implement this function and a corresponding\nget_extra_state()\nfor your module if you need to store extra state within its\nstate_dict\n.\nParameters\nstate\n(\ndict\n) – Extra state from the\nstate_dict\nset_submodule\n(\ntarget\n,\nmodule\n)\n[source]\n[source]\n¶\nSet the submodule given by\ntarget\nif it exists, otherwise throw an error.\nFor example, let’s say you have an\nnn.Module\nA\nthat\nlooks like this:\nA(\n    (net_b): Module(\n        (net_c): Module(\n            (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n        )\n        (linear): Linear(in_features=100, out_features=200, bias=True)\n    )\n)\n(The diagram shows an\nnn.Module\nA\n.\nA\nhas a nested\nsubmodule\nnet_b\n, which itself has two submodules\nnet_c\nand\nlinear\n.\nnet_c\nthen has a submodule\nconv\n.)\nTo overide the\nConv2d\nwith a new submodule\nLinear\n, you\nwould call\nset_submodule(\"net_b.net_c.conv\",\nnn.Linear(33,\n16))\n.\nParameters\ntarget\n(\nstr\n) – The fully-qualified string name of the submodule\nto look for. (See above example for how to specify a\nfully-qualified string.)\nmodule\n(\nModule\n) – The module to set the submodule to.\nRaises\nValueError\n– If the target string is empty\nAttributeError\n– If the target string references an invalid\n    path or resolves to something that is not an\nnn.Module\nshare_memory\n(\n)\n[source]\n[source]\n¶\nSee\ntorch.Tensor.share_memory_()\n.\nReturn type\nT\nstate_dict\n(\n*\n,\ndestination\n:\nT_destination\n,\nprefix\n:\nstr\n=\n''\n,\nkeep_vars\n:\nbool\n=\nFalse\n)\n→\nT_destination\n[source]\n[source]\n¶\nstate_dict\n(\n*\n,\nprefix\n:\nstr\n=\n''\n,\nkeep_vars\n:\nbool\n=\nFalse\n)\n→\nDict\n[\nstr\n,\nAny\n]\nReturn a dictionary containing references to the whole state of the module.\nBoth parameters and persistent buffers (e.g. running averages) are\nincluded. Keys are corresponding parameter and buffer names.\nParameters and buffers set to\nNone\nare not included.\nNote\nThe returned object is a shallow copy. It contains references\nto the module’s parameters and buffers.\nWarning\nCurrently\nstate_dict()\nalso accepts positional arguments for\ndestination\n,\nprefix\nand\nkeep_vars\nin order. However,\nthis is being deprecated and keyword arguments will be enforced in\nfuture releases.\nWarning\nPlease avoid the use of argument\ndestination\nas it is not\ndesigned for end-users.\nParameters\ndestination\n(\ndict\n,\noptional\n) – If provided, the state of module will\nbe updated into the dict and the same object is returned.\nOtherwise, an\nOrderedDict\nwill be created and returned.\nDefault:\nNone\n.\nprefix\n(\nstr\n,\noptional\n) – a prefix added to parameter and buffer\nnames to compose the keys in state_dict. Default:\n''\n.\nkeep_vars\n(\nbool\n,\noptional\n) – by default the\nTensor\ns\nreturned in the state dict are detached from autograd. If it’s\nset to\nTrue\n, detaching will not be performed.\nDefault:\nFalse\n.\nReturns\na dictionary containing a whole state of the module\nReturn type\ndict\nExample:\n>>>\nmodule\n.\nstate_dict\n()\n.\nkeys\n()\n['bias', 'weight']\nto\n(\ndevice\n:\nOptional\n[\nUnion\n[\nstr\n,\ndevice\n,\nint\n]\n]\n=\n...\n,\ndtype\n:\nOptional\n[\ndtype\n]\n=\n...\n,\nnon_blocking\n:\nbool\n=\n...\n)\n→\nSelf\n[source]\n[source]\n¶\nto\n(\ndtype\n:\ndtype\n,\nnon_blocking\n:\nbool\n=\n...\n)\n→\nSelf\nto\n(\ntensor\n:\nTensor\n,\nnon_blocking\n:\nbool\n=\n...\n)\n→\nSelf\nMove and/or cast the parameters and buffers.\nThis can be called as\nto\n(\ndevice\n=\nNone\n,\ndtype\n=\nNone\n,\nnon_blocking\n=\nFalse\n)\n[source]\n[source]\nto\n(\ndtype\n,\nnon_blocking\n=\nFalse\n)\n[source]\n[source]\nto\n(\ntensor\n,\nnon_blocking\n=\nFalse\n)\n[source]\n[source]\nto\n(\nmemory_format\n=\ntorch.channels_last\n)\n[source]\n[source]\nIts signature is similar to\ntorch.Tensor.to()\n, but only accepts\nfloating point or complex\ndtype\ns. In addition, this method will\nonly cast the floating point or complex parameters and buffers to\ndtype\n(if given). The integral parameters and buffers will be moved\ndevice\n, if that is given, but with dtypes unchanged. When\nnon_blocking\nis set, it tries to convert/move asynchronously\nwith respect to the host if possible, e.g., moving CPU Tensors with\npinned memory to CUDA devices.\nSee below for examples.\nNote\nThis method modifies the module in-place.\nParameters\ndevice\n(\ntorch.device\n) – the desired device of the parameters\nand buffers in this module\ndtype\n(\ntorch.dtype\n) – the desired floating point or complex dtype of\nthe parameters and buffers in this module\ntensor\n(\ntorch.Tensor\n) – Tensor whose dtype and device are the desired\ndtype and device for all parameters and buffers in this module\nmemory_format\n(\ntorch.memory_format\n) – the desired memory\nformat for 4D parameters and buffers in this module (keyword\nonly argument)\nReturns\nself\nReturn type\nModule\nExamples:\n>>>\nlinear\n=\nnn\n.\nLinear\n(\n2\n,\n2\n)\n>>>\nlinear\n.\nweight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n[-0.5113, -0.2325]])\n>>>\nlinear\n.\nto\n(\ntorch\n.\ndouble\n)\nLinear(in_features=2, out_features=2, bias=True)\n>>>\nlinear\n.\nweight\nParameter containing:\ntensor([[ 0.1913, -0.3420],\n[-0.5113, -0.2325]], dtype=torch.float64)\n>>>\ngpu1\n=\ntorch\n.\ndevice\n(\n\"cuda:1\"\n)\n>>>\nlinear\n.\nto\n(\ngpu1\n,\ndtype\n=\ntorch\n.\nhalf\n,\nnon_blocking\n=\nTrue\n)\nLinear(in_features=2, out_features=2, bias=True)\n>>>\nlinear\n.\nweight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n[-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n>>>\ncpu\n=\ntorch\n.\ndevice\n(\n\"cpu\"\n)\n>>>\nlinear\n.\nto\n(\ncpu\n)\nLinear(in_features=2, out_features=2, bias=True)\n>>>\nlinear\n.\nweight\nParameter containing:\ntensor([[ 0.1914, -0.3420],\n[-0.5112, -0.2324]], dtype=torch.float16)\n>>>\nlinear\n=\nnn\n.\nLinear\n(\n2\n,\n2\n,\nbias\n=\nNone\n)\n.\nto\n(\ntorch\n.\ncdouble\n)\n>>>\nlinear\n.\nweight\nParameter containing:\ntensor([[ 0.3741+0.j,  0.2382+0.j],\n[ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n>>>\nlinear\n(\ntorch\n.\nones\n(\n3\n,\n2\n,\ndtype\n=\ntorch\n.\ncdouble\n))\ntensor([[0.6122+0.j, 0.1150+0.j],\n[0.6122+0.j, 0.1150+0.j],\n[0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\nto_empty\n(\n*\n,\ndevice\n,\nrecurse\n=\nTrue\n)\n[source]\n[source]\n¶\nMove the parameters and buffers to the specified device without copying storage.\nParameters\ndevice\n(\ntorch.device\n) – The desired device of the parameters\nand buffers in this module.\nrecurse\n(\nbool\n) – Whether parameters and buffers of submodules should\nbe recursively moved to the specified device.\nReturns\nself\nReturn type\nModule\ntrain\n(\nmode\n=\nTrue\n)\n[source]\n[source]\n¶\nSet the module in training mode.\nThis has an effect only on certain modules. See the documentation of\nparticular modules for details of their behaviors in training/evaluation\nmode, i.e., whether they are affected, e.g.\nDropout\n,\nBatchNorm\n,\netc.\nParameters\nmode\n(\nbool\n) – whether to set training mode (\nTrue\n) or evaluation\nmode (\nFalse\n). Default:\nTrue\n.\nReturns\nself\nReturn type\nModule\ntype\n(\ndst_type\n)\n[source]\n[source]\n¶\nCasts all parameters and buffers to\ndst_type\n.\nNote\nThis method modifies the module in-place.\nParameters\ndst_type\n(\ntype\nor\nstring\n) – the desired type\nReturns\nself\nReturn type\nModule\nxpu\n(\ndevice\n=\nNone\n)\n[source]\n[source]\n¶\nMove all model parameters and buffers to the XPU.\nThis also makes associated parameters and buffers different objects. So\nit should be called before constructing optimizer if the module will\nlive on XPU while being optimized.\nNote\nThis method modifies the module in-place.\nParameters\ndevice\n(\nint\n,\noptional\n) – if specified, all parameters will be\ncopied to that device\nReturns\nself\nReturn type\nModule\nzero_grad\n(\nset_to_none\n=\nTrue\n)\n[source]\n[source]\n¶\nReset gradients of all model parameters.\nSee similar function under\ntorch.optim.Optimizer\nfor more context.\nParameters\nset_to_none\n(\nbool\n) – instead of setting to zero, set the grads to None.\nSee\ntorch.optim.Optimizer.zero_grad()\nfor details.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L402",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.add_module",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L634",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.add_module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.apply",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L995",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.apply",
    "https://pytorch.org/docs/stable/nn.init.html#nn-init-doc",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.bfloat16",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1170",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.bfloat16",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.buffers",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2665",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.buffers",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Iterator",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.children",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2719",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.children",
    "https://docs.python.org/3/library/typing.html#typing.Iterator",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.compile",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2982",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.compile",
    "https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile",
    "https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile",
    "https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.cpu",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1112",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cpu",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.cuda",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1036",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cuda",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.double",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1148",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.double",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.eval",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2846",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.eval",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train",
    "https://pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.extra_repr",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2922",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.extra_repr",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.float",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1137",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.float",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L386",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.get_buffer",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L826",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.get_buffer",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/exceptions.html#AttributeError",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.get_extra_state",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L862",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.get_extra_state",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.set_extra_state",
    "https://docs.python.org/3/library/functions.html#object",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.get_parameter",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L790",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.get_parameter",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/exceptions.html#AttributeError",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.get_submodule",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L666",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.get_submodule",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/exceptions.html#AttributeError",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.half",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1159",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.half",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.ipu",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1055",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.ipu",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.load_state_dict",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2473",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict",
    "https://pytorch.org/docs/stable/future_mod.html#torch.__future__.get_swap_module_params_on_conversion",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.modules",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2748",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.modules",
    "https://docs.python.org/3/library/typing.html#typing.Iterator",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.mtia",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1093",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.mtia",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.named_buffers",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2688",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_buffers",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Iterator",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.named_children",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2728",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_children",
    "https://docs.python.org/3/library/typing.html#typing.Iterator",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.named_modules",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2775",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_modules",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/typing.html#typing.Set",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.named_parameters",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2633",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.named_parameters",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Iterator",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.parameters",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2608",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.parameters",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Iterator",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_backward_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1394",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_backward_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_buffer",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L522",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cuda",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_forward_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1646",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_forward_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_forward_pre_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1580",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_forward_pre_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_full_backward_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1420",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_full_backward_pre_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1345",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_pre_hook",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_load_state_dict_post_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2263",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_load_state_dict_post_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_load_state_dict_pre_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2251",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_load_state_dict_pre_hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_module",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L662",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_module",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.add_module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_parameter",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L584",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_parameter",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.cuda",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_state_dict_post_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2061",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_state_dict_post_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_state_dict_pre_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2085",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_state_dict_pre_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.requires_grad_",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2864",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.requires_grad_",
    "https://pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.set_extra_state",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L883",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.set_extra_state",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.load_state_dict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.get_extra_state",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.set_submodule",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L731",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.set_submodule",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/exceptions.html#ValueError",
    "https://docs.python.org/3/library/exceptions.html#AttributeError",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.share_memory",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2915",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.share_memory",
    "https://pytorch.org/docs/stable/generated/torch.Tensor.share_memory_.html#torch.Tensor.share_memory_",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.state_dict",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2142",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.state_dict",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Dict",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.to",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1216",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.to",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1216",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.to",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1216",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.to",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1216",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.to",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1216",
    "https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.memory_format",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.to_empty",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1181",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to_empty",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.train",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2824",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.train",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.type",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1123",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.type",
    "https://docs.python.org/3/library/functions.html#type",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.xpu",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L1074",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.xpu",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.zero_grad",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L2887",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.zero_grad",
    "https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedBuffer.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "Sequential",
  "page_text": "Sequential\n¶\nclass\ntorch.nn.\nSequential\n(\n*\nargs\n:\nModule\n)\n[source]\n[source]\n¶\nclass\ntorch.nn.\nSequential\n(\narg\n:\nOrderedDict\n[\nstr\n,\nModule\n]\n)\nA sequential container.\nModules will be added to it in the order they are passed in the\nconstructor. Alternatively, an\nOrderedDict\nof modules can be\npassed in. The\nforward()\nmethod of\nSequential\naccepts any\ninput and forwards it to the first module it contains. It then\n“chains” outputs to inputs sequentially for each subsequent module,\nfinally returning the output of the last module.\nThe value a\nSequential\nprovides over manually calling a sequence\nof modules is that it allows treating the whole container as a\nsingle module, such that performing a transformation on the\nSequential\napplies to each of the modules it stores (which are\neach a registered submodule of the\nSequential\n).\nWhat’s the difference between a\nSequential\nand a\ntorch.nn.ModuleList\n? A\nModuleList\nis exactly what it\nsounds like–a list for storing\nModule\ns! On the other hand,\nthe layers in a\nSequential\nare connected in a cascading way.\nExample:\n# Using Sequential to create a small model. When `model` is run,\n# input will first be passed to `Conv2d(1,20,5)`. The output of\n# `Conv2d(1,20,5)` will be used as the input to the first\n# `ReLU`; the output of the first `ReLU` will become the input\n# for `Conv2d(20,64,5)`. Finally, the output of\n# `Conv2d(20,64,5)` will be used as input to the second `ReLU`\nmodel\n=\nnn\n.\nSequential\n(\nnn\n.\nConv2d\n(\n1\n,\n20\n,\n5\n),\nnn\n.\nReLU\n(),\nnn\n.\nConv2d\n(\n20\n,\n64\n,\n5\n),\nnn\n.\nReLU\n()\n)\n# Using Sequential with OrderedDict. This is functionally the\n# same as the above code\nmodel\n=\nnn\n.\nSequential\n(\nOrderedDict\n([\n(\n'conv1'\n,\nnn\n.\nConv2d\n(\n1\n,\n20\n,\n5\n)),\n(\n'relu1'\n,\nnn\n.\nReLU\n()),\n(\n'conv2'\n,\nnn\n.\nConv2d\n(\n20\n,\n64\n,\n5\n)),\n(\n'relu2'\n,\nnn\n.\nReLU\n())\n]))\nappend\n(\nmodule\n)\n[source]\n[source]\n¶\nAppend a given module to the end.\nParameters\nmodule\n(\nnn.Module\n) – module to append\nReturn type\nSequential\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#sequential",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#Sequential",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L64",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential",
    "https://docs.python.org/3/library/collections.html#collections.OrderedDict",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#Sequential.append",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L253",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential.append",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "ModuleList",
  "page_text": "ModuleList\n¶\nclass\ntorch.nn.\nModuleList\n(\nmodules\n=\nNone\n)\n[source]\n[source]\n¶\nHolds submodules in a list.\nModuleList\ncan be indexed like a regular Python list, but\nmodules it contains are properly registered, and will be visible by all\nModule\nmethods.\nParameters\nmodules\n(\niterable\n,\noptional\n) – an iterable of modules to add\nExample:\nclass\nMyModule\n(\nnn\n.\nModule\n):\ndef\n__init__\n(\nself\n)\n->\nNone\n:\nsuper\n()\n.\n__init__\n()\nself\n.\nlinears\n=\nnn\n.\nModuleList\n([\nnn\n.\nLinear\n(\n10\n,\n10\n)\nfor\ni\nin\nrange\n(\n10\n)])\ndef\nforward\n(\nself\n,\nx\n):\n# ModuleList can act as an iterable, or be indexed using ints\nfor\ni\n,\nl\nin\nenumerate\n(\nself\n.\nlinears\n):\nx\n=\nself\n.\nlinears\n[\ni\n//\n2\n](\nx\n)\n+\nl\n(\nx\n)\nreturn\nx\nappend\n(\nmodule\n)\n[source]\n[source]\n¶\nAppend a given module to the end of the list.\nParameters\nmodule\n(\nnn.Module\n) – module to append\nReturn type\nModuleList\nextend\n(\nmodules\n)\n[source]\n[source]\n¶\nAppend modules from a Python iterable to the end of the list.\nParameters\nmodules\n(\niterable\n) – iterable of modules to append\nReturn type\nSelf\ninsert\n(\nindex\n,\nmodule\n)\n[source]\n[source]\n¶\nInsert a given module before a given index in the list.\nParameters\nindex\n(\nint\n) – index to insert.\nmodule\n(\nnn.Module\n) – module to insert\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#modulelist",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleList",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L281",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleList.append",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L416",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList.append",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleList.extend",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L430",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList.extend",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleList.insert",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L405",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList.insert",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "ModuleDict",
  "page_text": "ModuleDict\n¶\nclass\ntorch.nn.\nModuleDict\n(\nmodules\n=\nNone\n)\n[source]\n[source]\n¶\nHolds submodules in a dictionary.\nModuleDict\ncan be indexed like a regular Python dictionary,\nbut modules it contains are properly registered, and will be visible by all\nModule\nmethods.\nModuleDict\nis an\nordered\ndictionary that respects\nthe order of insertion, and\nin\nupdate()\n, the order of the merged\nOrderedDict\n,\ndict\n(started from Python 3.6) or another\nModuleDict\n(the argument to\nupdate()\n).\nNote that\nupdate()\nwith other unordered mapping\ntypes (e.g., Python’s plain\ndict\nbefore Python version 3.6) does not\npreserve the order of the merged mapping.\nParameters\nmodules\n(\niterable\n,\noptional\n) – a mapping (dictionary) of (string: module)\nor an iterable of key-value pairs of type (string, module)\nExample:\nclass\nMyModule\n(\nnn\n.\nModule\n):\ndef\n__init__\n(\nself\n)\n->\nNone\n:\nsuper\n()\n.\n__init__\n()\nself\n.\nchoices\n=\nnn\n.\nModuleDict\n({\n'conv'\n:\nnn\n.\nConv2d\n(\n10\n,\n10\n,\n3\n),\n'pool'\n:\nnn\n.\nMaxPool2d\n(\n3\n)\n})\nself\n.\nactivations\n=\nnn\n.\nModuleDict\n([\n[\n'lrelu'\n,\nnn\n.\nLeakyReLU\n()],\n[\n'prelu'\n,\nnn\n.\nPReLU\n()]\n])\ndef\nforward\n(\nself\n,\nx\n,\nchoice\n,\nact\n):\nx\n=\nself\n.\nchoices\n[\nchoice\n](\nx\n)\nx\n=\nself\n.\nactivations\n[\nact\n](\nx\n)\nreturn\nx\nclear\n(\n)\n[source]\n[source]\n¶\nRemove all items from the ModuleDict.\nitems\n(\n)\n[source]\n[source]\n¶\nReturn an iterable of the ModuleDict key/value pairs.\nReturn type\nIterable\n[\nTuple\n[\nstr\n,\nModule\n]]\nkeys\n(\n)\n[source]\n[source]\n¶\nReturn an iterable of the ModuleDict keys.\nReturn type\nIterable\n[\nstr\n]\npop\n(\nkey\n)\n[source]\n[source]\n¶\nRemove key from the ModuleDict and return its module.\nParameters\nkey\n(\nstr\n) – key to pop from the ModuleDict\nReturn type\nModule\nupdate\n(\nmodules\n)\n[source]\n[source]\n¶\nUpdate the\nModuleDict\nwith key-value pairs from a mapping, overwriting existing keys.\nNote\nIf\nmodules\nis an\nOrderedDict\n, a\nModuleDict\n, or\nan iterable of key-value pairs, the order of new elements in it is preserved.\nParameters\nmodules\n(\niterable\n) – a mapping (dictionary) from string to\nModule\n,\nor an iterable of key-value pairs of type (string,\nModule\n)\nvalues\n(\n)\n[source]\n[source]\n¶\nReturn an iterable of the ModuleDict values.\nReturn type\nIterable\n[\nModule\n]\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#moduledict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleDict",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L449",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.update",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.update",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.update",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleDict.clear",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L522",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.clear",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleDict.items",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L541",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.items",
    "https://docs.python.org/3/library/typing.html#typing.Iterable",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleDict.keys",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L536",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.keys",
    "https://docs.python.org/3/library/typing.html#typing.Iterable",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleDict.pop",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L526",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.pop",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleDict.update",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L551",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.update",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict",
    "https://pytorch.org/docs/stable/nn.html#module-torch.nn.modules",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ModuleDict.values",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L546",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.values",
    "https://docs.python.org/3/library/typing.html#typing.Iterable",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "ParameterList",
  "page_text": "ParameterList\n¶\nclass\ntorch.nn.\nParameterList\n(\nvalues\n=\nNone\n)\n[source]\n[source]\n¶\nHolds parameters in a list.\nParameterList\ncan be used like a regular Python\nlist, but Tensors that are\nParameter\nare properly registered,\nand will be visible by all\nModule\nmethods.\nNote that the constructor, assigning an element of the list, the\nappend()\nmethod and the\nextend()\nmethod will convert any\nTensor\ninto\nParameter\n.\nParameters\nparameters\n(\niterable\n,\noptional\n) – an iterable of elements to add to the list.\nExample:\nclass\nMyModule\n(\nnn\n.\nModule\n):\ndef\n__init__\n(\nself\n)\n->\nNone\n:\nsuper\n()\n.\n__init__\n()\nself\n.\nparams\n=\nnn\n.\nParameterList\n([\nnn\n.\nParameter\n(\ntorch\n.\nrandn\n(\n10\n,\n10\n))\nfor\ni\nin\nrange\n(\n10\n)])\ndef\nforward\n(\nself\n,\nx\n):\n# ParameterList can act as an iterable, or be indexed using ints\nfor\ni\n,\np\nin\nenumerate\n(\nself\n.\nparams\n):\nx\n=\nself\n.\nparams\n[\ni\n//\n2\n]\n.\nmm\n(\nx\n)\n+\np\n.\nmm\n(\nx\n)\nreturn\nx\nappend\n(\nvalue\n)\n[source]\n[source]\n¶\nAppend a given value at the end of the list.\nParameters\nvalue\n(\nAny\n) – value to append\nReturn type\nParameterList\nextend\n(\nvalues\n)\n[source]\n[source]\n¶\nAppend values from a Python iterable to the end of the list.\nParameters\nvalues\n(\niterable\n) – iterable of values to append\nReturn type\nSelf\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#parameterlist",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterList",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L591",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList.append",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList.extend",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterList.append",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L678",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList.append",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterList.extend",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L689",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html#torch.nn.ParameterList.extend",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleDict.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "ParameterDict",
  "page_text": "ParameterDict\n¶\nclass\ntorch.nn.\nParameterDict\n(\nparameters\n=\nNone\n)\n[source]\n[source]\n¶\nHolds parameters in a dictionary.\nParameterDict can be indexed like a regular Python dictionary, but Parameters it\ncontains are properly registered, and will be visible by all Module methods.\nOther objects are treated as would be done by a regular Python dictionary\nParameterDict\nis an\nordered\ndictionary.\nupdate()\nwith other unordered mapping\ntypes (e.g., Python’s plain\ndict\n) does not preserve the order of the\nmerged mapping. On the other hand,\nOrderedDict\nor another\nParameterDict\nwill preserve their ordering.\nNote that the constructor, assigning an element of the dictionary and the\nupdate()\nmethod will convert any\nTensor\ninto\nParameter\n.\nParameters\nvalues\n(\niterable\n,\noptional\n) – a mapping (dictionary) of\n(string : Any) or an iterable of key-value pairs\nof type (string, Any)\nExample:\nclass\nMyModule\n(\nnn\n.\nModule\n):\ndef\n__init__\n(\nself\n)\n->\nNone\n:\nsuper\n()\n.\n__init__\n()\nself\n.\nparams\n=\nnn\n.\nParameterDict\n({\n'left'\n:\nnn\n.\nParameter\n(\ntorch\n.\nrandn\n(\n5\n,\n10\n)),\n'right'\n:\nnn\n.\nParameter\n(\ntorch\n.\nrandn\n(\n5\n,\n10\n))\n})\ndef\nforward\n(\nself\n,\nx\n,\nchoice\n):\nx\n=\nself\n.\nparams\n[\nchoice\n]\n.\nmm\n(\nx\n)\nreturn\nx\nclear\n(\n)\n[source]\n[source]\n¶\nRemove all items from the ParameterDict.\ncopy\n(\n)\n[source]\n[source]\n¶\nReturn a copy of this\nParameterDict\ninstance.\nReturn type\nParameterDict\nfromkeys\n(\nkeys\n,\ndefault\n=\nNone\n)\n[source]\n[source]\n¶\nReturn a new ParameterDict with the keys provided.\nParameters\nkeys\n(\niterable\n,\nstring\n) – keys to make the new ParameterDict from\ndefault\n(\nParameter\n,\noptional\n) – value to set for all keys\nReturn type\nParameterDict\nget\n(\nkey\n,\ndefault\n=\nNone\n)\n[source]\n[source]\n¶\nReturn the parameter associated with key if present. Otherwise return default if provided, None if not.\nParameters\nkey\n(\nstr\n) – key to get from the ParameterDict\ndefault\n(\nParameter\n,\noptional\n) – value to return if key not present\nReturn type\nAny\nitems\n(\n)\n[source]\n[source]\n¶\nReturn an iterable of the ParameterDict key/value pairs.\nReturn type\nIterable\n[\nTuple\n[\nstr\n,\nAny\n]]\nkeys\n(\n)\n[source]\n[source]\n¶\nReturn an iterable of the ParameterDict keys.\nReturn type\nIterable\n[\nstr\n]\npop\n(\nkey\n)\n[source]\n[source]\n¶\nRemove key from the ParameterDict and return its parameter.\nParameters\nkey\n(\nstr\n) – key to pop from the ParameterDict\nReturn type\nAny\npopitem\n(\n)\n[source]\n[source]\n¶\nRemove and return the last inserted\n(key, parameter)\npair from the ParameterDict.\nReturn type\nTuple\n[\nstr\n,\nAny\n]\nsetdefault\n(\nkey\n,\ndefault\n=\nNone\n)\n[source]\n[source]\n¶\nSet the default for a key in the Parameterdict.\nIf key is in the ParameterDict, return its value.\nIf not, insert\nkey\nwith a parameter\ndefault\nand return\ndefault\n.\ndefault\ndefaults to\nNone\n.\nParameters\nkey\n(\nstr\n) – key to set default for\ndefault\n(\nAny\n) – the parameter set to the key\nReturn type\nAny\nupdate\n(\nparameters\n)\n[source]\n[source]\n¶\nUpdate the\nParameterDict\nwith key-value pairs from\nparameters\n, overwriting existing keys.\nNote\nIf\nparameters\nis an\nOrderedDict\n, a\nParameterDict\n, or\nan iterable of key-value pairs, the order of new elements in it is preserved.\nParameters\nparameters\n(\niterable\n) – a mapping (dictionary) from string to\nParameter\n, or an iterable of\nkey-value pairs of type (string,\nParameter\n)\nvalues\n(\n)\n[source]\n[source]\n¶\nReturn an iterable of the ParameterDict values.\nReturn type\nIterable\n[\nAny\n]\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#parameterdict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L735",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.update",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.update",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.clear",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L843",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.clear",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.copy",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L819",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.copy",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.fromkeys",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L876",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.fromkeys",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.get",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L867",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.get",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.items",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L891",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.items",
    "https://docs.python.org/3/library/typing.html#typing.Iterable",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.keys",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L887",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.keys",
    "https://docs.python.org/3/library/typing.html#typing.Iterable",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.pop",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L848",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.pop",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.popitem",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L858",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.popitem",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.setdefault",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L828",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.setdefault",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.update",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L899",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.update",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/container.html#ParameterDict.values",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/container.py#L895",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.values",
    "https://docs.python.org/3/library/typing.html#typing.Iterable",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_pre_hook.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterList.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "register_module_forward_pre_hook",
  "page_text": "torch.nn.modules.module.register_module_forward_pre_hook\n¶\ntorch.nn.modules.module.\nregister_module_forward_pre_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a forward pre-hook common to all modules.\nWarning\nThis adds global state to the\nnn.module\nmodule\nand it is only intended for debugging/profiling purposes.\nThe hook will be called every time before\nforward()\nis invoked.\nIt should have the following signature:\nhook\n(\nmodule\n,\ninput\n)\n->\nNone\nor\nmodified\ninput\nThe input contains only the positional arguments given to the module.\nKeyword arguments won’t be passed to the hooks and only to the\nforward\n.\nThe hook can modify the input. User can either return a tuple or a\nsingle modified value in the hook. We will wrap the value into a tuple\nif a single value is returned(unless that value is already a tuple).\nThis hook has precedence over the specific module hooks registered with\nregister_forward_pre_hook\n.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_pre_hook.html#torch-nn-modules-module-register-module-forward-pre-hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#register_module_forward_pre_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L212",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_pre_hook.html#torch.nn.modules.module.register_module_forward_pre_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_hook.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ParameterDict.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "register_module_forward_hook",
  "page_text": "torch.nn.modules.module.register_module_forward_hook\n¶\ntorch.nn.modules.module.\nregister_module_forward_hook\n(\nhook\n,\n*\n,\nwith_kwargs\n=\nFalse\n,\nalways_call\n=\nFalse\n)\n[source]\n[source]\n¶\nRegister a global forward hook for all the modules.\nWarning\nThis adds global state to the\nnn.module\nmodule\nand it is only intended for debugging/profiling purposes.\nThe hook will be called every time after\nforward()\nhas computed an output.\nIt should have the following signature:\nhook\n(\nmodule\n,\ninput\n,\noutput\n)\n->\nNone\nor\nmodified\noutput\nThe input contains only the positional arguments given to the module.\nKeyword arguments won’t be passed to the hooks and only to the\nforward\n.\nYou can optionally modify the output of the module by returning a new value\nthat will replace the output from the\nforward()\nfunction.\nParameters\nhook\n(\nCallable\n) – The user defined hook to be registered.\nalways_call\n(\nbool\n) – If\nTrue\nthe\nhook\nwill be run regardless of\nwhether an exception is raised while calling the Module.\nDefault:\nFalse\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nThis hook will be executed before specific module hooks registered with\nregister_forward_hook\n.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_hook.html#torch-nn-modules-module-register-module-forward-hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#register_module_forward_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L244",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_hook.html#torch.nn.modules.module.register_module_forward_hook",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_backward_hook.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_pre_hook.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "register_module_backward_hook",
  "page_text": "torch.nn.modules.module.register_module_backward_hook\n¶\ntorch.nn.modules.module.\nregister_module_backward_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a backward hook common to all the modules.\nThis function is deprecated in favor of\ntorch.nn.modules.module.register_module_full_backward_hook()\nand the behavior of this function will change in future versions.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_backward_hook.html#torch-nn-modules-module-register-module-backward-hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#register_module_backward_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L291",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_backward_hook.html#torch.nn.modules.module.register_module_backward_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_hook.html#torch.nn.modules.module.register_module_full_backward_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_pre_hook.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_forward_hook.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "register_module_full_backward_pre_hook",
  "page_text": "torch.nn.modules.module.register_module_full_backward_pre_hook\n¶\ntorch.nn.modules.module.\nregister_module_full_backward_pre_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a backward pre-hook common to all the modules.\nWarning\nThis adds global state to the\nnn.module\nmodule\nand it is only intended for debugging/profiling purposes.\nHooks registered using this function behave in the same way as those\nregistered by\ntorch.nn.Module.register_full_backward_pre_hook()\n.\nRefer to its documentation for more details.\nHooks registered using this function will be called before hooks registered\nusing\ntorch.nn.Module.register_full_backward_pre_hook()\n.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_pre_hook.html#torch-nn-modules-module-register-module-full-backward-pre-hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#register_module_full_backward_pre_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L320",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_pre_hook.html#torch.nn.modules.module.register_module_full_backward_pre_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_pre_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_pre_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_hook.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_backward_hook.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "register_module_full_backward_hook",
  "page_text": "torch.nn.modules.module.register_module_full_backward_hook\n¶\ntorch.nn.modules.module.\nregister_module_full_backward_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a backward hook common to all the modules.\nWarning\nThis adds global state to the\nnn.module\nmodule\nand it is only intended for debugging/profiling purposes.\nHooks registered using this function behave in the same way as those\nregistered by\ntorch.nn.Module.register_full_backward_hook()\n.\nRefer to its documentation for more details.\nHooks registered using this function will be called before hooks registered\nusing\ntorch.nn.Module.register_full_backward_hook()\n.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_hook.html#torch-nn-modules-module-register-module-full-backward-hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#register_module_full_backward_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L347",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_hook.html#torch.nn.modules.module.register_module_full_backward_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_buffer_registration_hook.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_pre_hook.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "register_module_buffer_registration_hook",
  "page_text": "torch.nn.modules.module.register_module_buffer_registration_hook\n¶\ntorch.nn.modules.module.\nregister_module_buffer_registration_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a buffer registration hook common to all modules.\nWarning\nThis adds global state to the\nnn.Module\nmodule\nThe hook will be called every time\nregister_buffer()\nis invoked.\nIt should have the following signature:\nhook\n(\nmodule\n,\nname\n,\nbuffer\n)\n->\nNone\nor\nnew\nbuffer\nThe hook can modify the input or return a single modified value in the hook.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_buffer_registration_hook.html#torch-nn-modules-module-register-module-buffer-registration-hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#register_module_buffer_registration_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L134",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_buffer_registration_hook.html#torch.nn.modules.module.register_module_buffer_registration_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_module_registration_hook.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_full_backward_hook.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "register_module_module_registration_hook",
  "page_text": "torch.nn.modules.module.register_module_module_registration_hook\n¶\ntorch.nn.modules.module.\nregister_module_module_registration_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a module registration hook common to all modules.\nWarning\nThis adds global state to the\nnn.Module\nmodule\nThe hook will be called every time\nregister_module()\nis invoked.\nIt should have the following signature:\nhook\n(\nmodule\n,\nname\n,\nsubmodule\n)\n->\nNone\nor\nnew\nsubmodule\nThe hook can modify the input or return a single modified value in the hook.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_module_registration_hook.html#torch-nn-modules-module-register-module-module-registration-hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#register_module_module_registration_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L160",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_module_registration_hook.html#torch.nn.modules.module.register_module_module_registration_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_parameter_registration_hook.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_buffer_registration_hook.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "register_module_parameter_registration_hook",
  "page_text": "torch.nn.modules.module.register_module_parameter_registration_hook\n¶\ntorch.nn.modules.module.\nregister_module_parameter_registration_hook\n(\nhook\n)\n[source]\n[source]\n¶\nRegister a parameter registration hook common to all modules.\nWarning\nThis adds global state to the\nnn.Module\nmodule\nThe hook will be called every time\nregister_parameter()\nis invoked.\nIt should have the following signature:\nhook\n(\nmodule\n,\nname\n,\nparam\n)\n->\nNone\nor\nnew\nparameter\nThe hook can modify the input or return a single modified value in the hook.\nReturns\na handle that can be used to remove the added hook by calling\nhandle.remove()\nReturn type\ntorch.utils.hooks.RemovableHandle\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_parameter_registration_hook.html#torch-nn-modules-module-register-module-parameter-registration-hook",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#register_module_parameter_registration_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/module.py#L186",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_parameter_registration_hook.html#torch.nn.modules.module.register_module_parameter_registration_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_module_registration_hook.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Conv1d",
  "page_text": "Conv1d\n¶\nclass\ntorch.nn.\nConv1d\n(\nin_channels\n,\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 1D convolution over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\nin\n,\nL\n)\n(N, C_{\\text{in}}, L)\n(\nN\n,\nC\nin\n​\n,\nL\n)\nand output\n(\nN\n,\nC\nout\n,\nL\nout\n)\n(N, C_{\\text{out}}, L_{\\text{out}})\n(\nN\n,\nC\nout\n​\n,\nL\nout\n​\n)\ncan be\nprecisely described as:\nout\n(\nN\ni\n,\nC\nout\nj\n)\n=\nbias\n(\nC\nout\nj\n)\n+\n∑\nk\n=\n0\nC\ni\nn\n−\n1\nweight\n(\nC\nout\nj\n,\nk\n)\n⋆\ninput\n(\nN\ni\n,\nk\n)\n\\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n\\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n\\star \\text{input}(N_i, k)\nout\n(\nN\ni\n​\n,\nC\nout\nj\n​\n​\n)\n=\nbias\n(\nC\nout\nj\n​\n​\n)\n+\nk\n=\n0\n∑\nC\nin\n​\n−\n1\n​\nweight\n(\nC\nout\nj\n​\n​\n,\nk\n)\n⋆\ninput\n(\nN\ni\n​\n,\nk\n)\nwhere\n⋆\n\\star\n⋆\nis the valid\ncross-correlation\noperator,\nN\nN\nN\nis a batch size,\nC\nC\nC\ndenotes a number of channels,\nL\nL\nL\nis a length of signal sequence.\nThis module supports\nTensorFloat32\n.\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nstride\ncontrols the stride for the cross-correlation, a single\nnumber or a one-element tuple.\npadding\ncontrols the amount of padding applied to the input. It\ncan be either a string {‘valid’, ‘same’} or a tuple of ints giving the\namount of implicit padding applied on both sides.\ndilation\ncontrols the spacing between the kernel points; also\nknown as the à trous algorithm. It is harder to describe, but this\nlink\nhas a nice visualization of what\ndilation\ndoes.\ngroups\ncontrols the connections between inputs and outputs.\nin_channels\nand\nout_channels\nmust both be divisible by\ngroups\n. For example,\nAt groups=1, all inputs are convolved to all outputs.\nAt groups=2, the operation becomes equivalent to having two conv\nlayers side by side, each seeing half the input channels\nand producing half the output channels, and both subsequently\nconcatenated.\nAt groups=\nin_channels\n, each input channel is convolved with\nits own set of filters (of size\nout_channels\nin_channels\n\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}\nin_channels\nout_channels\n​\n).\nNote\nWhen\ngroups == in_channels\nand\nout_channels == K * in_channels\n,\nwhere\nK\nis a positive integer, this operation is also known as a “depthwise convolution”.\nIn other words, for an input of size\n(\nN\n,\nC\ni\nn\n,\nL\ni\nn\n)\n(N, C_{in}, L_{in})\n(\nN\n,\nC\nin\n​\n,\nL\nin\n​\n)\n,\na depthwise convolution with a depthwise multiplier\nK\ncan be performed with the arguments\n(\nC\nin\n=\nC\nin\n,\nC\nout\n=\nC\nin\n×\nK\n,\n.\n.\n.\n,\ngroups\n=\nC\nin\n)\n(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})\n(\nC\nin\n​\n=\nC\nin\n​\n,\nC\nout\n​\n=\nC\nin\n​\n×\nK\n,\n...\n,\ngroups\n=\nC\nin\n​\n)\n.\nNote\nIn some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting\ntorch.backends.cudnn.deterministic\n=\nTrue\n. See\nReproducibility\nfor more information.\nNote\npadding='valid'\nis the same as no padding.\npadding='same'\npads\nthe input so the output has the shape as the input. However, this mode\ndoesn’t support any stride values other than 1.\nNote\nThis module supports complex data types i.e.\ncomplex32,\ncomplex64,\ncomplex128\n.\nParameters\nin_channels\n(\nint\n) – Number of channels in the input image\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\n,\ntuple\nor\nstr\n,\noptional\n) – Padding added to both sides of\nthe input. Default: 0\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel\nelements. Default: 1\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input\nchannels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the\noutput. Default:\nTrue\npadding_mode\n(\nstr\n,\noptional\n) –\n'zeros'\n,\n'reflect'\n,\n'replicate'\nor\n'circular'\n. Default:\n'zeros'\nShape:\nInput:\n(\nN\n,\nC\ni\nn\n,\nL\ni\nn\n)\n(N, C_{in}, L_{in})\n(\nN\n,\nC\nin\n​\n,\nL\nin\n​\n)\nor\n(\nC\ni\nn\n,\nL\ni\nn\n)\n(C_{in}, L_{in})\n(\nC\nin\n​\n,\nL\nin\n​\n)\nOutput:\n(\nN\n,\nC\no\nu\nt\n,\nL\no\nu\nt\n)\n(N, C_{out}, L_{out})\n(\nN\n,\nC\no\nu\nt\n​\n,\nL\no\nu\nt\n​\n)\nor\n(\nC\no\nu\nt\n,\nL\no\nu\nt\n)\n(C_{out}, L_{out})\n(\nC\no\nu\nt\n​\n,\nL\no\nu\nt\n​\n)\n, where\nL\no\nu\nt\n=\n⌊\nL\ni\nn\n+\n2\n×\npadding\n−\ndilation\n×\n(\nkernel_size\n−\n1\n)\n−\n1\nstride\n+\n1\n⌋\nL_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n          \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\nL\no\nu\nt\n​\n=\n⌊\nstride\nL\nin\n​\n+\n2\n×\npadding\n−\ndilation\n×\n(\nkernel_size\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nVariables\nweight\n(\nTensor\n) – the learnable weights of the module of shape\n(\nout_channels\n,\nin_channels\ngroups\n,\nkernel_size\n)\n(\\text{out\\_channels},\n\\frac{\\text{in\\_channels}}{\\text{groups}}, \\text{kernel\\_size})\n(\nout_channels\n,\ngroups\nin_channels\n​\n,\nkernel_size\n)\n.\nThe values of these weights are sampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nin\n∗\nkernel_size\nk = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}\nk\n=\nC\nin\n​\n∗\nkernel_size\ng\nro\nu\np\ns\n​\nbias\n(\nTensor\n) – the learnable bias of the module of shape\n(out_channels). If\nbias\nis\nTrue\n, then the values of these weights are\nsampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nin\n∗\nkernel_size\nk = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}\nk\n=\nC\nin\n​\n∗\nkernel_size\ng\nro\nu\np\ns\n​\nExamples:\n>>>\nm\n=\nnn\n.\nConv1d\n(\n16\n,\n33\n,\n3\n,\nstride\n=\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#conv1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#Conv1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L214",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d",
    "https://en.wikipedia.org/wiki/Cross-correlation",
    "https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.module.register_module_parameter_registration_hook.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Conv2d",
  "page_text": "Conv2d\n¶\nclass\ntorch.nn.\nConv2d\n(\nin_channels\n,\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 2D convolution over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\nin\n,\nH\n,\nW\n)\n(N, C_{\\text{in}}, H, W)\n(\nN\n,\nC\nin\n​\n,\nH\n,\nW\n)\nand output\n(\nN\n,\nC\nout\n,\nH\nout\n,\nW\nout\n)\n(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})\n(\nN\n,\nC\nout\n​\n,\nH\nout\n​\n,\nW\nout\n​\n)\ncan be precisely described as:\nout\n(\nN\ni\n,\nC\nout\nj\n)\n=\nbias\n(\nC\nout\nj\n)\n+\n∑\nk\n=\n0\nC\nin\n−\n1\nweight\n(\nC\nout\nj\n,\nk\n)\n⋆\ninput\n(\nN\ni\n,\nk\n)\n\\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n\\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\nout\n(\nN\ni\n​\n,\nC\nout\nj\n​\n​\n)\n=\nbias\n(\nC\nout\nj\n​\n​\n)\n+\nk\n=\n0\n∑\nC\nin\n​\n−\n1\n​\nweight\n(\nC\nout\nj\n​\n​\n,\nk\n)\n⋆\ninput\n(\nN\ni\n​\n,\nk\n)\nwhere\n⋆\n\\star\n⋆\nis the valid 2D\ncross-correlation\noperator,\nN\nN\nN\nis a batch size,\nC\nC\nC\ndenotes a number of channels,\nH\nH\nH\nis a height of input planes in pixels, and\nW\nW\nW\nis\nwidth in pixels.\nThis module supports\nTensorFloat32\n.\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nstride\ncontrols the stride for the cross-correlation, a single\nnumber or a tuple.\npadding\ncontrols the amount of padding applied to the input. It\ncan be either a string {‘valid’, ‘same’} or an int / a tuple of ints giving the\namount of implicit padding applied on both sides.\ndilation\ncontrols the spacing between the kernel points; also\nknown as the à trous algorithm. It is harder to describe, but this\nlink\nhas a nice visualization of what\ndilation\ndoes.\ngroups\ncontrols the connections between inputs and outputs.\nin_channels\nand\nout_channels\nmust both be divisible by\ngroups\n. For example,\nAt groups=1, all inputs are convolved to all outputs.\nAt groups=2, the operation becomes equivalent to having two conv\nlayers side by side, each seeing half the input channels\nand producing half the output channels, and both subsequently\nconcatenated.\nAt groups=\nin_channels\n, each input channel is convolved with\nits own set of filters (of size\nout_channels\nin_channels\n\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}\nin_channels\nout_channels\n​\n).\nThe parameters\nkernel_size\n,\nstride\n,\npadding\n,\ndilation\ncan either be:\na single\nint\n– in which case the same value is used for the height and width dimension\na\ntuple\nof two ints – in which case, the first\nint\nis used for the height dimension,\nand the second\nint\nfor the width dimension\nNote\nWhen\ngroups == in_channels\nand\nout_channels == K * in_channels\n,\nwhere\nK\nis a positive integer, this operation is also known as a “depthwise convolution”.\nIn other words, for an input of size\n(\nN\n,\nC\ni\nn\n,\nL\ni\nn\n)\n(N, C_{in}, L_{in})\n(\nN\n,\nC\nin\n​\n,\nL\nin\n​\n)\n,\na depthwise convolution with a depthwise multiplier\nK\ncan be performed with the arguments\n(\nC\nin\n=\nC\nin\n,\nC\nout\n=\nC\nin\n×\nK\n,\n.\n.\n.\n,\ngroups\n=\nC\nin\n)\n(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})\n(\nC\nin\n​\n=\nC\nin\n​\n,\nC\nout\n​\n=\nC\nin\n​\n×\nK\n,\n...\n,\ngroups\n=\nC\nin\n​\n)\n.\nNote\nIn some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting\ntorch.backends.cudnn.deterministic\n=\nTrue\n. See\nReproducibility\nfor more information.\nNote\npadding='valid'\nis the same as no padding.\npadding='same'\npads\nthe input so the output has the shape as the input. However, this mode\ndoesn’t support any stride values other than 1.\nNote\nThis module supports complex data types i.e.\ncomplex32,\ncomplex64,\ncomplex128\n.\nParameters\nin_channels\n(\nint\n) – Number of channels in the input image\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\n,\ntuple\nor\nstr\n,\noptional\n) – Padding added to all four sides of\nthe input. Default: 0\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel elements. Default: 1\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input\nchannels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the\noutput. Default:\nTrue\npadding_mode\n(\nstr\n,\noptional\n) –\n'zeros'\n,\n'reflect'\n,\n'replicate'\nor\n'circular'\n. Default:\n'zeros'\nShape:\nInput:\n(\nN\n,\nC\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C_{in}, H_{in}, W_{in})\n(\nN\n,\nC\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C_{in}, H_{in}, W_{in})\n(\nC\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nOutput:\n(\nN\n,\nC\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C_{out}, H_{out}, W_{out})\n(\nN\n,\nC\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C_{out}, H_{out}, W_{out})\n(\nC\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n+\n2\n×\npadding\n[\n0\n]\n−\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n−\n1\nstride\n[\n0\n]\n+\n1\n⌋\nH_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n          \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nstride\n[\n0\n]\nH\nin\n​\n+\n2\n×\npadding\n[\n0\n]\n−\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n+\n2\n×\npadding\n[\n1\n]\n−\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n−\n1\nstride\n[\n1\n]\n+\n1\n⌋\nW_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n          \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nstride\n[\n1\n]\nW\nin\n​\n+\n2\n×\npadding\n[\n1\n]\n−\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nVariables\nweight\n(\nTensor\n) – the learnable weights of the module of shape\n(\nout_channels\n,\nin_channels\ngroups\n,\n(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},\n(\nout_channels\n,\ngroups\nin_channels\n​\n,\nkernel_size[0]\n,\nkernel_size[1]\n)\n\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})\nkernel_size[0]\n,\nkernel_size[1]\n)\n.\nThe values of these weights are sampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nin\n∗\n∏\ni\n=\n0\n1\nkernel_size\n[\ni\n]\nk = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}\nk\n=\nC\nin\n​\n∗\n∏\ni\n=\n0\n1\n​\nkernel_size\n[\ni\n]\ng\nro\nu\np\ns\n​\nbias\n(\nTensor\n) – the learnable bias of the module of shape\n(out_channels). If\nbias\nis\nTrue\n,\nthen the values of these weights are\nsampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nin\n∗\n∏\ni\n=\n0\n1\nkernel_size\n[\ni\n]\nk = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}\nk\n=\nC\nin\n​\n∗\n∏\ni\n=\n0\n1\n​\nkernel_size\n[\ni\n]\ng\nro\nu\np\ns\n​\nExamples\n>>>\n# With square kernels and equal stride\n>>>\nm\n=\nnn\n.\nConv2d\n(\n16\n,\n33\n,\n3\n,\nstride\n=\n2\n)\n>>>\n# non-square kernels and unequal stride and with padding\n>>>\nm\n=\nnn\n.\nConv2d\n(\n16\n,\n33\n,\n(\n3\n,\n5\n),\nstride\n=\n(\n2\n,\n1\n),\npadding\n=\n(\n4\n,\n2\n))\n>>>\n# non-square kernels and unequal stride and with padding and dilation\n>>>\nm\n=\nnn\n.\nConv2d\n(\n16\n,\n33\n,\n(\n3\n,\n5\n),\nstride\n=\n(\n2\n,\n1\n),\npadding\n=\n(\n4\n,\n2\n),\ndilation\n=\n(\n3\n,\n1\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n100\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#Conv2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L378",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d",
    "https://en.wikipedia.org/wiki/Cross-correlation",
    "https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Conv3d",
  "page_text": "Conv3d\n¶\nclass\ntorch.nn.\nConv3d\n(\nin_channels\n,\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 3D convolution over an input signal composed of several input\nplanes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\ni\nn\n,\nD\n,\nH\n,\nW\n)\n(N, C_{in}, D, H, W)\n(\nN\n,\nC\nin\n​\n,\nD\n,\nH\n,\nW\n)\nand output\n(\nN\n,\nC\no\nu\nt\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C_{out}, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\no\nu\nt\n​\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\ncan be precisely described as:\no\nu\nt\n(\nN\ni\n,\nC\no\nu\nt\nj\n)\n=\nb\ni\na\ns\n(\nC\no\nu\nt\nj\n)\n+\n∑\nk\n=\n0\nC\ni\nn\n−\n1\nw\ne\ni\ng\nh\nt\n(\nC\no\nu\nt\nj\n,\nk\n)\n⋆\ni\nn\np\nu\nt\n(\nN\ni\n,\nk\n)\nout(N_i, C_{out_j}) = bias(C_{out_j}) +\n                        \\sum_{k = 0}^{C_{in} - 1} weight(C_{out_j}, k) \\star input(N_i, k)\no\nu\nt\n(\nN\ni\n​\n,\nC\no\nu\nt\nj\n​\n​\n)\n=\nbia\ns\n(\nC\no\nu\nt\nj\n​\n​\n)\n+\nk\n=\n0\n∑\nC\nin\n​\n−\n1\n​\nw\ne\ni\ng\nh\nt\n(\nC\no\nu\nt\nj\n​\n​\n,\nk\n)\n⋆\nin\np\nu\nt\n(\nN\ni\n​\n,\nk\n)\nwhere\n⋆\n\\star\n⋆\nis the valid 3D\ncross-correlation\noperator\nThis module supports\nTensorFloat32\n.\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nstride\ncontrols the stride for the cross-correlation.\npadding\ncontrols the amount of padding applied to the input. It\ncan be either a string {‘valid’, ‘same’} or a tuple of ints giving the\namount of implicit padding applied on both sides.\ndilation\ncontrols the spacing between the kernel points; also known as the à trous algorithm.\nIt is harder to describe, but this\nlink\nhas a nice visualization of what\ndilation\ndoes.\ngroups\ncontrols the connections between inputs and outputs.\nin_channels\nand\nout_channels\nmust both be divisible by\ngroups\n. For example,\nAt groups=1, all inputs are convolved to all outputs.\nAt groups=2, the operation becomes equivalent to having two conv\nlayers side by side, each seeing half the input channels\nand producing half the output channels, and both subsequently\nconcatenated.\nAt groups=\nin_channels\n, each input channel is convolved with\nits own set of filters (of size\nout_channels\nin_channels\n\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}\nin_channels\nout_channels\n​\n).\nThe parameters\nkernel_size\n,\nstride\n,\npadding\n,\ndilation\ncan either be:\na single\nint\n– in which case the same value is used for the depth, height and width dimension\na\ntuple\nof three ints – in which case, the first\nint\nis used for the depth dimension,\nthe second\nint\nfor the height dimension and the third\nint\nfor the width dimension\nNote\nWhen\ngroups == in_channels\nand\nout_channels == K * in_channels\n,\nwhere\nK\nis a positive integer, this operation is also known as a “depthwise convolution”.\nIn other words, for an input of size\n(\nN\n,\nC\ni\nn\n,\nL\ni\nn\n)\n(N, C_{in}, L_{in})\n(\nN\n,\nC\nin\n​\n,\nL\nin\n​\n)\n,\na depthwise convolution with a depthwise multiplier\nK\ncan be performed with the arguments\n(\nC\nin\n=\nC\nin\n,\nC\nout\n=\nC\nin\n×\nK\n,\n.\n.\n.\n,\ngroups\n=\nC\nin\n)\n(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})\n(\nC\nin\n​\n=\nC\nin\n​\n,\nC\nout\n​\n=\nC\nin\n​\n×\nK\n,\n...\n,\ngroups\n=\nC\nin\n​\n)\n.\nNote\nIn some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting\ntorch.backends.cudnn.deterministic\n=\nTrue\n. See\nReproducibility\nfor more information.\nNote\npadding='valid'\nis the same as no padding.\npadding='same'\npads\nthe input so the output has the shape as the input. However, this mode\ndoesn’t support any stride values other than 1.\nNote\nThis module supports complex data types i.e.\ncomplex32,\ncomplex64,\ncomplex128\n.\nParameters\nin_channels\n(\nint\n) – Number of channels in the input image\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\n,\ntuple\nor\nstr\n,\noptional\n) – Padding added to all six sides of\nthe input. Default: 0\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel elements. Default: 1\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input channels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the output. Default:\nTrue\npadding_mode\n(\nstr\n,\noptional\n) –\n'zeros'\n,\n'reflect'\n,\n'replicate'\nor\n'circular'\n. Default:\n'zeros'\nShape:\nInput:\n(\nN\n,\nC\ni\nn\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C_{in}, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\nin\n​\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\ni\nn\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C_{in}, D_{in}, H_{in}, W_{in})\n(\nC\nin\n​\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nOutput:\n(\nN\n,\nC\no\nu\nt\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C_{out}, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\no\nu\nt\n​\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\no\nu\nt\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C_{out}, D_{out}, H_{out}, W_{out})\n(\nC\no\nu\nt\n​\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n,\nwhere\nD\no\nu\nt\n=\n⌊\nD\ni\nn\n+\n2\n×\npadding\n[\n0\n]\n−\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n−\n1\nstride\n[\n0\n]\n+\n1\n⌋\nD_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n      \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\nD\no\nu\nt\n​\n=\n⌊\nstride\n[\n0\n]\nD\nin\n​\n+\n2\n×\npadding\n[\n0\n]\n−\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n+\n2\n×\npadding\n[\n1\n]\n−\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n−\n1\nstride\n[\n1\n]\n+\n1\n⌋\nH_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n      \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nstride\n[\n1\n]\nH\nin\n​\n+\n2\n×\npadding\n[\n1\n]\n−\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n+\n2\n×\npadding\n[\n2\n]\n−\ndilation\n[\n2\n]\n×\n(\nkernel_size\n[\n2\n]\n−\n1\n)\n−\n1\nstride\n[\n2\n]\n+\n1\n⌋\nW_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2]\n      \\times (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nstride\n[\n2\n]\nW\nin\n​\n+\n2\n×\npadding\n[\n2\n]\n−\ndilation\n[\n2\n]\n×\n(\nkernel_size\n[\n2\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nVariables\nweight\n(\nTensor\n) – the learnable weights of the module of shape\n(\nout_channels\n,\nin_channels\ngroups\n,\n(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},\n(\nout_channels\n,\ngroups\nin_channels\n​\n,\nkernel_size[0]\n,\nkernel_size[1]\n,\nkernel_size[2]\n)\n\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]}, \\text{kernel\\_size[2]})\nkernel_size[0]\n,\nkernel_size[1]\n,\nkernel_size[2]\n)\n.\nThe values of these weights are sampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nin\n∗\n∏\ni\n=\n0\n2\nkernel_size\n[\ni\n]\nk = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}\nk\n=\nC\nin\n​\n∗\n∏\ni\n=\n0\n2\n​\nkernel_size\n[\ni\n]\ng\nro\nu\np\ns\n​\nbias\n(\nTensor\n) – the learnable bias of the module of shape (out_channels). If\nbias\nis\nTrue\n,\nthen the values of these weights are\nsampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nin\n∗\n∏\ni\n=\n0\n2\nkernel_size\n[\ni\n]\nk = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}\nk\n=\nC\nin\n​\n∗\n∏\ni\n=\n0\n2\n​\nkernel_size\n[\ni\n]\ng\nro\nu\np\ns\n​\nExamples:\n>>>\n# With square kernels and equal stride\n>>>\nm\n=\nnn\n.\nConv3d\n(\n16\n,\n33\n,\n3\n,\nstride\n=\n2\n)\n>>>\n# non-square kernels and unequal stride and with padding\n>>>\nm\n=\nnn\n.\nConv3d\n(\n16\n,\n33\n,\n(\n3\n,\n5\n,\n2\n),\nstride\n=\n(\n2\n,\n1\n,\n1\n),\npadding\n=\n(\n4\n,\n2\n,\n0\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n10\n,\n50\n,\n100\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#conv3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#Conv3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L557",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d",
    "https://en.wikipedia.org/wiki/Cross-correlation",
    "https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ConvTranspose1d",
  "page_text": "ConvTranspose1d\n¶\nclass\ntorch.nn.\nConvTranspose1d\n(\nin_channels\n,\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\noutput_padding\n=\n0\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\ndilation\n=\n1\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 1D transposed convolution operator over an input image\ncomposed of several input planes.\nThis module can be seen as the gradient of Conv1d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation as it does\nnot compute a true inverse of convolution). For more information, see the visualizations\nhere\nand the\nDeconvolutional Networks\npaper.\nThis module supports\nTensorFloat32\n.\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nstride\ncontrols the stride for the cross-correlation.\npadding\ncontrols the amount of implicit zero padding on both\nsides for\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nnumber of points. See note\nbelow for details.\noutput_padding\ncontrols the additional size added to one side\nof the output shape. See note below for details.\ndilation\ncontrols the spacing between the kernel points; also known as the à trous algorithm.\nIt is harder to describe, but the link\nhere\nhas a nice visualization of what\ndilation\ndoes.\ngroups\ncontrols the connections between inputs and outputs.\nin_channels\nand\nout_channels\nmust both be divisible by\ngroups\n. For example,\nAt groups=1, all inputs are convolved to all outputs.\nAt groups=2, the operation becomes equivalent to having two conv\nlayers side by side, each seeing half the input channels\nand producing half the output channels, and both subsequently\nconcatenated.\nAt groups=\nin_channels\n, each input channel is convolved with\nits own set of filters (of size\nout_channels\nin_channels\n\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}\nin_channels\nout_channels\n​\n).\nNote\nThe\npadding\nargument effectively adds\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\namount of zero padding to both sizes of the input. This is set so that\nwhen a\nConv1d\nand a\nConvTranspose1d\nare initialized with same parameters, they are inverses of each other in\nregard to the input and output shapes. However, when\nstride\n>\n1\n,\nConv1d\nmaps multiple input shapes to the same output\nshape.\noutput_padding\nis provided to resolve this ambiguity by\neffectively increasing the calculated output shape on one side. Note\nthat\noutput_padding\nis only used to find output shape, but does\nnot actually add zero-padding to output.\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance. If this is\nundesirable, you can try to make the operation deterministic (potentially at\na performance cost) by setting\ntorch.backends.cudnn.deterministic\n=\nTrue\n.\nPlease see the notes on\nReproducibility\nfor background.\nParameters\nin_channels\n(\nint\n) – Number of channels in the input image\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) –\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nzero-padding\nwill be added to both sides of the input. Default: 0\noutput_padding\n(\nint\nor\ntuple\n,\noptional\n) – Additional size added to one side\nof the output shape. Default: 0\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input channels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the output. Default:\nTrue\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel elements. Default: 1\nShape:\nInput:\n(\nN\n,\nC\ni\nn\n,\nL\ni\nn\n)\n(N, C_{in}, L_{in})\n(\nN\n,\nC\nin\n​\n,\nL\nin\n​\n)\nor\n(\nC\ni\nn\n,\nL\ni\nn\n)\n(C_{in}, L_{in})\n(\nC\nin\n​\n,\nL\nin\n​\n)\nOutput:\n(\nN\n,\nC\no\nu\nt\n,\nL\no\nu\nt\n)\n(N, C_{out}, L_{out})\n(\nN\n,\nC\no\nu\nt\n​\n,\nL\no\nu\nt\n​\n)\nor\n(\nC\no\nu\nt\n,\nL\no\nu\nt\n)\n(C_{out}, L_{out})\n(\nC\no\nu\nt\n​\n,\nL\no\nu\nt\n​\n)\n, where\nL\no\nu\nt\n=\n(\nL\ni\nn\n−\n1\n)\n×\nstride\n−\n2\n×\npadding\n+\ndilation\n×\n(\nkernel_size\n−\n1\n)\n+\noutput_padding\n+\n1\nL_{out} = (L_{in} - 1) \\times \\text{stride} - 2 \\times \\text{padding} + \\text{dilation}\n          \\times (\\text{kernel\\_size} - 1) + \\text{output\\_padding} + 1\nL\no\nu\nt\n​\n=\n(\nL\nin\n​\n−\n1\n)\n×\nstride\n−\n2\n×\npadding\n+\ndilation\n×\n(\nkernel_size\n−\n1\n)\n+\noutput_padding\n+\n1\nVariables\nweight\n(\nTensor\n) – the learnable weights of the module of shape\n(\nin_channels\n,\nout_channels\ngroups\n,\n(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},\n(\nin_channels\n,\ngroups\nout_channels\n​\n,\nkernel_size\n)\n\\text{kernel\\_size})\nkernel_size\n)\n.\nThe values of these weights are sampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nout\n∗\nkernel_size\nk = \\frac{groups}{C_\\text{out} * \\text{kernel\\_size}}\nk\n=\nC\nout\n​\n∗\nkernel_size\ng\nro\nu\np\ns\n​\nbias\n(\nTensor\n) – the learnable bias of the module of shape (out_channels).\nIf\nbias\nis\nTrue\n, then the values of these weights are\nsampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nout\n∗\nkernel_size\nk = \\frac{groups}{C_\\text{out} * \\text{kernel\\_size}}\nk\n=\nC\nout\n​\n∗\nkernel_size\ng\nro\nu\np\ns\n​\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#convtranspose1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#ConvTranspose1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L822",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf",
    "https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ConvTranspose2d",
  "page_text": "ConvTranspose2d\n¶\nclass\ntorch.nn.\nConvTranspose2d\n(\nin_channels\n,\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\noutput_padding\n=\n0\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\ndilation\n=\n1\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 2D transposed convolution operator over an input image\ncomposed of several input planes.\nThis module can be seen as the gradient of Conv2d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation as it does\nnot compute a true inverse of convolution). For more information, see the visualizations\nhere\nand the\nDeconvolutional Networks\npaper.\nThis module supports\nTensorFloat32\n.\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nstride\ncontrols the stride for the cross-correlation.\npadding\ncontrols the amount of implicit zero padding on both\nsides for\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nnumber of points. See note\nbelow for details.\noutput_padding\ncontrols the additional size added to one side\nof the output shape. See note below for details.\ndilation\ncontrols the spacing between the kernel points; also known as the à trous algorithm.\nIt is harder to describe, but the link\nhere\nhas a nice visualization of what\ndilation\ndoes.\ngroups\ncontrols the connections between inputs and outputs.\nin_channels\nand\nout_channels\nmust both be divisible by\ngroups\n. For example,\nAt groups=1, all inputs are convolved to all outputs.\nAt groups=2, the operation becomes equivalent to having two conv\nlayers side by side, each seeing half the input channels\nand producing half the output channels, and both subsequently\nconcatenated.\nAt groups=\nin_channels\n, each input channel is convolved with\nits own set of filters (of size\nout_channels\nin_channels\n\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}\nin_channels\nout_channels\n​\n).\nThe parameters\nkernel_size\n,\nstride\n,\npadding\n,\noutput_padding\ncan either be:\na single\nint\n– in which case the same value is used for the height and width dimensions\na\ntuple\nof two ints – in which case, the first\nint\nis used for the height dimension,\nand the second\nint\nfor the width dimension\nNote\nThe\npadding\nargument effectively adds\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\namount of zero padding to both sizes of the input. This is set so that\nwhen a\nConv2d\nand a\nConvTranspose2d\nare initialized with same parameters, they are inverses of each other in\nregard to the input and output shapes. However, when\nstride\n>\n1\n,\nConv2d\nmaps multiple input shapes to the same output\nshape.\noutput_padding\nis provided to resolve this ambiguity by\neffectively increasing the calculated output shape on one side. Note\nthat\noutput_padding\nis only used to find output shape, but does\nnot actually add zero-padding to output.\nNote\nIn some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting\ntorch.backends.cudnn.deterministic\n=\nTrue\n. See\nReproducibility\nfor more information.\nParameters\nin_channels\n(\nint\n) – Number of channels in the input image\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) –\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nzero-padding\nwill be added to both sides of each dimension in the input. Default: 0\noutput_padding\n(\nint\nor\ntuple\n,\noptional\n) – Additional size added to one side\nof each dimension in the output shape. Default: 0\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input channels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the output. Default:\nTrue\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel elements. Default: 1\nShape:\nInput:\n(\nN\n,\nC\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C_{in}, H_{in}, W_{in})\n(\nN\n,\nC\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C_{in}, H_{in}, W_{in})\n(\nC\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nOutput:\n(\nN\n,\nC\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C_{out}, H_{out}, W_{out})\n(\nN\n,\nC\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C_{out}, H_{out}, W_{out})\n(\nC\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\n(\nH\ni\nn\n−\n1\n)\n×\nstride\n[\n0\n]\n−\n2\n×\npadding\n[\n0\n]\n+\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n+\noutput_padding\n[\n0\n]\n+\n1\nH_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n          \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\nH\no\nu\nt\n​\n=\n(\nH\nin\n​\n−\n1\n)\n×\nstride\n[\n0\n]\n−\n2\n×\npadding\n[\n0\n]\n+\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n+\noutput_padding\n[\n0\n]\n+\n1\nW\no\nu\nt\n=\n(\nW\ni\nn\n−\n1\n)\n×\nstride\n[\n1\n]\n−\n2\n×\npadding\n[\n1\n]\n+\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n+\noutput_padding\n[\n1\n]\n+\n1\nW_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n          \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\nW\no\nu\nt\n​\n=\n(\nW\nin\n​\n−\n1\n)\n×\nstride\n[\n1\n]\n−\n2\n×\npadding\n[\n1\n]\n+\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n+\noutput_padding\n[\n1\n]\n+\n1\nVariables\nweight\n(\nTensor\n) – the learnable weights of the module of shape\n(\nin_channels\n,\nout_channels\ngroups\n,\n(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},\n(\nin_channels\n,\ngroups\nout_channels\n​\n,\nkernel_size[0]\n,\nkernel_size[1]\n)\n\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})\nkernel_size[0]\n,\nkernel_size[1]\n)\n.\nThe values of these weights are sampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nout\n∗\n∏\ni\n=\n0\n1\nkernel_size\n[\ni\n]\nk = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}\nk\n=\nC\nout\n​\n∗\n∏\ni\n=\n0\n1\n​\nkernel_size\n[\ni\n]\ng\nro\nu\np\ns\n​\nbias\n(\nTensor\n) – the learnable bias of the module of shape (out_channels)\nIf\nbias\nis\nTrue\n, then the values of these weights are\nsampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nout\n∗\n∏\ni\n=\n0\n1\nkernel_size\n[\ni\n]\nk = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}\nk\n=\nC\nout\n​\n∗\n∏\ni\n=\n0\n1\n​\nkernel_size\n[\ni\n]\ng\nro\nu\np\ns\n​\nExamples:\n>>>\n# With square kernels and equal stride\n>>>\nm\n=\nnn\n.\nConvTranspose2d\n(\n16\n,\n33\n,\n3\n,\nstride\n=\n2\n)\n>>>\n# non-square kernels and unequal stride and with padding\n>>>\nm\n=\nnn\n.\nConvTranspose2d\n(\n16\n,\n33\n,\n(\n3\n,\n5\n),\nstride\n=\n(\n2\n,\n1\n),\npadding\n=\n(\n4\n,\n2\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n100\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# exact output size can be also specified as an argument\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n16\n,\n12\n,\n12\n)\n>>>\ndownsample\n=\nnn\n.\nConv2d\n(\n16\n,\n16\n,\n3\n,\nstride\n=\n2\n,\npadding\n=\n1\n)\n>>>\nupsample\n=\nnn\n.\nConvTranspose2d\n(\n16\n,\n16\n,\n3\n,\nstride\n=\n2\n,\npadding\n=\n1\n)\n>>>\nh\n=\ndownsample\n(\ninput\n)\n>>>\nh\n.\nsize\n()\ntorch.Size([1, 16, 6, 6])\n>>>\noutput\n=\nupsample\n(\nh\n,\noutput_size\n=\ninput\n.\nsize\n())\n>>>\noutput\n.\nsize\n()\ntorch.Size([1, 16, 12, 12])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#convtranspose2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#ConvTranspose2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L986",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf",
    "https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ConvTranspose3d",
  "page_text": "ConvTranspose3d\n¶\nclass\ntorch.nn.\nConvTranspose3d\n(\nin_channels\n,\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\noutput_padding\n=\n0\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\ndilation\n=\n1\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 3D transposed convolution operator over an input image composed of several input\nplanes.\nThe transposed convolution operator multiplies each input value element-wise by a learnable kernel,\nand sums over the outputs from all input feature planes.\nThis module can be seen as the gradient of Conv3d with respect to its input.\nIt is also known as a fractionally-strided convolution or\na deconvolution (although it is not an actual deconvolution operation as it does\nnot compute a true inverse of convolution). For more information, see the visualizations\nhere\nand the\nDeconvolutional Networks\npaper.\nThis module supports\nTensorFloat32\n.\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nstride\ncontrols the stride for the cross-correlation.\npadding\ncontrols the amount of implicit zero padding on both\nsides for\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nnumber of points. See note\nbelow for details.\noutput_padding\ncontrols the additional size added to one side\nof the output shape. See note below for details.\ndilation\ncontrols the spacing between the kernel points; also known as the à trous algorithm.\nIt is harder to describe, but the link\nhere\nhas a nice visualization of what\ndilation\ndoes.\ngroups\ncontrols the connections between inputs and outputs.\nin_channels\nand\nout_channels\nmust both be divisible by\ngroups\n. For example,\nAt groups=1, all inputs are convolved to all outputs.\nAt groups=2, the operation becomes equivalent to having two conv\nlayers side by side, each seeing half the input channels\nand producing half the output channels, and both subsequently\nconcatenated.\nAt groups=\nin_channels\n, each input channel is convolved with\nits own set of filters (of size\nout_channels\nin_channels\n\\frac{\\text{out\\_channels}}{\\text{in\\_channels}}\nin_channels\nout_channels\n​\n).\nThe parameters\nkernel_size\n,\nstride\n,\npadding\n,\noutput_padding\ncan either be:\na single\nint\n– in which case the same value is used for the depth, height and width dimensions\na\ntuple\nof three ints – in which case, the first\nint\nis used for the depth dimension,\nthe second\nint\nfor the height dimension and the third\nint\nfor the width dimension\nNote\nThe\npadding\nargument effectively adds\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\namount of zero padding to both sizes of the input. This is set so that\nwhen a\nConv3d\nand a\nConvTranspose3d\nare initialized with same parameters, they are inverses of each other in\nregard to the input and output shapes. However, when\nstride\n>\n1\n,\nConv3d\nmaps multiple input shapes to the same output\nshape.\noutput_padding\nis provided to resolve this ambiguity by\neffectively increasing the calculated output shape on one side. Note\nthat\noutput_padding\nis only used to find output shape, but does\nnot actually add zero-padding to output.\nNote\nIn some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting\ntorch.backends.cudnn.deterministic\n=\nTrue\n. See\nReproducibility\nfor more information.\nParameters\nin_channels\n(\nint\n) – Number of channels in the input image\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) –\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nzero-padding\nwill be added to both sides of each dimension in the input. Default: 0\noutput_padding\n(\nint\nor\ntuple\n,\noptional\n) – Additional size added to one side\nof each dimension in the output shape. Default: 0\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input channels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the output. Default:\nTrue\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel elements. Default: 1\nShape:\nInput:\n(\nN\n,\nC\ni\nn\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C_{in}, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\nin\n​\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\ni\nn\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C_{in}, D_{in}, H_{in}, W_{in})\n(\nC\nin\n​\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nOutput:\n(\nN\n,\nC\no\nu\nt\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C_{out}, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\no\nu\nt\n​\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\no\nu\nt\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C_{out}, D_{out}, H_{out}, W_{out})\n(\nC\no\nu\nt\n​\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nD\no\nu\nt\n=\n(\nD\ni\nn\n−\n1\n)\n×\nstride\n[\n0\n]\n−\n2\n×\npadding\n[\n0\n]\n+\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n+\noutput_padding\n[\n0\n]\n+\n1\nD_{out} = (D_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0]\n          \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\nD\no\nu\nt\n​\n=\n(\nD\nin\n​\n−\n1\n)\n×\nstride\n[\n0\n]\n−\n2\n×\npadding\n[\n0\n]\n+\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n+\noutput_padding\n[\n0\n]\n+\n1\nH\no\nu\nt\n=\n(\nH\ni\nn\n−\n1\n)\n×\nstride\n[\n1\n]\n−\n2\n×\npadding\n[\n1\n]\n+\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n+\noutput_padding\n[\n1\n]\n+\n1\nH_{out} = (H_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1]\n          \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\nH\no\nu\nt\n​\n=\n(\nH\nin\n​\n−\n1\n)\n×\nstride\n[\n1\n]\n−\n2\n×\npadding\n[\n1\n]\n+\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n+\noutput_padding\n[\n1\n]\n+\n1\nW\no\nu\nt\n=\n(\nW\ni\nn\n−\n1\n)\n×\nstride\n[\n2\n]\n−\n2\n×\npadding\n[\n2\n]\n+\ndilation\n[\n2\n]\n×\n(\nkernel_size\n[\n2\n]\n−\n1\n)\n+\noutput_padding\n[\n2\n]\n+\n1\nW_{out} = (W_{in} - 1) \\times \\text{stride}[2] - 2 \\times \\text{padding}[2] + \\text{dilation}[2]\n          \\times (\\text{kernel\\_size}[2] - 1) + \\text{output\\_padding}[2] + 1\nW\no\nu\nt\n​\n=\n(\nW\nin\n​\n−\n1\n)\n×\nstride\n[\n2\n]\n−\n2\n×\npadding\n[\n2\n]\n+\ndilation\n[\n2\n]\n×\n(\nkernel_size\n[\n2\n]\n−\n1\n)\n+\noutput_padding\n[\n2\n]\n+\n1\nVariables\nweight\n(\nTensor\n) – the learnable weights of the module of shape\n(\nin_channels\n,\nout_channels\ngroups\n,\n(\\text{in\\_channels}, \\frac{\\text{out\\_channels}}{\\text{groups}},\n(\nin_channels\n,\ngroups\nout_channels\n​\n,\nkernel_size[0]\n,\nkernel_size[1]\n,\nkernel_size[2]\n)\n\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]}, \\text{kernel\\_size[2]})\nkernel_size[0]\n,\nkernel_size[1]\n,\nkernel_size[2]\n)\n.\nThe values of these weights are sampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nout\n∗\n∏\ni\n=\n0\n2\nkernel_size\n[\ni\n]\nk = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}\nk\n=\nC\nout\n​\n∗\n∏\ni\n=\n0\n2\n​\nkernel_size\n[\ni\n]\ng\nro\nu\np\ns\n​\nbias\n(\nTensor\n) – the learnable bias of the module of shape (out_channels)\nIf\nbias\nis\nTrue\n, then the values of these weights are\nsampled from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\ng\nr\no\nu\np\ns\nC\nout\n∗\n∏\ni\n=\n0\n2\nkernel_size\n[\ni\n]\nk = \\frac{groups}{C_\\text{out} * \\prod_{i=0}^{2}\\text{kernel\\_size}[i]}\nk\n=\nC\nout\n​\n∗\n∏\ni\n=\n0\n2\n​\nkernel_size\n[\ni\n]\ng\nro\nu\np\ns\n​\nExamples:\n>>>\n# With square kernels and equal stride\n>>>\nm\n=\nnn\n.\nConvTranspose3d\n(\n16\n,\n33\n,\n3\n,\nstride\n=\n2\n)\n>>>\n# non-square kernels and unequal stride and with padding\n>>>\nm\n=\nnn\n.\nConvTranspose3d\n(\n16\n,\n33\n,\n(\n3\n,\n5\n,\n2\n),\nstride\n=\n(\n2\n,\n1\n,\n1\n),\npadding\n=\n(\n0\n,\n4\n,\n2\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n10\n,\n50\n,\n100\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#convtranspose3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#ConvTranspose3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L1174",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf",
    "https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyConv1d",
  "page_text": "LazyConv1d\n¶\nclass\ntorch.nn.\nLazyConv1d\n(\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.Conv1d\nmodule with lazy initialization of the\nin_channels\nargument.\nThe\nin_channels\nargument of the\nConv1d\nis inferred from the\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\nand\nbias\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) – Zero-padding added to both sides of\nthe input. Default: 0\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel\nelements. Default: 1\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input\nchannels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the\noutput. Default:\nTrue\npadding_mode\n(\nstr\n,\noptional\n) –\n'zeros'\n,\n'reflect'\n,\n'replicate'\nor\n'circular'\n. Default:\n'zeros'\nSee also\ntorch.nn.Conv1d\nand\ntorch.nn.modules.lazy.LazyModuleMixin\ncls_to_become\n[source]\n¶\nalias of\nConv1d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv1d.html#lazyconv1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#LazyConv1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L1455",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv1d.html#torch.nn.LazyConv1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L214",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv1d.html#torch.nn.LazyConv1d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#torch.nn.Conv1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyConv2d",
  "page_text": "LazyConv2d\n¶\nclass\ntorch.nn.\nLazyConv2d\n(\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.Conv2d\nmodule with lazy initialization of the\nin_channels\nargument.\nThe\nin_channels\nargument of the\nConv2d\nthat is inferred from the\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\nand\nbias\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) – Zero-padding added to both sides of\nthe input. Default: 0\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel\nelements. Default: 1\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input\nchannels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the\noutput. Default:\nTrue\npadding_mode\n(\nstr\n,\noptional\n) –\n'zeros'\n,\n'reflect'\n,\n'replicate'\nor\n'circular'\n. Default:\n'zeros'\nSee also\ntorch.nn.Conv2d\nand\ntorch.nn.modules.lazy.LazyModuleMixin\ncls_to_become\n[source]\n¶\nalias of\nConv2d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv2d.html#lazyconv2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#LazyConv2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L1524",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv2d.html#torch.nn.LazyConv2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L378",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv2d.html#torch.nn.LazyConv2d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyConv3d",
  "page_text": "LazyConv3d\n¶\nclass\ntorch.nn.\nLazyConv3d\n(\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.Conv3d\nmodule with lazy initialization of the\nin_channels\nargument.\nThe\nin_channels\nargument of the\nConv3d\nthat is inferred from\nthe\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\nand\nbias\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) – Zero-padding added to both sides of\nthe input. Default: 0\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel\nelements. Default: 1\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input\nchannels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the\noutput. Default:\nTrue\npadding_mode\n(\nstr\n,\noptional\n) –\n'zeros'\n,\n'reflect'\n,\n'replicate'\nor\n'circular'\n. Default:\n'zeros'\nSee also\ntorch.nn.Conv3d\nand\ntorch.nn.modules.lazy.LazyModuleMixin\ncls_to_become\n[source]\n¶\nalias of\nConv3d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv3d.html#lazyconv3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#LazyConv3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L1593",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv3d.html#torch.nn.LazyConv3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L557",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv3d.html#torch.nn.LazyConv3d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv3d.html#torch.nn.Conv3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyConvTranspose1d",
  "page_text": "LazyConvTranspose1d\n¶\nclass\ntorch.nn.\nLazyConvTranspose1d\n(\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\noutput_padding\n=\n0\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\ndilation\n=\n1\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.ConvTranspose1d\nmodule with lazy initialization of the\nin_channels\nargument.\nThe\nin_channels\nargument of the\nConvTranspose1d\nthat is inferred from\nthe\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\nand\nbias\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) –\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nzero-padding\nwill be added to both sides of the input. Default: 0\noutput_padding\n(\nint\nor\ntuple\n,\noptional\n) – Additional size added to one side\nof the output shape. Default: 0\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input channels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the output. Default:\nTrue\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel elements. Default: 1\nSee also\ntorch.nn.ConvTranspose1d\nand\ntorch.nn.modules.lazy.LazyModuleMixin\ncls_to_become\n[source]\n¶\nalias of\nConvTranspose1d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose1d.html#lazyconvtranspose1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#LazyConvTranspose1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L1663",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose1d.html#torch.nn.LazyConvTranspose1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L822",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose1d.html#torch.nn.LazyConvTranspose1d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConv3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyConvTranspose2d",
  "page_text": "LazyConvTranspose2d\n¶\nclass\ntorch.nn.\nLazyConvTranspose2d\n(\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\noutput_padding\n=\n0\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\ndilation\n=\n1\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.ConvTranspose2d\nmodule with lazy initialization of the\nin_channels\nargument.\nThe\nin_channels\nargument of the\nConvTranspose2d\nis inferred from\nthe\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\nand\nbias\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) –\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nzero-padding\nwill be added to both sides of each dimension in the input. Default: 0\noutput_padding\n(\nint\nor\ntuple\n,\noptional\n) – Additional size added to one side\nof each dimension in the output shape. Default: 0\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input channels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the output. Default:\nTrue\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel elements. Default: 1\nSee also\ntorch.nn.ConvTranspose2d\nand\ntorch.nn.modules.lazy.LazyModuleMixin\ncls_to_become\n[source]\n¶\nalias of\nConvTranspose2d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose2d.html#lazyconvtranspose2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#LazyConvTranspose2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L1732",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose2d.html#torch.nn.LazyConvTranspose2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L986",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose2d.html#torch.nn.LazyConvTranspose2d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyConvTranspose3d",
  "page_text": "LazyConvTranspose3d\n¶\nclass\ntorch.nn.\nLazyConvTranspose3d\n(\nout_channels\n,\nkernel_size\n,\nstride\n=\n1\n,\npadding\n=\n0\n,\noutput_padding\n=\n0\n,\ngroups\n=\n1\n,\nbias\n=\nTrue\n,\ndilation\n=\n1\n,\npadding_mode\n=\n'zeros'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.ConvTranspose3d\nmodule with lazy initialization of the\nin_channels\nargument.\nThe\nin_channels\nargument of the\nConvTranspose3d\nis inferred from\nthe\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\nand\nbias\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nout_channels\n(\nint\n) – Number of channels produced by the convolution\nkernel_size\n(\nint\nor\ntuple\n) – Size of the convolving kernel\nstride\n(\nint\nor\ntuple\n,\noptional\n) – Stride of the convolution. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) –\ndilation\n*\n(kernel_size\n-\n1)\n-\npadding\nzero-padding\nwill be added to both sides of each dimension in the input. Default: 0\noutput_padding\n(\nint\nor\ntuple\n,\noptional\n) – Additional size added to one side\nof each dimension in the output shape. Default: 0\ngroups\n(\nint\n,\noptional\n) – Number of blocked connections from input channels to output channels. Default: 1\nbias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a learnable bias to the output. Default:\nTrue\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – Spacing between kernel elements. Default: 1\nSee also\ntorch.nn.ConvTranspose3d\nand\ntorch.nn.modules.lazy.LazyModuleMixin\ncls_to_become\n[source]\n¶\nalias of\nConvTranspose3d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose3d.html#lazyconvtranspose3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html#LazyConvTranspose3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L1801",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose3d.html#torch.nn.LazyConvTranspose3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/conv.py#L1174",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose3d.html#torch.nn.LazyConvTranspose3d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Unfold",
  "page_text": "Unfold\n¶\nclass\ntorch.nn.\nUnfold\n(\nkernel_size\n,\ndilation\n=\n1\n,\npadding\n=\n0\n,\nstride\n=\n1\n)\n[source]\n[source]\n¶\nExtracts sliding local blocks from a batched input tensor.\nConsider a batched\ninput\ntensor of shape\n(\nN\n,\nC\n,\n∗\n)\n(N, C, *)\n(\nN\n,\nC\n,\n∗\n)\n,\nwhere\nN\nN\nN\nis the batch dimension,\nC\nC\nC\nis the channel dimension,\nand\n∗\n*\n∗\nrepresent arbitrary spatial dimensions. This operation flattens\neach sliding\nkernel_size\n-sized block within the spatial dimensions\nof\ninput\ninto a column (i.e., last dimension) of a 3-D\noutput\ntensor of shape\n(\nN\n,\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\n(N, C \\times \\prod(\\text{kernel\\_size}), L)\n(\nN\n,\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\n, where\nC\n×\n∏\n(\nkernel_size\n)\nC \\times \\prod(\\text{kernel\\_size})\nC\n×\n∏\n(\nkernel_size\n)\nis the total number of values\nwithin each block (a block has\n∏\n(\nkernel_size\n)\n\\prod(\\text{kernel\\_size})\n∏\n(\nkernel_size\n)\nspatial\nlocations each containing a\nC\nC\nC\n-channeled vector), and\nL\nL\nL\nis\nthe total number of such blocks:\nL\n=\n∏\nd\n⌊\nspatial_size\n[\nd\n]\n+\n2\n×\npadding\n[\nd\n]\n−\ndilation\n[\nd\n]\n×\n(\nkernel_size\n[\nd\n]\n−\n1\n)\n−\n1\nstride\n[\nd\n]\n+\n1\n⌋\n,\nL = \\prod_d \\left\\lfloor\\frac{\\text{spatial\\_size}[d] + 2 \\times \\text{padding}[d] %\n    - \\text{dilation}[d] \\times (\\text{kernel\\_size}[d] - 1) - 1}{\\text{stride}[d]} + 1\\right\\rfloor,\nL\n=\nd\n∏\n​\n⌊\nstride\n[\nd\n]\nspatial_size\n[\nd\n]\n+\n2\n×\npadding\n[\nd\n]\n−\ndilation\n[\nd\n]\n×\n(\nkernel_size\n[\nd\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\n,\nwhere\nspatial_size\n\\text{spatial\\_size}\nspatial_size\nis formed by the spatial dimensions\nof\ninput\n(\n∗\n*\n∗\nabove), and\nd\nd\nd\nis over all spatial\ndimensions.\nTherefore, indexing\noutput\nat the last dimension (column dimension)\ngives all values within a certain block.\nThe\npadding\n,\nstride\nand\ndilation\narguments specify\nhow the sliding blocks are retrieved.\nstride\ncontrols the stride for the sliding blocks.\npadding\ncontrols the amount of implicit zero-paddings on both\nsides for\npadding\nnumber of points for each dimension before\nreshaping.\ndilation\ncontrols the spacing between the kernel points; also known as the à trous algorithm.\nIt is harder to describe, but this\nlink\nhas a nice visualization of what\ndilation\ndoes.\nParameters\nkernel_size\n(\nint\nor\ntuple\n) – the size of the sliding blocks\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) – implicit zero padding to be added on\nboth sides of input. Default: 0\nstride\n(\nint\nor\ntuple\n,\noptional\n) – the stride of the sliding blocks in the input\nspatial dimensions. Default: 1\nIf\nkernel_size\n,\ndilation\n,\npadding\nor\nstride\nis an int or a tuple of length 1, their values will be\nreplicated across all spatial dimensions.\nFor the case of two input spatial dimensions this operation is sometimes\ncalled\nim2col\n.\nNote\nFold\ncalculates each combined value in the resulting\nlarge tensor by summing all values from all containing blocks.\nUnfold\nextracts the values in the local blocks by\ncopying from the large tensor. So, if the blocks overlap, they are not\ninverses of each other.\nIn general, folding and unfolding operations are related as\nfollows. Consider\nFold\nand\nUnfold\ninstances created with the same\nparameters:\n>>>\nfold_params\n=\ndict\n(\nkernel_size\n=...\n,\ndilation\n=...\n,\npadding\n=...\n,\nstride\n=...\n)\n>>>\nfold\n=\nnn\n.\nFold\n(\noutput_size\n=...\n,\n**\nfold_params\n)\n>>>\nunfold\n=\nnn\n.\nUnfold\n(\n**\nfold_params\n)\nThen for any (supported)\ninput\ntensor the following\nequality holds:\nfold\n(\nunfold\n(\ninput\n))\n==\ndivisor\n*\ninput\nwhere\ndivisor\nis a tensor that depends only on the shape\nand dtype of the\ninput\n:\n>>>\ninput_ones\n=\ntorch\n.\nones\n(\ninput\n.\nshape\n,\ndtype\n=\ninput\n.\ndtype\n)\n>>>\ndivisor\n=\nfold\n(\nunfold\n(\ninput_ones\n))\nWhen the\ndivisor\ntensor contains no zero elements, then\nfold\nand\nunfold\noperations are inverses of each\nother (up to constant divisor).\nWarning\nCurrently, only 4-D input tensors (batched image-like tensors) are\nsupported.\nShape:\nInput:\n(\nN\n,\nC\n,\n∗\n)\n(N, C, *)\n(\nN\n,\nC\n,\n∗\n)\nOutput:\n(\nN\n,\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\n(N, C \\times \\prod(\\text{kernel\\_size}), L)\n(\nN\n,\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\nas described above\nExamples:\n>>>\nunfold\n=\nnn\n.\nUnfold\n(\nkernel_size\n=\n(\n2\n,\n3\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n5\n,\n3\n,\n4\n)\n>>>\noutput\n=\nunfold\n(\ninput\n)\n>>>\n# each patch contains 30 values (2x3=6 vectors, each of 5 channels)\n>>>\n# 4 blocks (2x3 kernels) in total in the 3x4 input\n>>>\noutput\n.\nsize\n()\ntorch.Size([2, 30, 4])\n>>>\n# Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)\n>>>\ninp\n=\ntorch\n.\nrandn\n(\n1\n,\n3\n,\n10\n,\n12\n)\n>>>\nw\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n,\n4\n,\n5\n)\n>>>\ninp_unf\n=\ntorch\n.\nnn\n.\nfunctional\n.\nunfold\n(\ninp\n,\n(\n4\n,\n5\n))\n>>>\nout_unf\n=\ninp_unf\n.\ntranspose\n(\n1\n,\n2\n)\n.\nmatmul\n(\nw\n.\nview\n(\nw\n.\nsize\n(\n0\n),\n-\n1\n)\n.\nt\n())\n.\ntranspose\n(\n1\n,\n2\n)\n>>>\nout\n=\ntorch\n.\nnn\n.\nfunctional\n.\nfold\n(\nout_unf\n,\n(\n7\n,\n8\n),\n(\n1\n,\n1\n))\n>>>\n# or equivalently (and avoiding a copy),\n>>>\n# out = out_unf.view(1, 2, 7, 8)\n>>>\n(\ntorch\n.\nnn\n.\nfunctional\n.\nconv2d\n(\ninp\n,\nw\n)\n-\nout\n)\n.\nabs\n()\n.\nmax\n()\ntensor(1.9073e-06)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#unfold",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/fold.html#Unfold",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/fold.py#L164",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.Fold.html#torch.nn.Fold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Fold.html#torch.nn.Fold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Fold.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyConvTranspose3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Fold",
  "page_text": "Fold\n¶\nclass\ntorch.nn.\nFold\n(\noutput_size\n,\nkernel_size\n,\ndilation\n=\n1\n,\npadding\n=\n0\n,\nstride\n=\n1\n)\n[source]\n[source]\n¶\nCombines an array of sliding local blocks into a large containing tensor.\nConsider a batched\ninput\ntensor containing sliding local blocks,\ne.g., patches of images, of shape\n(\nN\n,\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\n(N, C \\times  \\prod(\\text{kernel\\_size}), L)\n(\nN\n,\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\n,\nwhere\nN\nN\nN\nis batch dimension,\nC\n×\n∏\n(\nkernel_size\n)\nC \\times \\prod(\\text{kernel\\_size})\nC\n×\n∏\n(\nkernel_size\n)\nis the number of values within a block (a block has\n∏\n(\nkernel_size\n)\n\\prod(\\text{kernel\\_size})\n∏\n(\nkernel_size\n)\nspatial locations each containing a\nC\nC\nC\n-channeled vector), and\nL\nL\nL\nis the total number of blocks. (This is exactly the\nsame specification as the output shape of\nUnfold\n.) This\noperation combines these local blocks into the large\noutput\ntensor\nof shape\n(\nN\n,\nC\n,\noutput_size\n[\n0\n]\n,\noutput_size\n[\n1\n]\n,\n…\n)\n(N, C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)\n(\nN\n,\nC\n,\noutput_size\n[\n0\n]\n,\noutput_size\n[\n1\n]\n,\n…\n)\nby summing the overlapping values. Similar to\nUnfold\n, the\narguments must satisfy\nL\n=\n∏\nd\n⌊\noutput_size\n[\nd\n]\n+\n2\n×\npadding\n[\nd\n]\n−\ndilation\n[\nd\n]\n×\n(\nkernel_size\n[\nd\n]\n−\n1\n)\n−\n1\nstride\n[\nd\n]\n+\n1\n⌋\n,\nL = \\prod_d \\left\\lfloor\\frac{\\text{output\\_size}[d] + 2 \\times \\text{padding}[d] %\n    - \\text{dilation}[d] \\times (\\text{kernel\\_size}[d] - 1) - 1}{\\text{stride}[d]} + 1\\right\\rfloor,\nL\n=\nd\n∏\n​\n⌊\nstride\n[\nd\n]\noutput_size\n[\nd\n]\n+\n2\n×\npadding\n[\nd\n]\n−\ndilation\n[\nd\n]\n×\n(\nkernel_size\n[\nd\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\n,\nwhere\nd\nd\nd\nis over all spatial dimensions.\noutput_size\ndescribes the spatial shape of the large containing\ntensor of the sliding local blocks. It is useful to resolve the ambiguity\nwhen multiple input shapes map to same number of sliding blocks, e.g.,\nwith\nstride\n>\n0\n.\nThe\npadding\n,\nstride\nand\ndilation\narguments specify\nhow the sliding blocks are retrieved.\nstride\ncontrols the stride for the sliding blocks.\npadding\ncontrols the amount of implicit zero-paddings on both\nsides for\npadding\nnumber of points for each dimension before\nreshaping.\ndilation\ncontrols the spacing between the kernel points; also known as the à trous algorithm.\nIt is harder to describe, but this\nlink\nhas a nice visualization of what\ndilation\ndoes.\nParameters\noutput_size\n(\nint\nor\ntuple\n) – the shape of the spatial dimensions of the\noutput (i.e.,\noutput.sizes()[2:]\n)\nkernel_size\n(\nint\nor\ntuple\n) – the size of the sliding blocks\ndilation\n(\nint\nor\ntuple\n,\noptional\n) – a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1\npadding\n(\nint\nor\ntuple\n,\noptional\n) – implicit zero padding to be added on\nboth sides of input. Default: 0\nstride\n(\nint\nor\ntuple\n) – the stride of the sliding blocks in the input\nspatial dimensions. Default: 1\nIf\noutput_size\n,\nkernel_size\n,\ndilation\n,\npadding\nor\nstride\nis an int or a tuple of length 1 then\ntheir values will be replicated across all spatial dimensions.\nFor the case of two output spatial dimensions this operation is sometimes\ncalled\ncol2im\n.\nNote\nFold\ncalculates each combined value in the resulting\nlarge tensor by summing all values from all containing blocks.\nUnfold\nextracts the values in the local blocks by\ncopying from the large tensor. So, if the blocks overlap, they are not\ninverses of each other.\nIn general, folding and unfolding operations are related as\nfollows. Consider\nFold\nand\nUnfold\ninstances created with the same\nparameters:\n>>>\nfold_params\n=\ndict\n(\nkernel_size\n=...\n,\ndilation\n=...\n,\npadding\n=...\n,\nstride\n=...\n)\n>>>\nfold\n=\nnn\n.\nFold\n(\noutput_size\n=...\n,\n**\nfold_params\n)\n>>>\nunfold\n=\nnn\n.\nUnfold\n(\n**\nfold_params\n)\nThen for any (supported)\ninput\ntensor the following\nequality holds:\nfold\n(\nunfold\n(\ninput\n))\n==\ndivisor\n*\ninput\nwhere\ndivisor\nis a tensor that depends only on the shape\nand dtype of the\ninput\n:\n>>>\ninput_ones\n=\ntorch\n.\nones\n(\ninput\n.\nshape\n,\ndtype\n=\ninput\n.\ndtype\n)\n>>>\ndivisor\n=\nfold\n(\nunfold\n(\ninput_ones\n))\nWhen the\ndivisor\ntensor contains no zero elements, then\nfold\nand\nunfold\noperations are inverses of each\nother (up to constant divisor).\nWarning\nCurrently, only unbatched (3D) or batched (4D) image-like output tensors are supported.\nShape:\nInput:\n(\nN\n,\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\n(N, C \\times \\prod(\\text{kernel\\_size}), L)\n(\nN\n,\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\nor\n(\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\n(C \\times \\prod(\\text{kernel\\_size}), L)\n(\nC\n×\n∏\n(\nkernel_size\n)\n,\nL\n)\nOutput:\n(\nN\n,\nC\n,\noutput_size\n[\n0\n]\n,\noutput_size\n[\n1\n]\n,\n…\n)\n(N, C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)\n(\nN\n,\nC\n,\noutput_size\n[\n0\n]\n,\noutput_size\n[\n1\n]\n,\n…\n)\nor\n(\nC\n,\noutput_size\n[\n0\n]\n,\noutput_size\n[\n1\n]\n,\n…\n)\n(C, \\text{output\\_size}[0], \\text{output\\_size}[1], \\dots)\n(\nC\n,\noutput_size\n[\n0\n]\n,\noutput_size\n[\n1\n]\n,\n…\n)\nas described above\nExamples:\n>>>\nfold\n=\nnn\n.\nFold\n(\noutput_size\n=\n(\n4\n,\n5\n),\nkernel_size\n=\n(\n2\n,\n2\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n3\n*\n2\n*\n2\n,\n12\n)\n>>>\noutput\n=\nfold\n(\ninput\n)\n>>>\noutput\n.\nsize\n()\ntorch.Size([1, 3, 4, 5])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Fold.html#fold",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/fold.html#Fold",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/fold.py#L11",
    "https://pytorch.org/docs/stable/generated/torch.nn.Fold.html#torch.nn.Fold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.Fold.html#torch.nn.Fold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Fold.html#torch.nn.Fold",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html#torch.nn.Unfold",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unfold.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MaxPool1d",
  "page_text": "MaxPool1d\n¶\nclass\ntorch.nn.\nMaxPool1d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\nreturn_indices\n=\nFalse\n,\nceil_mode\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 1D max pooling over an input signal composed of several input planes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\nand output\n(\nN\n,\nC\n,\nL\no\nu\nt\n)\n(N, C, L_{out})\n(\nN\n,\nC\n,\nL\no\nu\nt\n​\n)\ncan be precisely described as:\no\nu\nt\n(\nN\ni\n,\nC\nj\n,\nk\n)\n=\nmax\n⁡\nm\n=\n0\n,\n…\n,\nkernel_size\n−\n1\ni\nn\np\nu\nt\n(\nN\ni\n,\nC\nj\n,\ns\nt\nr\ni\nd\ne\n×\nk\n+\nm\n)\nout(N_i, C_j, k) = \\max_{m=0, \\ldots, \\text{kernel\\_size} - 1}\n        input(N_i, C_j, stride \\times k + m)\no\nu\nt\n(\nN\ni\n​\n,\nC\nj\n​\n,\nk\n)\n=\nm\n=\n0\n,\n…\n,\nkernel_size\n−\n1\nmax\n​\nin\np\nu\nt\n(\nN\ni\n​\n,\nC\nj\n​\n,\ns\nt\nr\ni\nd\ne\n×\nk\n+\nm\n)\nIf\npadding\nis non-zero, then the input is implicitly padded with negative infinity on both sides\nfor\npadding\nnumber of points.\ndilation\nis the stride between the elements within the\nsliding window. This\nlink\nhas a nice visualization of the pooling parameters.\nNote\nWhen ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\nor the input. Sliding windows that would start in the right padded region are ignored.\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – The size of the sliding window, must be > 0.\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – The stride of the sliding window, must be > 0. Default value is\nkernel_size\n.\npadding\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.\ndilation\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – The stride between elements within a sliding window, must be > 0.\nreturn_indices\n(\nbool\n) – If\nTrue\n, will return the argmax along with the max values.\nUseful for\ntorch.nn.MaxUnpool1d\nlater\nceil_mode\n(\nbool\n) – If\nTrue\n, will use\nceil\ninstead of\nfloor\nto compute the output shape. This\nensures that every element in the input tensor is covered by a sliding window.\nShape:\nInput:\n(\nN\n,\nC\n,\nL\ni\nn\n)\n(N, C, L_{in})\n(\nN\n,\nC\n,\nL\nin\n​\n)\nor\n(\nC\n,\nL\ni\nn\n)\n(C, L_{in})\n(\nC\n,\nL\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nL\no\nu\nt\n)\n(N, C, L_{out})\n(\nN\n,\nC\n,\nL\no\nu\nt\n​\n)\nor\n(\nC\n,\nL\no\nu\nt\n)\n(C, L_{out})\n(\nC\n,\nL\no\nu\nt\n​\n)\n, where\nL\no\nu\nt\n=\n⌊\nL\ni\nn\n+\n2\n×\npadding\n−\ndilation\n×\n(\nkernel_size\n−\n1\n)\n−\n1\nstride\n+\n1\n⌋\nL_{out} = \\left\\lfloor \\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n      \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\nL\no\nu\nt\n​\n=\n⌊\nstride\nL\nin\n​\n+\n2\n×\npadding\n−\ndilation\n×\n(\nkernel_size\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nExamples:\n>>>\n# pool of size=3, stride=2\n>>>\nm\n=\nnn\n.\nMaxPool1d\n(\n3\n,\nstride\n=\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#maxpool1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#MaxPool1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L81",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool1d.html#torch.nn.MaxUnpool1d",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Fold.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MaxPool2d",
  "page_text": "MaxPool2d\n¶\nclass\ntorch.nn.\nMaxPool2d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\nreturn_indices\n=\nFalse\n,\nceil_mode\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 2D max pooling over an input signal composed of several input planes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\n,\noutput\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nand\nkernel_size\n(\nk\nH\n,\nk\nW\n)\n(kH, kW)\n(\nk\nH\n,\nkW\n)\ncan be precisely described as:\no\nu\nt\n(\nN\ni\n,\nC\nj\n,\nh\n,\nw\n)\n=\nmax\n⁡\nm\n=\n0\n,\n…\n,\nk\nH\n−\n1\nmax\n⁡\nn\n=\n0\n,\n…\n,\nk\nW\n−\n1\ninput\n(\nN\ni\n,\nC\nj\n,\nstride[0]\n×\nh\n+\nm\n,\nstride[1]\n×\nw\n+\nn\n)\n\\begin{aligned}\n    out(N_i, C_j, h, w) ={} & \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\\n                            & \\text{input}(N_i, C_j, \\text{stride[0]} \\times h + m,\n                                           \\text{stride[1]} \\times w + n)\n\\end{aligned}\no\nu\nt\n(\nN\ni\n​\n,\nC\nj\n​\n,\nh\n,\nw\n)\n=\n​\nm\n=\n0\n,\n…\n,\nk\nH\n−\n1\nmax\n​\nn\n=\n0\n,\n…\n,\nkW\n−\n1\nmax\n​\ninput\n(\nN\ni\n​\n,\nC\nj\n​\n,\nstride[0]\n×\nh\n+\nm\n,\nstride[1]\n×\nw\n+\nn\n)\n​\nIf\npadding\nis non-zero, then the input is implicitly padded with negative infinity on both sides\nfor\npadding\nnumber of points.\ndilation\ncontrols the spacing between the kernel points.\nIt is harder to describe, but this\nlink\nhas a nice visualization of what\ndilation\ndoes.\nNote\nWhen ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\nor the input. Sliding windows that would start in the right padded region are ignored.\nThe parameters\nkernel_size\n,\nstride\n,\npadding\n,\ndilation\ncan either be:\na single\nint\n– in which case the same value is used for the height and width dimension\na\ntuple\nof two ints – in which case, the first\nint\nis used for the height dimension,\nand the second\nint\nfor the width dimension\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – the size of the window to take a max over\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – the stride of the window. Default value is\nkernel_size\npadding\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – Implicit negative infinity padding to be added on both sides\ndilation\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – a parameter that controls the stride of elements in the window\nreturn_indices\n(\nbool\n) – if\nTrue\n, will return the max indices along with the outputs.\nUseful for\ntorch.nn.MaxUnpool2d\nlater\nceil_mode\n(\nbool\n) – when True, will use\nceil\ninstead of\nfloor\nto compute the output shape\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n+\n2\n∗\npadding[0]\n−\ndilation[0]\n×\n(\nkernel_size[0]\n−\n1\n)\n−\n1\nstride[0]\n+\n1\n⌋\nH_{out} = \\left\\lfloor\\frac{H_{in} + 2 * \\text{padding[0]} - \\text{dilation[0]}\n      \\times (\\text{kernel\\_size[0]} - 1) - 1}{\\text{stride[0]}} + 1\\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nstride[0]\nH\nin\n​\n+\n2\n∗\npadding[0]\n−\ndilation[0]\n×\n(\nkernel_size[0]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n+\n2\n∗\npadding[1]\n−\ndilation[1]\n×\n(\nkernel_size[1]\n−\n1\n)\n−\n1\nstride[1]\n+\n1\n⌋\nW_{out} = \\left\\lfloor\\frac{W_{in} + 2 * \\text{padding[1]} - \\text{dilation[1]}\n      \\times (\\text{kernel\\_size[1]} - 1) - 1}{\\text{stride[1]}} + 1\\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nstride[1]\nW\nin\n​\n+\n2\n∗\npadding[1]\n−\ndilation[1]\n×\n(\nkernel_size[1]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nExamples:\n>>>\n# pool of square window of size=3, stride=2\n>>>\nm\n=\nnn\n.\nMaxPool2d\n(\n3\n,\nstride\n=\n2\n)\n>>>\n# pool of non-square window\n>>>\nm\n=\nnn\n.\nMaxPool2d\n((\n3\n,\n2\n),\nstride\n=\n(\n2\n,\n1\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n32\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#maxpool2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#MaxPool2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L145",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MaxPool3d",
  "page_text": "MaxPool3d\n¶\nclass\ntorch.nn.\nMaxPool3d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n,\ndilation\n=\n1\n,\nreturn_indices\n=\nFalse\n,\nceil_mode\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 3D max pooling over an input signal composed of several input planes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n,\noutput\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nand\nkernel_size\n(\nk\nD\n,\nk\nH\n,\nk\nW\n)\n(kD, kH, kW)\n(\nk\nD\n,\nk\nH\n,\nkW\n)\ncan be precisely described as:\nout\n(\nN\ni\n,\nC\nj\n,\nd\n,\nh\n,\nw\n)\n=\nmax\n⁡\nk\n=\n0\n,\n…\n,\nk\nD\n−\n1\nmax\n⁡\nm\n=\n0\n,\n…\n,\nk\nH\n−\n1\nmax\n⁡\nn\n=\n0\n,\n…\n,\nk\nW\n−\n1\ninput\n(\nN\ni\n,\nC\nj\n,\nstride[0]\n×\nd\n+\nk\n,\nstride[1]\n×\nh\n+\nm\n,\nstride[2]\n×\nw\n+\nn\n)\n\\begin{aligned}\n    \\text{out}(N_i, C_j, d, h, w) ={} & \\max_{k=0, \\ldots, kD-1} \\max_{m=0, \\ldots, kH-1} \\max_{n=0, \\ldots, kW-1} \\\\\n                                      & \\text{input}(N_i, C_j, \\text{stride[0]} \\times d + k,\n                                                     \\text{stride[1]} \\times h + m, \\text{stride[2]} \\times w + n)\n\\end{aligned}\nout\n(\nN\ni\n​\n,\nC\nj\n​\n,\nd\n,\nh\n,\nw\n)\n=\n​\nk\n=\n0\n,\n…\n,\nk\nD\n−\n1\nmax\n​\nm\n=\n0\n,\n…\n,\nk\nH\n−\n1\nmax\n​\nn\n=\n0\n,\n…\n,\nkW\n−\n1\nmax\n​\ninput\n(\nN\ni\n​\n,\nC\nj\n​\n,\nstride[0]\n×\nd\n+\nk\n,\nstride[1]\n×\nh\n+\nm\n,\nstride[2]\n×\nw\n+\nn\n)\n​\nIf\npadding\nis non-zero, then the input is implicitly padded with negative infinity on both sides\nfor\npadding\nnumber of points.\ndilation\ncontrols the spacing between the kernel points.\nIt is harder to describe, but this\nlink\nhas a nice visualization of what\ndilation\ndoes.\nNote\nWhen ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\nor the input. Sliding windows that would start in the right padded region are ignored.\nThe parameters\nkernel_size\n,\nstride\n,\npadding\n,\ndilation\ncan either be:\na single\nint\n– in which case the same value is used for the depth, height and width dimension\na\ntuple\nof three ints – in which case, the first\nint\nis used for the depth dimension,\nthe second\nint\nfor the height dimension and the third\nint\nfor the width dimension\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – the size of the window to take a max over\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – the stride of the window. Default value is\nkernel_size\npadding\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – Implicit negative infinity padding to be added on all three sides\ndilation\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – a parameter that controls the stride of elements in the window\nreturn_indices\n(\nbool\n) – if\nTrue\n, will return the max indices along with the outputs.\nUseful for\ntorch.nn.MaxUnpool3d\nlater\nceil_mode\n(\nbool\n) – when True, will use\nceil\ninstead of\nfloor\nto compute the output shape\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nD\no\nu\nt\n=\n⌊\nD\ni\nn\n+\n2\n×\npadding\n[\n0\n]\n−\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n−\n1\nstride\n[\n0\n]\n+\n1\n⌋\nD_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times\n  (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\nD\no\nu\nt\n​\n=\n⌊\nstride\n[\n0\n]\nD\nin\n​\n+\n2\n×\npadding\n[\n0\n]\n−\ndilation\n[\n0\n]\n×\n(\nkernel_size\n[\n0\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n+\n2\n×\npadding\n[\n1\n]\n−\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n−\n1\nstride\n[\n1\n]\n+\n1\n⌋\nH_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times\n  (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nstride\n[\n1\n]\nH\nin\n​\n+\n2\n×\npadding\n[\n1\n]\n−\ndilation\n[\n1\n]\n×\n(\nkernel_size\n[\n1\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n+\n2\n×\npadding\n[\n2\n]\n−\ndilation\n[\n2\n]\n×\n(\nkernel_size\n[\n2\n]\n−\n1\n)\n−\n1\nstride\n[\n2\n]\n+\n1\n⌋\nW_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] - \\text{dilation}[2] \\times\n  (\\text{kernel\\_size}[2] - 1) - 1}{\\text{stride}[2]} + 1\\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nstride\n[\n2\n]\nW\nin\n​\n+\n2\n×\npadding\n[\n2\n]\n−\ndilation\n[\n2\n]\n×\n(\nkernel_size\n[\n2\n]\n−\n1\n)\n−\n1\n​\n+\n1\n⌋\nExamples:\n>>>\n# pool of square window of size=3, stride=2\n>>>\nm\n=\nnn\n.\nMaxPool3d\n(\n3\n,\nstride\n=\n2\n)\n>>>\n# pool of non-square window\n>>>\nm\n=\nnn\n.\nMaxPool3d\n((\n3\n,\n2\n,\n2\n),\nstride\n=\n(\n2\n,\n1\n,\n2\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n44\n,\n31\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html#maxpool3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#MaxPool3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L224",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html#torch.nn.MaxPool3d",
    "https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool3d.html#torch.nn.MaxUnpool3d",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MaxUnpool1d",
  "page_text": "MaxUnpool1d\n¶\nclass\ntorch.nn.\nMaxUnpool1d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n)\n[source]\n[source]\n¶\nComputes a partial inverse of\nMaxPool1d\n.\nMaxPool1d\nis not fully invertible, since the non-maximal values are lost.\nMaxUnpool1d\ntakes in as input the output of\nMaxPool1d\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\nNote\nThis operation may behave nondeterministically when the input indices has repeat values.\nSee\nhttps://github.com/pytorch/pytorch/issues/80827\nand\nReproducibility\nfor more information.\nNote\nMaxPool1d\ncan map several input sizes to the same output\nsizes. Hence, the inversion process can get ambiguous.\nTo accommodate this, you can provide the needed output size\nas an additional argument\noutput_size\nin the forward call.\nSee the Inputs and Example below.\nParameters\nkernel_size\n(\nint\nor\ntuple\n) – Size of the max pooling window.\nstride\n(\nint\nor\ntuple\n) – Stride of the max pooling window.\nIt is set to\nkernel_size\nby default.\npadding\n(\nint\nor\ntuple\n) – Padding that was added to the input\nInputs:\ninput\n: the input Tensor to invert\nindices\n: the indices given out by\nMaxPool1d\noutput_size\n(optional): the targeted output size\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n)\n(N, C, H_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n)\n(C, H_{in})\n(\nC\n,\nH\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n)\n(N, C, H_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n)\n(C, H_{out})\n(\nC\n,\nH\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\n(\nH\ni\nn\n−\n1\n)\n×\nstride\n[\n0\n]\n−\n2\n×\npadding\n[\n0\n]\n+\nkernel_size\n[\n0\n]\nH_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{kernel\\_size}[0]\nH\no\nu\nt\n​\n=\n(\nH\nin\n​\n−\n1\n)\n×\nstride\n[\n0\n]\n−\n2\n×\npadding\n[\n0\n]\n+\nkernel_size\n[\n0\n]\nor as given by\noutput_size\nin the call operator\nExample:\n>>>\npool\n=\nnn\n.\nMaxPool1d\n(\n2\n,\nstride\n=\n2\n,\nreturn_indices\n=\nTrue\n)\n>>>\nunpool\n=\nnn\n.\nMaxUnpool1d\n(\n2\n,\nstride\n=\n2\n)\n>>>\ninput\n=\ntorch\n.\ntensor\n([[[\n1.\n,\n2\n,\n3\n,\n4\n,\n5\n,\n6\n,\n7\n,\n8\n]]])\n>>>\noutput\n,\nindices\n=\npool\n(\ninput\n)\n>>>\nunpool\n(\noutput\n,\nindices\n)\ntensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])\n>>>\n# Example showcasing the use of output_size\n>>>\ninput\n=\ntorch\n.\ntensor\n([[[\n1.\n,\n2\n,\n3\n,\n4\n,\n5\n,\n6\n,\n7\n,\n8\n,\n9\n]]])\n>>>\noutput\n,\nindices\n=\npool\n(\ninput\n)\n>>>\nunpool\n(\noutput\n,\nindices\n,\noutput_size\n=\ninput\n.\nsize\n())\ntensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.,  0.]]])\n>>>\nunpool\n(\noutput\n,\nindices\n)\ntensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool1d.html#maxunpool1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#MaxUnpool1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L312",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool1d.html#torch.nn.MaxUnpool1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool1d.html#torch.nn.MaxUnpool1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d",
    "https://github.com/pytorch/pytorch/issues/80827",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MaxUnpool2d",
  "page_text": "MaxUnpool2d\n¶\nclass\ntorch.nn.\nMaxUnpool2d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n)\n[source]\n[source]\n¶\nComputes a partial inverse of\nMaxPool2d\n.\nMaxPool2d\nis not fully invertible, since the non-maximal values are lost.\nMaxUnpool2d\ntakes in as input the output of\nMaxPool2d\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\nNote\nThis operation may behave nondeterministically when the input indices has repeat values.\nSee\nhttps://github.com/pytorch/pytorch/issues/80827\nand\nReproducibility\nfor more information.\nNote\nMaxPool2d\ncan map several input sizes to the same output\nsizes. Hence, the inversion process can get ambiguous.\nTo accommodate this, you can provide the needed output size\nas an additional argument\noutput_size\nin the forward call.\nSee the Inputs and Example below.\nParameters\nkernel_size\n(\nint\nor\ntuple\n) – Size of the max pooling window.\nstride\n(\nint\nor\ntuple\n) – Stride of the max pooling window.\nIt is set to\nkernel_size\nby default.\npadding\n(\nint\nor\ntuple\n) – Padding that was added to the input\nInputs:\ninput\n: the input Tensor to invert\nindices\n: the indices given out by\nMaxPool2d\noutput_size\n(optional): the targeted output size\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\n(\nH\ni\nn\n−\n1\n)\n×\nstride[0]\n−\n2\n×\npadding[0]\n+\nkernel_size[0]\nH_{out} = (H_{in} - 1) \\times \\text{stride[0]} - 2 \\times \\text{padding[0]} + \\text{kernel\\_size[0]}\nH\no\nu\nt\n​\n=\n(\nH\nin\n​\n−\n1\n)\n×\nstride[0]\n−\n2\n×\npadding[0]\n+\nkernel_size[0]\nW\no\nu\nt\n=\n(\nW\ni\nn\n−\n1\n)\n×\nstride[1]\n−\n2\n×\npadding[1]\n+\nkernel_size[1]\nW_{out} = (W_{in} - 1) \\times \\text{stride[1]} - 2 \\times \\text{padding[1]} + \\text{kernel\\_size[1]}\nW\no\nu\nt\n​\n=\n(\nW\nin\n​\n−\n1\n)\n×\nstride[1]\n−\n2\n×\npadding[1]\n+\nkernel_size[1]\nor as given by\noutput_size\nin the call operator\nExample:\n>>>\npool\n=\nnn\n.\nMaxPool2d\n(\n2\n,\nstride\n=\n2\n,\nreturn_indices\n=\nTrue\n)\n>>>\nunpool\n=\nnn\n.\nMaxUnpool2d\n(\n2\n,\nstride\n=\n2\n)\n>>>\ninput\n=\ntorch\n.\ntensor\n([[[[\n1.\n,\n2.\n,\n3.\n,\n4.\n],\n[ 5.,  6.,  7.,  8.],\n[ 9., 10., 11., 12.],\n[13., 14., 15., 16.]]]])\n>>>\noutput\n,\nindices\n=\npool\n(\ninput\n)\n>>>\nunpool\n(\noutput\n,\nindices\n)\ntensor([[[[  0.,   0.,   0.,   0.],\n[  0.,   6.,   0.,   8.],\n[  0.,   0.,   0.,   0.],\n[  0.,  14.,   0.,  16.]]]])\n>>>\n# Now using output_size to resolve an ambiguous size for the inverse\n>>>\ninput\n=\ntorch\n.\ntensor\n([[[[\n1.\n,\n2.\n,\n3.\n,\n4.\n,\n5.\n],\n[ 6.,  7.,  8.,  9., 10.],\n[11., 12., 13., 14., 15.],\n[16., 17., 18., 19., 20.]]]])\n>>>\noutput\n,\nindices\n=\npool\n(\ninput\n)\n>>>\n# This call will not work without specifying output_size\n>>>\nunpool\n(\noutput\n,\nindices\n,\noutput_size\n=\ninput\n.\nsize\n())\ntensor([[[[ 0.,  0.,  0.,  0.,  0.],\n[ 0.,  7.,  0.,  9.,  0.],\n[ 0.,  0.,  0.,  0.,  0.],\n[ 0., 17.,  0., 19.,  0.]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#maxunpool2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#MaxUnpool2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L394",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d",
    "https://github.com/pytorch/pytorch/issues/80827",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MaxUnpool3d",
  "page_text": "MaxUnpool3d\n¶\nclass\ntorch.nn.\nMaxUnpool3d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n)\n[source]\n[source]\n¶\nComputes a partial inverse of\nMaxPool3d\n.\nMaxPool3d\nis not fully invertible, since the non-maximal values are lost.\nMaxUnpool3d\ntakes in as input the output of\nMaxPool3d\nincluding the indices of the maximal values and computes a partial inverse\nin which all non-maximal values are set to zero.\nNote\nThis operation may behave nondeterministically when the input indices has repeat values.\nSee\nhttps://github.com/pytorch/pytorch/issues/80827\nand\nReproducibility\nfor more information.\nNote\nMaxPool3d\ncan map several input sizes to the same output\nsizes. Hence, the inversion process can get ambiguous.\nTo accommodate this, you can provide the needed output size\nas an additional argument\noutput_size\nin the forward call.\nSee the Inputs section below.\nParameters\nkernel_size\n(\nint\nor\ntuple\n) – Size of the max pooling window.\nstride\n(\nint\nor\ntuple\n) – Stride of the max pooling window.\nIt is set to\nkernel_size\nby default.\npadding\n(\nint\nor\ntuple\n) – Padding that was added to the input\nInputs:\ninput\n: the input Tensor to invert\nindices\n: the indices given out by\nMaxPool3d\noutput_size\n(optional): the targeted output size\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nD\no\nu\nt\n=\n(\nD\ni\nn\n−\n1\n)\n×\nstride[0]\n−\n2\n×\npadding[0]\n+\nkernel_size[0]\nD_{out} = (D_{in} - 1) \\times \\text{stride[0]} - 2 \\times \\text{padding[0]} + \\text{kernel\\_size[0]}\nD\no\nu\nt\n​\n=\n(\nD\nin\n​\n−\n1\n)\n×\nstride[0]\n−\n2\n×\npadding[0]\n+\nkernel_size[0]\nH\no\nu\nt\n=\n(\nH\ni\nn\n−\n1\n)\n×\nstride[1]\n−\n2\n×\npadding[1]\n+\nkernel_size[1]\nH_{out} = (H_{in} - 1) \\times \\text{stride[1]} - 2 \\times \\text{padding[1]} + \\text{kernel\\_size[1]}\nH\no\nu\nt\n​\n=\n(\nH\nin\n​\n−\n1\n)\n×\nstride[1]\n−\n2\n×\npadding[1]\n+\nkernel_size[1]\nW\no\nu\nt\n=\n(\nW\ni\nn\n−\n1\n)\n×\nstride[2]\n−\n2\n×\npadding[2]\n+\nkernel_size[2]\nW_{out} = (W_{in} - 1) \\times \\text{stride[2]} - 2 \\times \\text{padding[2]} + \\text{kernel\\_size[2]}\nW\no\nu\nt\n​\n=\n(\nW\nin\n​\n−\n1\n)\n×\nstride[2]\n−\n2\n×\npadding[2]\n+\nkernel_size[2]\nor as given by\noutput_size\nin the call operator\nExample:\n>>>\n# pool of square window of size=3, stride=2\n>>>\npool\n=\nnn\n.\nMaxPool3d\n(\n3\n,\nstride\n=\n2\n,\nreturn_indices\n=\nTrue\n)\n>>>\nunpool\n=\nnn\n.\nMaxUnpool3d\n(\n3\n,\nstride\n=\n2\n)\n>>>\noutput\n,\nindices\n=\npool\n(\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n51\n,\n33\n,\n15\n))\n>>>\nunpooled_output\n=\nunpool\n(\noutput\n,\nindices\n)\n>>>\nunpooled_output\n.\nsize\n()\ntorch.Size([20, 16, 51, 33, 15])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool3d.html#maxunpool3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#MaxUnpool3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L489",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool3d.html#torch.nn.MaxUnpool3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html#torch.nn.MaxPool3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html#torch.nn.MaxPool3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool3d.html#torch.nn.MaxUnpool3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html#torch.nn.MaxPool3d",
    "https://github.com/pytorch/pytorch/issues/80827",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html#torch.nn.MaxPool3d",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool3d.html#torch.nn.MaxPool3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AvgPool1d",
  "page_text": "AvgPool1d\n¶\nclass\ntorch.nn.\nAvgPool1d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n,\nceil_mode\n=\nFalse\n,\ncount_include_pad\n=\nTrue\n)\n[source]\n[source]\n¶\nApplies a 1D average pooling over an input signal composed of several input planes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\n,\noutput\n(\nN\n,\nC\n,\nL\no\nu\nt\n)\n(N, C, L_{out})\n(\nN\n,\nC\n,\nL\no\nu\nt\n​\n)\nand\nkernel_size\nk\nk\nk\ncan be precisely described as:\nout\n(\nN\ni\n,\nC\nj\n,\nl\n)\n=\n1\nk\n∑\nm\n=\n0\nk\n−\n1\ninput\n(\nN\ni\n,\nC\nj\n,\nstride\n×\nl\n+\nm\n)\n\\text{out}(N_i, C_j, l) = \\frac{1}{k} \\sum_{m=0}^{k-1}\n                       \\text{input}(N_i, C_j, \\text{stride} \\times l + m)\nout\n(\nN\ni\n​\n,\nC\nj\n​\n,\nl\n)\n=\nk\n1\n​\nm\n=\n0\n∑\nk\n−\n1\n​\ninput\n(\nN\ni\n​\n,\nC\nj\n​\n,\nstride\n×\nl\n+\nm\n)\nIf\npadding\nis non-zero, then the input is implicitly zero-padded on both sides\nfor\npadding\nnumber of points.\nNote\nWhen ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\nor the input. Sliding windows that would start in the right padded region are ignored.\nThe parameters\nkernel_size\n,\nstride\n,\npadding\ncan each be\nan\nint\nor a one-element tuple.\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – the size of the window\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – the stride of the window. Default value is\nkernel_size\npadding\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – implicit zero padding to be added on both sides\nceil_mode\n(\nbool\n) – when True, will use\nceil\ninstead of\nfloor\nto compute the output shape\ncount_include_pad\n(\nbool\n) – when True, will include the zero-padding in the averaging calculation\nShape:\nInput:\n(\nN\n,\nC\n,\nL\ni\nn\n)\n(N, C, L_{in})\n(\nN\n,\nC\n,\nL\nin\n​\n)\nor\n(\nC\n,\nL\ni\nn\n)\n(C, L_{in})\n(\nC\n,\nL\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nL\no\nu\nt\n)\n(N, C, L_{out})\n(\nN\n,\nC\n,\nL\no\nu\nt\n​\n)\nor\n(\nC\n,\nL\no\nu\nt\n)\n(C, L_{out})\n(\nC\n,\nL\no\nu\nt\n​\n)\n, where\nL\no\nu\nt\n=\n⌊\nL\ni\nn\n+\n2\n×\npadding\n−\nkernel_size\nstride\n+\n1\n⌋\nL_{out} = \\left\\lfloor \\frac{L_{in} +\n2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} + 1\\right\\rfloor\nL\no\nu\nt\n​\n=\n⌊\nstride\nL\nin\n​\n+\n2\n×\npadding\n−\nkernel_size\n​\n+\n1\n⌋\nPer the note above, if\nceil_mode\nis True and\n(\nL\no\nu\nt\n−\n1\n)\n×\nstride\n≥\nL\ni\nn\n+\npadding\n(L_{out} - 1) \\times \\text{stride} \\geq L_{in}\n+ \\text{padding}\n(\nL\no\nu\nt\n​\n−\n1\n)\n×\nstride\n≥\nL\nin\n​\n+\npadding\n, we skip the last window as it would start in the right padded region, resulting in\nL\no\nu\nt\nL_{out}\nL\no\nu\nt\n​\nbeing reduced by one.\nExamples:\n>>>\n# pool with window of size=3, stride=2\n>>>\nm\n=\nnn\n.\nAvgPool1d\n(\n3\n,\nstride\n=\n2\n)\n>>>\nm\n(\ntorch\n.\ntensor\n([[[\n1.\n,\n2\n,\n3\n,\n4\n,\n5\n,\n6\n,\n7\n]]]))\ntensor([[[2., 4., 6.]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool1d.html#avgpool1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AvgPool1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L580",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool1d.html#torch.nn.AvgPool1d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AvgPool2d",
  "page_text": "AvgPool2d\n¶\nclass\ntorch.nn.\nAvgPool2d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n,\nceil_mode\n=\nFalse\n,\ncount_include_pad\n=\nTrue\n,\ndivisor_override\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 2D average pooling over an input signal composed of several input planes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\n,\noutput\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nand\nkernel_size\n(\nk\nH\n,\nk\nW\n)\n(kH, kW)\n(\nk\nH\n,\nkW\n)\ncan be precisely described as:\no\nu\nt\n(\nN\ni\n,\nC\nj\n,\nh\n,\nw\n)\n=\n1\nk\nH\n∗\nk\nW\n∑\nm\n=\n0\nk\nH\n−\n1\n∑\nn\n=\n0\nk\nW\n−\n1\ni\nn\np\nu\nt\n(\nN\ni\n,\nC\nj\n,\ns\nt\nr\ni\nd\ne\n[\n0\n]\n×\nh\n+\nm\n,\ns\nt\nr\ni\nd\ne\n[\n1\n]\n×\nw\n+\nn\n)\nout(N_i, C_j, h, w)  = \\frac{1}{kH * kW} \\sum_{m=0}^{kH-1} \\sum_{n=0}^{kW-1}\n                       input(N_i, C_j, stride[0] \\times h + m, stride[1] \\times w + n)\no\nu\nt\n(\nN\ni\n​\n,\nC\nj\n​\n,\nh\n,\nw\n)\n=\nk\nH\n∗\nkW\n1\n​\nm\n=\n0\n∑\nk\nH\n−\n1\n​\nn\n=\n0\n∑\nkW\n−\n1\n​\nin\np\nu\nt\n(\nN\ni\n​\n,\nC\nj\n​\n,\ns\nt\nr\ni\nd\ne\n[\n0\n]\n×\nh\n+\nm\n,\ns\nt\nr\ni\nd\ne\n[\n1\n]\n×\nw\n+\nn\n)\nIf\npadding\nis non-zero, then the input is implicitly zero-padded on both sides\nfor\npadding\nnumber of points.\nNote\nWhen ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\nor the input. Sliding windows that would start in the right padded region are ignored.\nThe parameters\nkernel_size\n,\nstride\n,\npadding\ncan either be:\na single\nint\n– in which case the same value is used for the height and width dimension\na\ntuple\nof two ints – in which case, the first\nint\nis used for the height dimension,\nand the second\nint\nfor the width dimension\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – the size of the window\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – the stride of the window. Default value is\nkernel_size\npadding\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – implicit zero padding to be added on both sides\nceil_mode\n(\nbool\n) – when True, will use\nceil\ninstead of\nfloor\nto compute the output shape\ncount_include_pad\n(\nbool\n) – when True, will include the zero-padding in the averaging calculation\ndivisor_override\n(\nOptional\n[\nint\n]\n) – if specified, it will be used as divisor, otherwise size of the pooling region will be used.\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n+\n2\n×\npadding\n[\n0\n]\n−\nkernel_size\n[\n0\n]\nstride\n[\n0\n]\n+\n1\n⌋\nH_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] -\n  \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nstride\n[\n0\n]\nH\nin\n​\n+\n2\n×\npadding\n[\n0\n]\n−\nkernel_size\n[\n0\n]\n​\n+\n1\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n+\n2\n×\npadding\n[\n1\n]\n−\nkernel_size\n[\n1\n]\nstride\n[\n1\n]\n+\n1\n⌋\nW_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] -\n  \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nstride\n[\n1\n]\nW\nin\n​\n+\n2\n×\npadding\n[\n1\n]\n−\nkernel_size\n[\n1\n]\n​\n+\n1\n⌋\nPer the note above, if\nceil_mode\nis True and\n(\nH\no\nu\nt\n−\n1\n)\n×\nstride\n[\n0\n]\n≥\nH\ni\nn\n+\npadding\n[\n0\n]\n(H_{out} - 1)\\times \\text{stride}[0]\\geq H_{in}\n+ \\text{padding}[0]\n(\nH\no\nu\nt\n​\n−\n1\n)\n×\nstride\n[\n0\n]\n≥\nH\nin\n​\n+\npadding\n[\n0\n]\n, we skip the last window as it would start in the bottom padded region,\nresulting in\nH\no\nu\nt\nH_{out}\nH\no\nu\nt\n​\nbeing reduced by one.\nThe same applies for\nW\no\nu\nt\nW_{out}\nW\no\nu\nt\n​\n.\nExamples:\n>>>\n# pool of square window of size=3, stride=2\n>>>\nm\n=\nnn\n.\nAvgPool2d\n(\n3\n,\nstride\n=\n2\n)\n>>>\n# pool of non-square window\n>>>\nm\n=\nnn\n.\nAvgPool2d\n((\n3\n,\n2\n),\nstride\n=\n(\n2\n,\n1\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n32\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html#avgpool2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AvgPool2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L661",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html#torch.nn.AvgPool2d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AvgPool3d",
  "page_text": "AvgPool3d\n¶\nclass\ntorch.nn.\nAvgPool3d\n(\nkernel_size\n,\nstride\n=\nNone\n,\npadding\n=\n0\n,\nceil_mode\n=\nFalse\n,\ncount_include_pad\n=\nTrue\n,\ndivisor_override\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 3D average pooling over an input signal composed of several input planes.\nIn the simplest case, the output value of the layer with input size\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n,\noutput\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nand\nkernel_size\n(\nk\nD\n,\nk\nH\n,\nk\nW\n)\n(kD, kH, kW)\n(\nk\nD\n,\nk\nH\n,\nkW\n)\ncan be precisely described as:\nout\n(\nN\ni\n,\nC\nj\n,\nd\n,\nh\n,\nw\n)\n=\n∑\nk\n=\n0\nk\nD\n−\n1\n∑\nm\n=\n0\nk\nH\n−\n1\n∑\nn\n=\n0\nk\nW\n−\n1\ninput\n(\nN\ni\n,\nC\nj\n,\nstride\n[\n0\n]\n×\nd\n+\nk\n,\nstride\n[\n1\n]\n×\nh\n+\nm\n,\nstride\n[\n2\n]\n×\nw\n+\nn\n)\nk\nD\n×\nk\nH\n×\nk\nW\n\\begin{aligned}\n    \\text{out}(N_i, C_j, d, h, w) ={} & \\sum_{k=0}^{kD-1} \\sum_{m=0}^{kH-1} \\sum_{n=0}^{kW-1} \\\\\n                                      & \\frac{\\text{input}(N_i, C_j, \\text{stride}[0] \\times d + k,\n                                              \\text{stride}[1] \\times h + m, \\text{stride}[2] \\times w + n)}\n                                             {kD \\times kH \\times kW}\n\\end{aligned}\nout\n(\nN\ni\n​\n,\nC\nj\n​\n,\nd\n,\nh\n,\nw\n)\n=\n​\nk\n=\n0\n∑\nk\nD\n−\n1\n​\nm\n=\n0\n∑\nk\nH\n−\n1\n​\nn\n=\n0\n∑\nkW\n−\n1\n​\nk\nD\n×\nk\nH\n×\nkW\ninput\n(\nN\ni\n​\n,\nC\nj\n​\n,\nstride\n[\n0\n]\n×\nd\n+\nk\n,\nstride\n[\n1\n]\n×\nh\n+\nm\n,\nstride\n[\n2\n]\n×\nw\n+\nn\n)\n​\n​\nIf\npadding\nis non-zero, then the input is implicitly zero-padded on all three sides\nfor\npadding\nnumber of points.\nNote\nWhen ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding\nor the input. Sliding windows that would start in the right padded region are ignored.\nThe parameters\nkernel_size\n,\nstride\ncan either be:\na single\nint\n– in which case the same value is used for the depth, height and width dimension\na\ntuple\nof three ints – in which case, the first\nint\nis used for the depth dimension,\nthe second\nint\nfor the height dimension and the third\nint\nfor the width dimension\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – the size of the window\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – the stride of the window. Default value is\nkernel_size\npadding\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – implicit zero padding to be added on all three sides\nceil_mode\n(\nbool\n) – when True, will use\nceil\ninstead of\nfloor\nto compute the output shape\ncount_include_pad\n(\nbool\n) – when True, will include the zero-padding in the averaging calculation\ndivisor_override\n(\nOptional\n[\nint\n]\n) – if specified, it will be used as divisor, otherwise\nkernel_size\nwill be used\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nD\no\nu\nt\n=\n⌊\nD\ni\nn\n+\n2\n×\npadding\n[\n0\n]\n−\nkernel_size\n[\n0\n]\nstride\n[\n0\n]\n+\n1\n⌋\nD_{out} = \\left\\lfloor\\frac{D_{in} + 2 \\times \\text{padding}[0] -\n      \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\nD\no\nu\nt\n​\n=\n⌊\nstride\n[\n0\n]\nD\nin\n​\n+\n2\n×\npadding\n[\n0\n]\n−\nkernel_size\n[\n0\n]\n​\n+\n1\n⌋\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n+\n2\n×\npadding\n[\n1\n]\n−\nkernel_size\n[\n1\n]\nstride\n[\n1\n]\n+\n1\n⌋\nH_{out} = \\left\\lfloor\\frac{H_{in} + 2 \\times \\text{padding}[1] -\n      \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nstride\n[\n1\n]\nH\nin\n​\n+\n2\n×\npadding\n[\n1\n]\n−\nkernel_size\n[\n1\n]\n​\n+\n1\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n+\n2\n×\npadding\n[\n2\n]\n−\nkernel_size\n[\n2\n]\nstride\n[\n2\n]\n+\n1\n⌋\nW_{out} = \\left\\lfloor\\frac{W_{in} + 2 \\times \\text{padding}[2] -\n      \\text{kernel\\_size}[2]}{\\text{stride}[2]} + 1\\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nstride\n[\n2\n]\nW\nin\n​\n+\n2\n×\npadding\n[\n2\n]\n−\nkernel_size\n[\n2\n]\n​\n+\n1\n⌋\nPer the note above, if\nceil_mode\nis True and\n(\nD\no\nu\nt\n−\n1\n)\n×\nstride\n[\n0\n]\n≥\nD\ni\nn\n+\npadding\n[\n0\n]\n(D_{out} - 1)\\times \\text{stride}[0]\\geq D_{in}\n+ \\text{padding}[0]\n(\nD\no\nu\nt\n​\n−\n1\n)\n×\nstride\n[\n0\n]\n≥\nD\nin\n​\n+\npadding\n[\n0\n]\n, we skip the last window as it would start in the padded region,\nresulting in\nD\no\nu\nt\nD_{out}\nD\no\nu\nt\n​\nbeing reduced by one.\nThe same applies for\nW\no\nu\nt\nW_{out}\nW\no\nu\nt\n​\nand\nH\no\nu\nt\nH_{out}\nH\no\nu\nt\n​\n.\nExamples:\n>>>\n# pool of square window of size=3, stride=2\n>>>\nm\n=\nnn\n.\nAvgPool3d\n(\n3\n,\nstride\n=\n2\n)\n>>>\n# pool of non-square window\n>>>\nm\n=\nnn\n.\nAvgPool3d\n((\n3\n,\n2\n,\n2\n),\nstride\n=\n(\n2\n,\n1\n,\n2\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n44\n,\n31\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool3d.html#avgpool3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AvgPool3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L767",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool3d.html#torch.nn.AvgPool3d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.FractionalMaxPool2d",
  "page_text": "FractionalMaxPool2d\n¶\nclass\ntorch.nn.\nFractionalMaxPool2d\n(\nkernel_size\n,\noutput_size\n=\nNone\n,\noutput_ratio\n=\nNone\n,\nreturn_indices\n=\nFalse\n,\n_random_samples\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 2D fractional max pooling over an input signal composed of several input planes.\nFractional MaxPooling is described in detail in the paper\nFractional MaxPooling\nby Ben Graham\nThe max-pooling operation is applied in\nk\nH\n×\nk\nW\nkH \\times kW\nk\nH\n×\nkW\nregions by a stochastic\nstep size determined by the target output size.\nThe number of output features is equal to the number of input planes.\nNote\nExactly one of\noutput_size\nor\noutput_ratio\nmust be defined.\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – the size of the window to take a max over.\nCan be a single number k (for a square kernel of k x k) or a tuple\n(kh, kw)\noutput_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – the target output size of the image of the form\noH x oW\n.\nCan be a tuple\n(oH, oW)\nor a single number oH for a square image\noH x oH\n.\nNote that we must have\nk\nH\n+\no\nH\n−\n1\n<\n=\nH\ni\nn\nkH + oH - 1 <= H_{in}\nk\nH\n+\noH\n−\n1\n<=\nH\nin\n​\nand\nk\nW\n+\no\nW\n−\n1\n<\n=\nW\ni\nn\nkW + oW - 1 <= W_{in}\nkW\n+\no\nW\n−\n1\n<=\nW\nin\n​\noutput_ratio\n(\nUnion\n[\nfloat\n,\nTuple\n[\nfloat\n,\nfloat\n]\n]\n) – If one wants to have an output size as a ratio of the input size, this option can be given.\nThis has to be a number or tuple in the range (0, 1).\nNote that we must have\nk\nH\n+\n(\no\nu\nt\np\nu\nt\n_\nr\na\nt\ni\no\n_\nH\n∗\nH\ni\nn\n)\n−\n1\n<\n=\nH\ni\nn\nkH + (output\\_ratio\\_H * H_{in}) - 1 <= H_{in}\nk\nH\n+\n(\no\nu\ntp\nu\nt\n_\nr\na\nt\ni\no\n_\nH\n∗\nH\nin\n​\n)\n−\n1\n<=\nH\nin\n​\nand\nk\nW\n+\n(\no\nu\nt\np\nu\nt\n_\nr\na\nt\ni\no\n_\nW\n∗\nW\ni\nn\n)\n−\n1\n<\n=\nW\ni\nn\nkW + (output\\_ratio\\_W * W_{in}) - 1 <= W_{in}\nkW\n+\n(\no\nu\ntp\nu\nt\n_\nr\na\nt\ni\no\n_\nW\n∗\nW\nin\n​\n)\n−\n1\n<=\nW\nin\n​\nreturn_indices\n(\nbool\n) – if\nTrue\n, will return the indices along with the outputs.\nUseful to pass to\nnn.MaxUnpool2d()\n. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\n(\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n=\noutput_size\n(H_{out}, W_{out})=\\text{output\\_size}\n(\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n=\noutput_size\nor\n(\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n=\noutput_ratio\n×\n(\nH\ni\nn\n,\nW\ni\nn\n)\n(H_{out}, W_{out})=\\text{output\\_ratio} \\times (H_{in}, W_{in})\n(\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n=\noutput_ratio\n×\n(\nH\nin\n​\n,\nW\nin\n​\n)\n.\nExamples\n>>>\n# pool of square window of size=3, and target output size 13x12\n>>>\nm\n=\nnn\n.\nFractionalMaxPool2d\n(\n3\n,\noutput_size\n=\n(\n13\n,\n12\n))\n>>>\n# pool of square window and target output size being half of input image size\n>>>\nm\n=\nnn\n.\nFractionalMaxPool2d\n(\n3\n,\noutput_ratio\n=\n(\n0.5\n,\n0.5\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n32\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool2d.html#fractionalmaxpool2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#FractionalMaxPool2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L886",
    "https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool2d.html#torch.nn.FractionalMaxPool2d",
    "https://arxiv.org/abs/1412.6071",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AvgPool3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.FractionalMaxPool3d",
  "page_text": "FractionalMaxPool3d\n¶\nclass\ntorch.nn.\nFractionalMaxPool3d\n(\nkernel_size\n,\noutput_size\n=\nNone\n,\noutput_ratio\n=\nNone\n,\nreturn_indices\n=\nFalse\n,\n_random_samples\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 3D fractional max pooling over an input signal composed of several input planes.\nFractional MaxPooling is described in detail in the paper\nFractional MaxPooling\nby Ben Graham\nThe max-pooling operation is applied in\nk\nT\n×\nk\nH\n×\nk\nW\nkT \\times kH \\times kW\nk\nT\n×\nk\nH\n×\nkW\nregions by a stochastic\nstep size determined by the target output size.\nThe number of output features is equal to the number of input planes.\nNote\nExactly one of\noutput_size\nor\noutput_ratio\nmust be defined.\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – the size of the window to take a max over.\nCan be a single number k (for a square kernel of k x k x k) or a tuple\n(kt x kh x kw)\noutput_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – the target output size of the image of the form\noT x oH x oW\n.\nCan be a tuple\n(oT, oH, oW)\nor a single number oH for a square image\noH x oH x oH\noutput_ratio\n(\nUnion\n[\nfloat\n,\nTuple\n[\nfloat\n,\nfloat\n,\nfloat\n]\n]\n) – If one wants to have an output size as a ratio of the input size, this option can be given.\nThis has to be a number or tuple in the range (0, 1)\nreturn_indices\n(\nbool\n) – if\nTrue\n, will return the indices along with the outputs.\nUseful to pass to\nnn.MaxUnpool3d()\n. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nT\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, T_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nT\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nT\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, T_{in}, H_{in}, W_{in})\n(\nC\n,\nT\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nT\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, T_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nT\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nT\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, T_{out}, H_{out}, W_{out})\n(\nC\n,\nT\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\n(\nT\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n=\noutput_size\n(T_{out}, H_{out}, W_{out})=\\text{output\\_size}\n(\nT\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n=\noutput_size\nor\n(\nT\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n=\noutput_ratio\n×\n(\nT\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(T_{out}, H_{out}, W_{out})=\\text{output\\_ratio} \\times (T_{in}, H_{in}, W_{in})\n(\nT\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n=\noutput_ratio\n×\n(\nT\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nExamples\n>>>\n# pool of cubic window of size=3, and target output size 13x12x11\n>>>\nm\n=\nnn\n.\nFractionalMaxPool3d\n(\n3\n,\noutput_size\n=\n(\n13\n,\n12\n,\n11\n))\n>>>\n# pool of cubic window and target output size being half of input size\n>>>\nm\n=\nnn\n.\nFractionalMaxPool3d\n(\n3\n,\noutput_ratio\n=\n(\n0.5\n,\n0.5\n,\n0.5\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n32\n,\n16\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool3d.html#fractionalmaxpool3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#FractionalMaxPool3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L975",
    "https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool3d.html#torch.nn.FractionalMaxPool3d",
    "https://arxiv.org/abs/1412.6071",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LPPool1d",
  "page_text": "LPPool1d\n¶\nclass\ntorch.nn.\nLPPool1d\n(\nnorm_type\n,\nkernel_size\n,\nstride\n=\nNone\n,\nceil_mode\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 1D power-average pooling over an input signal composed of several input planes.\nOn each window, the function computed is:\nf\n(\nX\n)\n=\n∑\nx\n∈\nX\nx\np\np\nf(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}}\nf\n(\nX\n)\n=\np\n​\nx\n∈\nX\n∑\n​\nx\np\n​\nAt p =\n∞\n\\infty\n∞\n, one gets Max Pooling\nAt p = 1, one gets Sum Pooling (which is proportional to Average Pooling)\nNote\nIf the sum to the power of\np\nis zero, the gradient of this function is\nnot defined. This implementation will set the gradient to zero in this case.\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – a single int, the size of the window\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – a single int, the stride of the window. Default value is\nkernel_size\nceil_mode\n(\nbool\n) – when True, will use\nceil\ninstead of\nfloor\nto compute the output shape\nShape:\nInput:\n(\nN\n,\nC\n,\nL\ni\nn\n)\n(N, C, L_{in})\n(\nN\n,\nC\n,\nL\nin\n​\n)\nor\n(\nC\n,\nL\ni\nn\n)\n(C, L_{in})\n(\nC\n,\nL\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nL\no\nu\nt\n)\n(N, C, L_{out})\n(\nN\n,\nC\n,\nL\no\nu\nt\n​\n)\nor\n(\nC\n,\nL\no\nu\nt\n)\n(C, L_{out})\n(\nC\n,\nL\no\nu\nt\n​\n)\n, where\nL\no\nu\nt\n=\n⌊\nL\ni\nn\n−\nkernel_size\nstride\n+\n1\n⌋\nL_{out} = \\left\\lfloor\\frac{L_{in} - \\text{kernel\\_size}}{\\text{stride}} + 1\\right\\rfloor\nL\no\nu\nt\n​\n=\n⌊\nstride\nL\nin\n​\n−\nkernel_size\n​\n+\n1\n⌋\nExamples::\n>>>\n# power-2 pool of window of length 3, with stride 2.\n>>>\nm\n=\nnn\n.\nLPPool1d\n(\n2\n,\n3\n,\nstride\n=\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool1d.html#lppool1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#LPPool1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1090",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool1d.html#torch.nn.LPPool1d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.FractionalMaxPool3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LPPool2d",
  "page_text": "LPPool2d\n¶\nclass\ntorch.nn.\nLPPool2d\n(\nnorm_type\n,\nkernel_size\n,\nstride\n=\nNone\n,\nceil_mode\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 2D power-average pooling over an input signal composed of several input planes.\nOn each window, the function computed is:\nf\n(\nX\n)\n=\n∑\nx\n∈\nX\nx\np\np\nf(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}}\nf\n(\nX\n)\n=\np\n​\nx\n∈\nX\n∑\n​\nx\np\n​\nAt p =\n∞\n\\infty\n∞\n, one gets Max Pooling\nAt p = 1, one gets Sum Pooling (which is proportional to average pooling)\nThe parameters\nkernel_size\n,\nstride\ncan either be:\na single\nint\n– in which case the same value is used for the height and width dimension\na\ntuple\nof two ints – in which case, the first\nint\nis used for the height dimension,\nand the second\nint\nfor the width dimension\nNote\nIf the sum to the power of\np\nis zero, the gradient of this function is\nnot defined. This implementation will set the gradient to zero in this case.\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – the size of the window\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n]\n]\n) – the stride of the window. Default value is\nkernel_size\nceil_mode\n(\nbool\n) – when True, will use\nceil\ninstead of\nfloor\nto compute the output shape\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n−\nkernel_size\n[\n0\n]\nstride\n[\n0\n]\n+\n1\n⌋\nH_{out} = \\left\\lfloor\\frac{H_{in} - \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nstride\n[\n0\n]\nH\nin\n​\n−\nkernel_size\n[\n0\n]\n​\n+\n1\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n−\nkernel_size\n[\n1\n]\nstride\n[\n1\n]\n+\n1\n⌋\nW_{out} = \\left\\lfloor\\frac{W_{in} - \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nstride\n[\n1\n]\nW\nin\n​\n−\nkernel_size\n[\n1\n]\n​\n+\n1\n⌋\nExamples:\n>>>\n# power-2 pool of square window of size=3, stride=2\n>>>\nm\n=\nnn\n.\nLPPool2d\n(\n2\n,\n3\n,\nstride\n=\n2\n)\n>>>\n# pool of non-square window of power 1.2\n>>>\nm\n=\nnn\n.\nLPPool2d\n(\n1.2\n,\n(\n3\n,\n2\n),\nstride\n=\n(\n2\n,\n1\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n32\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool2d.html#lppool2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#LPPool2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1132",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool2d.html#torch.nn.LPPool2d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LPPool3d",
  "page_text": "LPPool3d\n¶\nclass\ntorch.nn.\nLPPool3d\n(\nnorm_type\n,\nkernel_size\n,\nstride\n=\nNone\n,\nceil_mode\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 3D power-average pooling over an input signal composed of several input planes.\nOn each window, the function computed is:\nf\n(\nX\n)\n=\n∑\nx\n∈\nX\nx\np\np\nf(X) = \\sqrt[p]{\\sum_{x \\in X} x^{p}}\nf\n(\nX\n)\n=\np\n​\nx\n∈\nX\n∑\n​\nx\np\n​\nAt p =\n∞\n\\infty\n∞\n, one gets Max Pooling\nAt p = 1, one gets Sum Pooling (which is proportional to average pooling)\nThe parameters\nkernel_size\n,\nstride\ncan either be:\na single\nint\n– in which case the same value is used for the height, width and depth dimension\na\ntuple\nof three ints – in which case, the first\nint\nis used for the depth dimension,\nthe second\nint\nfor the height dimension and the third\nint\nfor the width dimension\nNote\nIf the sum to the power of\np\nis zero, the gradient of this function is\nnot defined. This implementation will set the gradient to zero in this case.\nParameters\nkernel_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – the size of the window\nstride\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n,\nint\n,\nint\n]\n]\n) – the stride of the window. Default value is\nkernel_size\nceil_mode\n(\nbool\n) – when True, will use\nceil\ninstead of\nfloor\nto compute the output shape\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nD\no\nu\nt\n=\n⌊\nD\ni\nn\n−\nkernel_size\n[\n0\n]\nstride\n[\n0\n]\n+\n1\n⌋\nD_{out} = \\left\\lfloor\\frac{D_{in} - \\text{kernel\\_size}[0]}{\\text{stride}[0]} + 1\\right\\rfloor\nD\no\nu\nt\n​\n=\n⌊\nstride\n[\n0\n]\nD\nin\n​\n−\nkernel_size\n[\n0\n]\n​\n+\n1\n⌋\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n−\nkernel_size\n[\n1\n]\nstride\n[\n1\n]\n+\n1\n⌋\nH_{out} = \\left\\lfloor\\frac{H_{in} - \\text{kernel\\_size}[1]}{\\text{stride}[1]} + 1\\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nstride\n[\n1\n]\nH\nin\n​\n−\nkernel_size\n[\n1\n]\n​\n+\n1\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n−\nkernel_size\n[\n2\n]\nstride\n[\n2\n]\n+\n1\n⌋\nW_{out} = \\left\\lfloor\\frac{W_{in} - \\text{kernel\\_size}[2]}{\\text{stride}[2]} + 1\\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nstride\n[\n2\n]\nW\nin\n​\n−\nkernel_size\n[\n2\n]\n​\n+\n1\n⌋\nExamples:\n>>>\n# power-2 pool of square window of size=3, stride=2\n>>>\nm\n=\nnn\n.\nLPPool3d\n(\n2\n,\n3\n,\nstride\n=\n2\n)\n>>>\n# pool of non-square window of power 1.2\n>>>\nm\n=\nnn\n.\nLPPool3d\n(\n1.2\n,\n(\n3\n,\n2\n,\n2\n),\nstride\n=\n(\n2\n,\n1\n,\n2\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n50\n,\n44\n,\n31\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool3d.html#lppool3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#LPPool3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1187",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool3d.html#torch.nn.LPPool3d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AdaptiveMaxPool1d",
  "page_text": "AdaptiveMaxPool1d\n¶\nclass\ntorch.nn.\nAdaptiveMaxPool1d\n(\noutput_size\n,\nreturn_indices\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 1D adaptive max pooling over an input signal composed of several input planes.\nThe output size is\nL\no\nu\nt\nL_{out}\nL\no\nu\nt\n​\n, for any input size.\nThe number of output features is equal to the number of input planes.\nParameters\noutput_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – the target output size\nL\no\nu\nt\nL_{out}\nL\no\nu\nt\n​\n.\nreturn_indices\n(\nbool\n) – if\nTrue\n, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool1d. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nL\ni\nn\n)\n(N, C, L_{in})\n(\nN\n,\nC\n,\nL\nin\n​\n)\nor\n(\nC\n,\nL\ni\nn\n)\n(C, L_{in})\n(\nC\n,\nL\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nL\no\nu\nt\n)\n(N, C, L_{out})\n(\nN\n,\nC\n,\nL\no\nu\nt\n​\n)\nor\n(\nC\n,\nL\no\nu\nt\n)\n(C, L_{out})\n(\nC\n,\nL\no\nu\nt\n​\n)\n, where\nL\no\nu\nt\n=\noutput_size\nL_{out}=\\text{output\\_size}\nL\no\nu\nt\n​\n=\noutput_size\n.\nExamples\n>>>\n# target output size of 5\n>>>\nm\n=\nnn\n.\nAdaptiveMaxPool1d\n(\n5\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n8\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool1d.html#adaptivemaxpool1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1265",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool1d.html#torch.nn.AdaptiveMaxPool1d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LPPool3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AdaptiveMaxPool2d",
  "page_text": "AdaptiveMaxPool2d\n¶\nclass\ntorch.nn.\nAdaptiveMaxPool2d\n(\noutput_size\n,\nreturn_indices\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 2D adaptive max pooling over an input signal composed of several input planes.\nThe output is of size\nH\no\nu\nt\n×\nW\no\nu\nt\nH_{out} \\times W_{out}\nH\no\nu\nt\n​\n×\nW\no\nu\nt\n​\n, for any input size.\nThe number of output features is equal to the number of input planes.\nParameters\noutput_size\n(\nUnion\n[\nint\n,\nNone\n,\nTuple\n[\nOptional\n[\nint\n]\n,\nOptional\n[\nint\n]\n]\n]\n) – the target output size of the image of the form\nH\no\nu\nt\n×\nW\no\nu\nt\nH_{out} \\times W_{out}\nH\no\nu\nt\n​\n×\nW\no\nu\nt\n​\n.\nCan be a tuple\n(\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(H_{out}, W_{out})\n(\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor a single\nH\no\nu\nt\nH_{out}\nH\no\nu\nt\n​\nfor a\nsquare image\nH\no\nu\nt\n×\nH\no\nu\nt\nH_{out} \\times H_{out}\nH\no\nu\nt\n​\n×\nH\no\nu\nt\n​\n.\nH\no\nu\nt\nH_{out}\nH\no\nu\nt\n​\nand\nW\no\nu\nt\nW_{out}\nW\no\nu\nt\n​\ncan be either a\nint\n, or\nNone\nwhich means the size will be the same as that\nof the input.\nreturn_indices\n(\nbool\n) – if\nTrue\n, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool2d. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\n(\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n=\noutput_size\n(H_{out}, W_{out})=\\text{output\\_size}\n(\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n=\noutput_size\n.\nExamples\n>>>\n# target output size of 5x7\n>>>\nm\n=\nnn\n.\nAdaptiveMaxPool2d\n((\n5\n,\n7\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n8\n,\n9\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# target output size of 7x7 (square)\n>>>\nm\n=\nnn\n.\nAdaptiveMaxPool2d\n(\n7\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n10\n,\n9\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# target output size of 10x7\n>>>\nm\n=\nnn\n.\nAdaptiveMaxPool2d\n((\nNone\n,\n7\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n10\n,\n9\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html#adaptivemaxpool2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1295",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html#torch.nn.AdaptiveMaxPool2d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AdaptiveMaxPool3d",
  "page_text": "AdaptiveMaxPool3d\n¶\nclass\ntorch.nn.\nAdaptiveMaxPool3d\n(\noutput_size\n,\nreturn_indices\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies a 3D adaptive max pooling over an input signal composed of several input planes.\nThe output is of size\nD\no\nu\nt\n×\nH\no\nu\nt\n×\nW\no\nu\nt\nD_{out} \\times H_{out} \\times W_{out}\nD\no\nu\nt\n​\n×\nH\no\nu\nt\n​\n×\nW\no\nu\nt\n​\n, for any input size.\nThe number of output features is equal to the number of input planes.\nParameters\noutput_size\n(\nUnion\n[\nint\n,\nNone\n,\nTuple\n[\nOptional\n[\nint\n]\n,\nOptional\n[\nint\n]\n,\nOptional\n[\nint\n]\n]\n]\n) – the target output size of the image of the form\nD\no\nu\nt\n×\nH\no\nu\nt\n×\nW\no\nu\nt\nD_{out} \\times H_{out} \\times W_{out}\nD\no\nu\nt\n​\n×\nH\no\nu\nt\n​\n×\nW\no\nu\nt\n​\n.\nCan be a tuple\n(\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(D_{out}, H_{out}, W_{out})\n(\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor a single\nD\no\nu\nt\nD_{out}\nD\no\nu\nt\n​\nfor a cube\nD\no\nu\nt\n×\nD\no\nu\nt\n×\nD\no\nu\nt\nD_{out} \\times D_{out} \\times D_{out}\nD\no\nu\nt\n​\n×\nD\no\nu\nt\n​\n×\nD\no\nu\nt\n​\n.\nD\no\nu\nt\nD_{out}\nD\no\nu\nt\n​\n,\nH\no\nu\nt\nH_{out}\nH\no\nu\nt\n​\nand\nW\no\nu\nt\nW_{out}\nW\no\nu\nt\n​\ncan be either a\nint\n, or\nNone\nwhich means the size will be the same as that of the input.\nreturn_indices\n(\nbool\n) – if\nTrue\n, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool3d. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n,\nwhere\n(\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n=\noutput_size\n(D_{out}, H_{out}, W_{out})=\\text{output\\_size}\n(\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n=\noutput_size\n.\nExamples\n>>>\n# target output size of 5x7x9\n>>>\nm\n=\nnn\n.\nAdaptiveMaxPool3d\n((\n5\n,\n7\n,\n9\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n8\n,\n9\n,\n10\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# target output size of 7x7x7 (cube)\n>>>\nm\n=\nnn\n.\nAdaptiveMaxPool3d\n(\n7\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n10\n,\n9\n,\n8\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# target output size of 7x9x8\n>>>\nm\n=\nnn\n.\nAdaptiveMaxPool3d\n((\n7\n,\nNone\n,\nNone\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n10\n,\n9\n,\n8\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool3d.html#adaptivemaxpool3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1337",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool3d.html#torch.nn.AdaptiveMaxPool3d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AdaptiveAvgPool1d",
  "page_text": "AdaptiveAvgPool1d\n¶\nclass\ntorch.nn.\nAdaptiveAvgPool1d\n(\noutput_size\n)\n[source]\n[source]\n¶\nApplies a 1D adaptive average pooling over an input signal composed of several input planes.\nThe output size is\nL\no\nu\nt\nL_{out}\nL\no\nu\nt\n​\n, for any input size.\nThe number of output features is equal to the number of input planes.\nParameters\noutput_size\n(\nUnion\n[\nint\n,\nTuple\n[\nint\n]\n]\n) – the target output size\nL\no\nu\nt\nL_{out}\nL\no\nu\nt\n​\n.\nShape:\nInput:\n(\nN\n,\nC\n,\nL\ni\nn\n)\n(N, C, L_{in})\n(\nN\n,\nC\n,\nL\nin\n​\n)\nor\n(\nC\n,\nL\ni\nn\n)\n(C, L_{in})\n(\nC\n,\nL\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nL\no\nu\nt\n)\n(N, C, L_{out})\n(\nN\n,\nC\n,\nL\no\nu\nt\n​\n)\nor\n(\nC\n,\nL\no\nu\nt\n)\n(C, L_{out})\n(\nC\n,\nL\no\nu\nt\n​\n)\n, where\nL\no\nu\nt\n=\noutput_size\nL_{out}=\\text{output\\_size}\nL\no\nu\nt\n​\n=\noutput_size\n.\nExamples\n>>>\n# target output size of 5\n>>>\nm\n=\nnn\n.\nAdaptiveAvgPool1d\n(\n5\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n8\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool1d.html#adaptiveavgpool1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1391",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool1d.html#torch.nn.AdaptiveAvgPool1d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveMaxPool3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AdaptiveAvgPool2d",
  "page_text": "AdaptiveAvgPool2d\n¶\nclass\ntorch.nn.\nAdaptiveAvgPool2d\n(\noutput_size\n)\n[source]\n[source]\n¶\nApplies a 2D adaptive average pooling over an input signal composed of several input planes.\nThe output is of size H x W, for any input size.\nThe number of output features is equal to the number of input planes.\nParameters\noutput_size\n(\nUnion\n[\nint\n,\nNone\n,\nTuple\n[\nOptional\n[\nint\n]\n,\nOptional\n[\nint\n]\n]\n]\n) – the target output size of the image of the form H x W.\nCan be a tuple (H, W) or a single H for a square image H x H.\nH and W can be either a\nint\n, or\nNone\nwhich means the size will\nbe the same as that of the input.\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nS\n0\n,\nS\n1\n)\n(N, C, S_{0}, S_{1})\n(\nN\n,\nC\n,\nS\n0\n​\n,\nS\n1\n​\n)\nor\n(\nC\n,\nS\n0\n,\nS\n1\n)\n(C, S_{0}, S_{1})\n(\nC\n,\nS\n0\n​\n,\nS\n1\n​\n)\n, where\nS\n=\noutput_size\nS=\\text{output\\_size}\nS\n=\noutput_size\n.\nExamples\n>>>\n# target output size of 5x7\n>>>\nm\n=\nnn\n.\nAdaptiveAvgPool2d\n((\n5\n,\n7\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n8\n,\n9\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# target output size of 7x7 (square)\n>>>\nm\n=\nnn\n.\nAdaptiveAvgPool2d\n(\n7\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n10\n,\n9\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# target output size of 10x7\n>>>\nm\n=\nnn\n.\nAdaptiveAvgPool2d\n((\nNone\n,\n7\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n10\n,\n9\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html#adaptiveavgpool2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1419",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html#torch.nn.AdaptiveAvgPool2d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AdaptiveAvgPool3d",
  "page_text": "AdaptiveAvgPool3d\n¶\nclass\ntorch.nn.\nAdaptiveAvgPool3d\n(\noutput_size\n)\n[source]\n[source]\n¶\nApplies a 3D adaptive average pooling over an input signal composed of several input planes.\nThe output is of size D x H x W, for any input size.\nThe number of output features is equal to the number of input planes.\nParameters\noutput_size\n(\nUnion\n[\nint\n,\nNone\n,\nTuple\n[\nOptional\n[\nint\n]\n,\nOptional\n[\nint\n]\n,\nOptional\n[\nint\n]\n]\n]\n) – the target output size of the form D x H x W.\nCan be a tuple (D, H, W) or a single number D for a cube D x D x D.\nD, H and W can be either a\nint\n, or\nNone\nwhich means the size will\nbe the same as that of the input.\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nS\n0\n,\nS\n1\n,\nS\n2\n)\n(N, C, S_{0}, S_{1}, S_{2})\n(\nN\n,\nC\n,\nS\n0\n​\n,\nS\n1\n​\n,\nS\n2\n​\n)\nor\n(\nC\n,\nS\n0\n,\nS\n1\n,\nS\n2\n)\n(C, S_{0}, S_{1}, S_{2})\n(\nC\n,\nS\n0\n​\n,\nS\n1\n​\n,\nS\n2\n​\n)\n,\nwhere\nS\n=\noutput_size\nS=\\text{output\\_size}\nS\n=\noutput_size\n.\nExamples\n>>>\n# target output size of 5x7x9\n>>>\nm\n=\nnn\n.\nAdaptiveAvgPool3d\n((\n5\n,\n7\n,\n9\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n8\n,\n9\n,\n10\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# target output size of 7x7x7 (cube)\n>>>\nm\n=\nnn\n.\nAdaptiveAvgPool3d\n(\n7\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n10\n,\n9\n,\n8\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# target output size of 7x9x8\n>>>\nm\n=\nnn\n.\nAdaptiveAvgPool3d\n((\n7\n,\nNone\n,\nNone\n))\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n64\n,\n10\n,\n9\n,\n8\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool3d.html#adaptiveavgpool3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pooling.py#L1458",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool3d.html#torch.nn.AdaptiveAvgPool3d",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ReflectionPad1d",
  "page_text": "ReflectionPad1d\n¶\nclass\ntorch.nn.\nReflectionPad1d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using the reflection of the input boundary.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 2-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n)\nShape:\nInput:\n(\nC\n,\nW\ni\nn\n)\n(C, W_{in})\n(\nC\n,\nW\nin\n​\n)\nor\n(\nN\n,\nC\n,\nW\ni\nn\n)\n(N, C, W_{in})\n(\nN\n,\nC\n,\nW\nin\n​\n)\n.\nOutput:\n(\nC\n,\nW\no\nu\nt\n)\n(C, W_{out})\n(\nC\n,\nW\no\nu\nt\n​\n)\nor\n(\nN\n,\nC\n,\nW\no\nu\nt\n)\n(N, C, W_{out})\n(\nN\n,\nC\n,\nW\no\nu\nt\n​\n)\n, where\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nReflectionPad1d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\narange\n(\n8\n,\ndtype\n=\ntorch\n.\nfloat\n)\n.\nreshape\n(\n1\n,\n2\n,\n4\n)\n>>>\ninput\ntensor([[[0., 1., 2., 3.],\n[4., 5., 6., 7.]]])\n>>>\nm\n(\ninput\n)\ntensor([[[2., 1., 0., 1., 2., 3., 2., 1.],\n[6., 5., 4., 5., 6., 7., 6., 5.]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nReflectionPad1d\n((\n3\n,\n1\n))\n>>>\nm\n(\ninput\n)\ntensor([[[3., 2., 1., 0., 1., 2., 3., 2.],\n[7., 6., 5., 4., 5., 6., 7., 6.]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad1d.html#reflectionpad1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ReflectionPad1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L374",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad1d.html#torch.nn.ReflectionPad1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ReflectionPad2d",
  "page_text": "ReflectionPad2d\n¶\nclass\ntorch.nn.\nReflectionPad2d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using the reflection of the input boundary.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 4-\ntuple\n, uses (\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n)\nNote that padding size should be less than the corresponding input dimension.\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nwhere\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nReflectionPad2d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\narange\n(\n9\n,\ndtype\n=\ntorch\n.\nfloat\n)\n.\nreshape\n(\n1\n,\n1\n,\n3\n,\n3\n)\n>>>\ninput\ntensor([[[[0., 1., 2.],\n[3., 4., 5.],\n[6., 7., 8.]]]])\n>>>\nm\n(\ninput\n)\ntensor([[[[8., 7., 6., 7., 8., 7., 6.],\n[5., 4., 3., 4., 5., 4., 3.],\n[2., 1., 0., 1., 2., 1., 0.],\n[5., 4., 3., 4., 5., 4., 3.],\n[8., 7., 6., 7., 8., 7., 6.],\n[5., 4., 3., 4., 5., 4., 3.],\n[2., 1., 0., 1., 2., 1., 0.]]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nReflectionPad2d\n((\n1\n,\n1\n,\n2\n,\n0\n))\n>>>\nm\n(\ninput\n)\ntensor([[[[7., 6., 7., 8., 7.],\n[4., 3., 4., 5., 4.],\n[1., 0., 1., 2., 1.],\n[4., 3., 4., 5., 4.],\n[7., 6., 7., 8., 7.]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad2d.html#reflectionpad2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ReflectionPad2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L415",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad2d.html#torch.nn.ReflectionPad2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ReflectionPad3d",
  "page_text": "ReflectionPad3d\n¶\nclass\ntorch.nn.\nReflectionPad3d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using the reflection of the input boundary.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 6-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n,\npadding_front\n\\text{padding\\_front}\npadding_front\n,\npadding_back\n\\text{padding\\_back}\npadding_back\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n,\nwhere\nD\no\nu\nt\n=\nD\ni\nn\n+\npadding_front\n+\npadding_back\nD_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}\nD\no\nu\nt\n​\n=\nD\nin\n​\n+\npadding_front\n+\npadding_back\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nReflectionPad3d\n(\n1\n)\n>>>\ninput\n=\ntorch\n.\narange\n(\n8\n,\ndtype\n=\ntorch\n.\nfloat\n)\n.\nreshape\n(\n1\n,\n1\n,\n2\n,\n2\n,\n2\n)\n>>>\nm\n(\ninput\n)\ntensor([[[[[7., 6., 7., 6.],\n[5., 4., 5., 4.],\n[7., 6., 7., 6.],\n[5., 4., 5., 4.]],\n[[3., 2., 3., 2.],\n[1., 0., 1., 0.],\n[3., 2., 3., 2.],\n[1., 0., 1., 0.]],\n[[7., 6., 7., 6.],\n[5., 4., 5., 4.],\n[7., 6., 7., 6.],\n[5., 4., 5., 4.]],\n[[3., 2., 3., 2.],\n[1., 0., 1., 0.],\n[3., 2., 3., 2.],\n[1., 0., 1., 0.]]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad3d.html#reflectionpad3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ReflectionPad3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L468",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad3d.html#torch.nn.ReflectionPad3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ReplicationPad1d",
  "page_text": "ReplicationPad1d\n¶\nclass\ntorch.nn.\nReplicationPad1d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using replication of the input boundary.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 2-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n)\nShape:\nInput:\n(\nC\n,\nW\ni\nn\n)\n(C, W_{in})\n(\nC\n,\nW\nin\n​\n)\nor\n(\nN\n,\nC\n,\nW\ni\nn\n)\n(N, C, W_{in})\n(\nN\n,\nC\n,\nW\nin\n​\n)\n.\nOutput:\n(\nC\n,\nW\no\nu\nt\n)\n(C, W_{out})\n(\nC\n,\nW\no\nu\nt\n​\n)\nor\n(\nN\n,\nC\n,\nW\no\nu\nt\n)\n(N, C, W_{out})\n(\nN\n,\nC\n,\nW\no\nu\nt\n​\n)\n, where\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nReplicationPad1d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\narange\n(\n8\n,\ndtype\n=\ntorch\n.\nfloat\n)\n.\nreshape\n(\n1\n,\n2\n,\n4\n)\n>>>\ninput\ntensor([[[0., 1., 2., 3.],\n[4., 5., 6., 7.]]])\n>>>\nm\n(\ninput\n)\ntensor([[[0., 0., 0., 1., 2., 3., 3., 3.],\n[4., 4., 4., 5., 6., 7., 7., 7.]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nReplicationPad1d\n((\n3\n,\n1\n))\n>>>\nm\n(\ninput\n)\ntensor([[[0., 0., 0., 0., 1., 2., 3., 3.],\n[4., 4., 4., 4., 5., 6., 7., 7.]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad1d.html#replicationpad1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ReplicationPad1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L533",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad1d.html#torch.nn.ReplicationPad1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReflectionPad3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ReplicationPad2d",
  "page_text": "ReplicationPad2d\n¶\nclass\ntorch.nn.\nReplicationPad2d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using replication of the input boundary.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 4-\ntuple\n, uses (\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nReplicationPad2d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\narange\n(\n9\n,\ndtype\n=\ntorch\n.\nfloat\n)\n.\nreshape\n(\n1\n,\n1\n,\n3\n,\n3\n)\n>>>\ninput\ntensor([[[[0., 1., 2.],\n[3., 4., 5.],\n[6., 7., 8.]]]])\n>>>\nm\n(\ninput\n)\ntensor([[[[0., 0., 0., 1., 2., 2., 2.],\n[0., 0., 0., 1., 2., 2., 2.],\n[0., 0., 0., 1., 2., 2., 2.],\n[3., 3., 3., 4., 5., 5., 5.],\n[6., 6., 6., 7., 8., 8., 8.],\n[6., 6., 6., 7., 8., 8., 8.],\n[6., 6., 6., 7., 8., 8., 8.]]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nReplicationPad2d\n((\n1\n,\n1\n,\n2\n,\n0\n))\n>>>\nm\n(\ninput\n)\ntensor([[[[0., 0., 1., 2., 2.],\n[0., 0., 1., 2., 2.],\n[0., 0., 1., 2., 2.],\n[3., 3., 4., 5., 5.],\n[6., 6., 7., 8., 8.]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad2d.html#replicationpad2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ReplicationPad2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L574",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad2d.html#torch.nn.ReplicationPad2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ReplicationPad3d",
  "page_text": "ReplicationPad3d\n¶\nclass\ntorch.nn.\nReplicationPad3d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using replication of the input boundary.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 6-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n,\npadding_front\n\\text{padding\\_front}\npadding_front\n,\npadding_back\n\\text{padding\\_back}\npadding_back\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n,\nwhere\nD\no\nu\nt\n=\nD\ni\nn\n+\npadding_front\n+\npadding_back\nD_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}\nD\no\nu\nt\n​\n=\nD\nin\n​\n+\npadding_front\n+\npadding_back\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nReplicationPad3d\n(\n3\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n16\n,\n3\n,\n8\n,\n320\n,\n480\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nReplicationPad3d\n((\n3\n,\n3\n,\n6\n,\n6\n,\n1\n,\n1\n))\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad3d.html#replicationpad3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ReplicationPad3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L626",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad3d.html#torch.nn.ReplicationPad3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ZeroPad1d",
  "page_text": "ZeroPad1d\n¶\nclass\ntorch.nn.\nZeroPad1d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor boundaries with zero.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in both boundaries. If a 2-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n)\nShape:\nInput:\n(\nC\n,\nW\ni\nn\n)\n(C, W_{in})\n(\nC\n,\nW\nin\n​\n)\nor\n(\nN\n,\nC\n,\nW\ni\nn\n)\n(N, C, W_{in})\n(\nN\n,\nC\n,\nW\nin\n​\n)\n.\nOutput:\n(\nC\n,\nW\no\nu\nt\n)\n(C, W_{out})\n(\nC\n,\nW\no\nu\nt\n​\n)\nor\n(\nN\n,\nC\n,\nW\no\nu\nt\n)\n(N, C, W_{out})\n(\nN\n,\nC\n,\nW\no\nu\nt\n​\n)\n, where\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nZeroPad1d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n2\n,\n4\n)\n>>>\ninput\ntensor([[[-1.0491, -0.7152, -0.0749,  0.8530],\n[-1.3287,  1.8966,  0.1466, -0.2771]]])\n>>>\nm\n(\ninput\n)\ntensor([[[ 0.0000,  0.0000, -1.0491, -0.7152, -0.0749,  0.8530,  0.0000,\n0.0000],\n[ 0.0000,  0.0000, -1.3287,  1.8966,  0.1466, -0.2771,  0.0000,\n0.0000]]])\n>>>\nm\n=\nnn\n.\nZeroPad1d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n2\n,\n3\n)\n>>>\ninput\ntensor([[[ 1.6616,  1.4523, -1.1255],\n[-3.6372,  0.1182, -1.8652]]])\n>>>\nm\n(\ninput\n)\ntensor([[[ 0.0000,  0.0000,  1.6616,  1.4523, -1.1255,  0.0000,  0.0000],\n[ 0.0000,  0.0000, -3.6372,  0.1182, -1.8652,  0.0000,  0.0000]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nZeroPad1d\n((\n3\n,\n1\n))\n>>>\nm\n(\ninput\n)\ntensor([[[ 0.0000,  0.0000,  0.0000,  1.6616,  1.4523, -1.1255,  0.0000],\n[ 0.0000,  0.0000,  0.0000, -3.6372,  0.1182, -1.8652,  0.0000]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad1d.html#zeropad1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ZeroPad1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L667",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad1d.html#torch.nn.ZeroPad1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReplicationPad3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ZeroPad2d",
  "page_text": "ZeroPad2d\n¶\nclass\ntorch.nn.\nZeroPad2d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor boundaries with zero.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 4-\ntuple\n, uses (\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nZeroPad2d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n1\n,\n3\n,\n3\n)\n>>>\ninput\ntensor([[[[-0.1678, -0.4418,  1.9466],\n[ 0.9604, -0.4219, -0.5241],\n[-0.9162, -0.5436, -0.6446]]]])\n>>>\nm\n(\ninput\n)\ntensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n[ 0.0000,  0.0000, -0.1678, -0.4418,  1.9466,  0.0000,  0.0000],\n[ 0.0000,  0.0000,  0.9604, -0.4219, -0.5241,  0.0000,  0.0000],\n[ 0.0000,  0.0000, -0.9162, -0.5436, -0.6446,  0.0000,  0.0000],\n[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nZeroPad2d\n((\n1\n,\n1\n,\n2\n,\n0\n))\n>>>\nm\n(\ninput\n)\ntensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n[ 0.0000, -0.1678, -0.4418,  1.9466,  0.0000],\n[ 0.0000,  0.9604, -0.4219, -0.5241,  0.0000],\n[ 0.0000, -0.9162, -0.5436, -0.6446,  0.0000]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad2d.html#zeropad2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ZeroPad2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L720",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad2d.html#torch.nn.ZeroPad2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ZeroPad3d",
  "page_text": "ZeroPad3d\n¶\nclass\ntorch.nn.\nZeroPad3d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor boundaries with zero.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 6-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n,\npadding_front\n\\text{padding\\_front}\npadding_front\n,\npadding_back\n\\text{padding\\_back}\npadding_back\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nD\no\nu\nt\n=\nD\ni\nn\n+\npadding_front\n+\npadding_back\nD_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}\nD\no\nu\nt\n​\n=\nD\nin\n​\n+\npadding_front\n+\npadding_back\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nZeroPad3d\n(\n3\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n16\n,\n3\n,\n10\n,\n20\n,\n30\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nZeroPad3d\n((\n3\n,\n3\n,\n6\n,\n6\n,\n0\n,\n1\n))\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad3d.html#zeropad3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ZeroPad3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L774",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad3d.html#torch.nn.ZeroPad3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ConstantPad1d",
  "page_text": "ConstantPad1d\n¶\nclass\ntorch.nn.\nConstantPad1d\n(\npadding\n,\nvalue\n)\n[source]\n[source]\n¶\nPads the input tensor boundaries with a constant value.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in both boundaries. If a 2-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n)\nShape:\nInput:\n(\nC\n,\nW\ni\nn\n)\n(C, W_{in})\n(\nC\n,\nW\nin\n​\n)\nor\n(\nN\n,\nC\n,\nW\ni\nn\n)\n(N, C, W_{in})\n(\nN\n,\nC\n,\nW\nin\n​\n)\n.\nOutput:\n(\nC\n,\nW\no\nu\nt\n)\n(C, W_{out})\n(\nC\n,\nW\no\nu\nt\n​\n)\nor\n(\nN\n,\nC\n,\nW\no\nu\nt\n)\n(N, C, W_{out})\n(\nN\n,\nC\n,\nW\no\nu\nt\n​\n)\n, where\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nConstantPad1d\n(\n2\n,\n3.5\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n2\n,\n4\n)\n>>>\ninput\ntensor([[[-1.0491, -0.7152, -0.0749,  0.8530],\n[-1.3287,  1.8966,  0.1466, -0.2771]]])\n>>>\nm\n(\ninput\n)\ntensor([[[ 3.5000,  3.5000, -1.0491, -0.7152, -0.0749,  0.8530,  3.5000,\n3.5000],\n[ 3.5000,  3.5000, -1.3287,  1.8966,  0.1466, -0.2771,  3.5000,\n3.5000]]])\n>>>\nm\n=\nnn\n.\nConstantPad1d\n(\n2\n,\n3.5\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n2\n,\n3\n)\n>>>\ninput\ntensor([[[ 1.6616,  1.4523, -1.1255],\n[-3.6372,  0.1182, -1.8652]]])\n>>>\nm\n(\ninput\n)\ntensor([[[ 3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000,  3.5000],\n[ 3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000,  3.5000]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nConstantPad1d\n((\n3\n,\n1\n),\n3.5\n)\n>>>\nm\n(\ninput\n)\ntensor([[[ 3.5000,  3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000],\n[ 3.5000,  3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad1d.html#constantpad1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ConstantPad1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L221",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad1d.html#torch.nn.ConstantPad1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ZeroPad3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ConstantPad2d",
  "page_text": "ConstantPad2d\n¶\nclass\ntorch.nn.\nConstantPad2d\n(\npadding\n,\nvalue\n)\n[source]\n[source]\n¶\nPads the input tensor boundaries with a constant value.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 4-\ntuple\n, uses (\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nConstantPad2d\n(\n2\n,\n3.5\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n2\n,\n2\n)\n>>>\ninput\ntensor([[[ 1.6585,  0.4320],\n[-0.8701, -0.4649]]])\n>>>\nm\n(\ninput\n)\ntensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n[ 3.5000,  3.5000,  1.6585,  0.4320,  3.5000,  3.5000],\n[ 3.5000,  3.5000, -0.8701, -0.4649,  3.5000,  3.5000],\n[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nConstantPad2d\n((\n3\n,\n0\n,\n2\n,\n1\n),\n3.5\n)\n>>>\nm\n(\ninput\n)\ntensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],\n[ 3.5000,  3.5000,  3.5000,  1.6585,  0.4320],\n[ 3.5000,  3.5000,  3.5000, -0.8701, -0.4649],\n[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad2d.html#constantpad2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ConstantPad2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L272",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad2d.html#torch.nn.ConstantPad2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ConstantPad3d",
  "page_text": "ConstantPad3d\n¶\nclass\ntorch.nn.\nConstantPad3d\n(\npadding\n,\nvalue\n)\n[source]\n[source]\n¶\nPads the input tensor boundaries with a constant value.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 6-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n,\npadding_front\n\\text{padding\\_front}\npadding_front\n,\npadding_back\n\\text{padding\\_back}\npadding_back\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nD\no\nu\nt\n=\nD\ni\nn\n+\npadding_front\n+\npadding_back\nD_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}\nD\no\nu\nt\n​\n=\nD\nin\n​\n+\npadding_front\n+\npadding_back\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nConstantPad3d\n(\n3\n,\n3.5\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n16\n,\n3\n,\n10\n,\n20\n,\n30\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nConstantPad3d\n((\n3\n,\n3\n,\n6\n,\n6\n,\n0\n,\n1\n),\n3.5\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad3d.html#constantpad3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#ConstantPad3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L323",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad3d.html#torch.nn.ConstantPad3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.CircularPad1d",
  "page_text": "CircularPad1d\n¶\nclass\ntorch.nn.\nCircularPad1d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using circular padding of the input boundary.\nTensor values at the beginning of the dimension are used to pad the end,\nand values at the end are used to pad the beginning. If negative padding is\napplied then the ends of the tensor get removed.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 2-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n)\nShape:\nInput:\n(\nC\n,\nW\ni\nn\n)\n(C, W_{in})\n(\nC\n,\nW\nin\n​\n)\nor\n(\nN\n,\nC\n,\nW\ni\nn\n)\n(N, C, W_{in})\n(\nN\n,\nC\n,\nW\nin\n​\n)\n.\nOutput:\n(\nC\n,\nW\no\nu\nt\n)\n(C, W_{out})\n(\nC\n,\nW\no\nu\nt\n​\n)\nor\n(\nN\n,\nC\n,\nW\no\nu\nt\n)\n(N, C, W_{out})\n(\nN\n,\nC\n,\nW\no\nu\nt\n​\n)\n, where\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nCircularPad1d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\narange\n(\n8\n,\ndtype\n=\ntorch\n.\nfloat\n)\n.\nreshape\n(\n1\n,\n2\n,\n4\n)\n>>>\ninput\ntensor([[[0., 1., 2., 3.],\n[4., 5., 6., 7.]]])\n>>>\nm\n(\ninput\n)\ntensor([[[2., 3., 0., 1., 2., 3., 0., 1.],\n[6., 7., 4., 5., 6., 7., 4., 5.]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nCircularPad1d\n((\n3\n,\n1\n))\n>>>\nm\n(\ninput\n)\ntensor([[[1., 2., 3., 0., 1., 2., 3., 0.],\n[5., 6., 7., 4., 5., 6., 7., 4.]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad1d.html#circularpad1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#CircularPad1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L48",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad1d.html#torch.nn.CircularPad1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ConstantPad3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.CircularPad2d",
  "page_text": "CircularPad2d\n¶\nclass\ntorch.nn.\nCircularPad2d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using circular padding of the input boundary.\nTensor values at the beginning of the dimension are used to pad the end,\nand values at the end are used to pad the beginning. If negative padding is\napplied then the ends of the tensor get removed.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 4-\ntuple\n, uses (\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, H_{in}, W_{in})\n(\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, H_{out}, W_{out})\n(\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nCircularPad2d\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\narange\n(\n9\n,\ndtype\n=\ntorch\n.\nfloat\n)\n.\nreshape\n(\n1\n,\n1\n,\n3\n,\n3\n)\n>>>\ninput\ntensor([[[[0., 1., 2.],\n[3., 4., 5.],\n[6., 7., 8.]]]])\n>>>\nm\n(\ninput\n)\ntensor([[[[4., 5., 3., 4., 5., 3., 4.],\n[7., 8., 6., 7., 8., 6., 7.],\n[1., 2., 0., 1., 2., 0., 1.],\n[4., 5., 3., 4., 5., 3., 4.],\n[7., 8., 6., 7., 8., 6., 7.],\n[1., 2., 0., 1., 2., 0., 1.],\n[4., 5., 3., 4., 5., 3., 4.]]]])\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nCircularPad2d\n((\n1\n,\n1\n,\n2\n,\n0\n))\n>>>\nm\n(\ninput\n)\ntensor([[[[5., 3., 4., 5., 3.],\n[8., 6., 7., 8., 6.],\n[2., 0., 1., 2., 0.],\n[5., 3., 4., 5., 3.],\n[8., 6., 7., 8., 6.]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad2d.html#circularpad2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#CircularPad2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L97",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad2d.html#torch.nn.CircularPad2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.CircularPad3d",
  "page_text": "CircularPad3d\n¶\nclass\ntorch.nn.\nCircularPad3d\n(\npadding\n)\n[source]\n[source]\n¶\nPads the input tensor using circular padding of the input boundary.\nTensor values at the beginning of the dimension are used to pad the end,\nand values at the end are used to pad the beginning. If negative padding is\napplied then the ends of the tensor get removed.\nFor\nN\n-dimensional padding, use\ntorch.nn.functional.pad()\n.\nParameters\npadding\n(\nint\n,\ntuple\n) – the size of the padding. If is\nint\n, uses the same\npadding in all boundaries. If a 6-\ntuple\n, uses\n(\npadding_left\n\\text{padding\\_left}\npadding_left\n,\npadding_right\n\\text{padding\\_right}\npadding_right\n,\npadding_top\n\\text{padding\\_top}\npadding_top\n,\npadding_bottom\n\\text{padding\\_bottom}\npadding_bottom\n,\npadding_front\n\\text{padding\\_front}\npadding_front\n,\npadding_back\n\\text{padding\\_back}\npadding_back\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(C, D_{in}, H_{in}, W_{in})\n(\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(C, D_{out}, H_{out}, W_{out})\n(\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n,\nwhere\nD\no\nu\nt\n=\nD\ni\nn\n+\npadding_front\n+\npadding_back\nD_{out} = D_{in} + \\text{padding\\_front} + \\text{padding\\_back}\nD\no\nu\nt\n​\n=\nD\nin\n​\n+\npadding_front\n+\npadding_back\nH\no\nu\nt\n=\nH\ni\nn\n+\npadding_top\n+\npadding_bottom\nH_{out} = H_{in} + \\text{padding\\_top} + \\text{padding\\_bottom}\nH\no\nu\nt\n​\n=\nH\nin\n​\n+\npadding_top\n+\npadding_bottom\nW\no\nu\nt\n=\nW\ni\nn\n+\npadding_left\n+\npadding_right\nW_{out} = W_{in} + \\text{padding\\_left} + \\text{padding\\_right}\nW\no\nu\nt\n​\n=\nW\nin\n​\n+\npadding_left\n+\npadding_right\nExamples:\n>>>\nm\n=\nnn\n.\nCircularPad3d\n(\n3\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n16\n,\n3\n,\n8\n,\n320\n,\n480\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# using different paddings for different sides\n>>>\nm\n=\nnn\n.\nCircularPad3d\n((\n3\n,\n3\n,\n6\n,\n6\n,\n1\n,\n1\n))\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad3d.html#circularpad3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/padding.html#CircularPad3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/padding.py#L156",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad3d.html#torch.nn.CircularPad3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html#torch.nn.functional.pad",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.ELU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ELU",
  "page_text": "ELU\n¶\nclass\ntorch.nn.\nELU\n(\nalpha\n=\n1.0\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the Exponential Linear Unit (ELU) function, element-wise.\nMethod described in the paper:\nFast and Accurate Deep Network Learning by Exponential Linear\nUnits (ELUs)\n.\nELU is defined as:\nELU\n(\nx\n)\n=\n{\nx\n,\nif\nx\n>\n0\nα\n∗\n(\nexp\n⁡\n(\nx\n)\n−\n1\n)\n,\nif\nx\n≤\n0\n\\text{ELU}(x) = \\begin{cases}\nx, & \\text{ if } x > 0\\\\\n\\alpha * (\\exp(x) - 1), & \\text{ if } x \\leq 0\n\\end{cases}\nELU\n(\nx\n)\n=\n{\nx\n,\nα\n∗\n(\nexp\n(\nx\n)\n−\n1\n)\n,\n​\nif\nx\n>\n0\nif\nx\n≤\n0\n​\nParameters\nalpha\n(\nfloat\n) – the\nα\n\\alpha\nα\nvalue for the ELU formulation. Default: 1.0\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nELU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ELU.html#elu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#ELU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L520",
    "https://pytorch.org/docs/stable/generated/torch.nn.ELU.html#torch.nn.ELU",
    "https://arxiv.org/abs/1511.07289",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardshrink.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.CircularPad3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Hardshrink",
  "page_text": "Hardshrink\n¶\nclass\ntorch.nn.\nHardshrink\n(\nlambd\n=\n0.5\n)\n[source]\n[source]\n¶\nApplies the Hard Shrinkage (Hardshrink) function element-wise.\nHardshrink is defined as:\nHardShrink\n(\nx\n)\n=\n{\nx\n,\nif\nx\n>\nλ\nx\n,\nif\nx\n<\n−\nλ\n0\n,\notherwise\n\\text{HardShrink}(x) =\n\\begin{cases}\nx, & \\text{ if } x > \\lambda \\\\\nx, & \\text{ if } x < -\\lambda \\\\\n0, & \\text{ otherwise }\n\\end{cases}\nHardShrink\n(\nx\n)\n=\n⎩\n⎨\n⎧\n​\nx\n,\nx\n,\n0\n,\n​\nif\nx\n>\nλ\nif\nx\n<\n−\nλ\notherwise\n​\nParameters\nlambd\n(\nfloat\n) – the\nλ\n\\lambda\nλ\nvalue for the Hardshrink formulation. Default: 0.5\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nHardshrink\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardshrink.html#hardshrink",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Hardshrink",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L740",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardshrink.html#torch.nn.Hardshrink",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardsigmoid.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ELU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Hardsigmoid",
  "page_text": "Hardsigmoid\n¶\nclass\ntorch.nn.\nHardsigmoid\n(\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the Hardsigmoid function element-wise.\nHardsigmoid is defined as:\nHardsigmoid\n(\nx\n)\n=\n{\n0\nif\nx\n≤\n−\n3\n,\n1\nif\nx\n≥\n+\n3\n,\nx\n/\n6\n+\n1\n/\n2\notherwise\n\\text{Hardsigmoid}(x) = \\begin{cases}\n    0 & \\text{if~} x \\le -3, \\\\\n    1 & \\text{if~} x \\ge +3, \\\\\n    x / 6 + 1 / 2 & \\text{otherwise}\n\\end{cases}\nHardsigmoid\n(\nx\n)\n=\n⎩\n⎨\n⎧\n​\n0\n1\nx\n/6\n+\n1/2\n​\nif\nx\n≤\n−\n3\n,\nif\nx\n≥\n+\n3\n,\notherwise\n​\nParameters\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nHardsigmoid\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardsigmoid.html#hardsigmoid",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Hardsigmoid",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L330",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardsigmoid.html#torch.nn.Hardsigmoid",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardtanh.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardshrink.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Hardtanh",
  "page_text": "Hardtanh\n¶\nclass\ntorch.nn.\nHardtanh\n(\nmin_val\n=\n-1.0\n,\nmax_val\n=\n1.0\n,\ninplace\n=\nFalse\n,\nmin_value\n=\nNone\n,\nmax_value\n=\nNone\n)\n[source]\n[source]\n¶\nApplies the HardTanh function element-wise.\nHardTanh is defined as:\nHardTanh\n(\nx\n)\n=\n{\nmax_val\nif\nx\n>\nmax_val\nmin_val\nif\nx\n<\nmin_val\nx\notherwise\n\\text{HardTanh}(x) = \\begin{cases}\n    \\text{max\\_val} & \\text{ if } x > \\text{ max\\_val } \\\\\n    \\text{min\\_val} & \\text{ if } x < \\text{ min\\_val } \\\\\n    x & \\text{ otherwise } \\\\\n\\end{cases}\nHardTanh\n(\nx\n)\n=\n⎩\n⎨\n⎧\n​\nmax_val\nmin_val\nx\n​\nif\nx\n>\nmax_val\nif\nx\n<\nmin_val\notherwise\n​\nParameters\nmin_val\n(\nfloat\n) – minimum value of the linear region range. Default: -1\nmax_val\n(\nfloat\n) – maximum value of the linear region range. Default: 1\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nKeyword arguments\nmin_value\nand\nmax_value\nhave been deprecated in favor of\nmin_val\nand\nmax_val\n.\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nHardtanh\n(\n-\n2\n,\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardtanh.html#hardtanh",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Hardtanh",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L200",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardtanh.html#torch.nn.Hardtanh",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardswish.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardsigmoid.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Hardswish",
  "page_text": "Hardswish\n¶\nclass\ntorch.nn.\nHardswish\n(\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the Hardswish function, element-wise.\nMethod described in the paper:\nSearching for MobileNetV3\n.\nHardswish is defined as:\nHardswish\n(\nx\n)\n=\n{\n0\nif\nx\n≤\n−\n3\n,\nx\nif\nx\n≥\n+\n3\n,\nx\n⋅\n(\nx\n+\n3\n)\n/\n6\notherwise\n\\text{Hardswish}(x) = \\begin{cases}\n    0 & \\text{if~} x \\le -3, \\\\\n    x & \\text{if~} x \\ge +3, \\\\\n    x \\cdot (x + 3) /6 & \\text{otherwise}\n\\end{cases}\nHardswish\n(\nx\n)\n=\n⎩\n⎨\n⎧\n​\n0\nx\nx\n⋅\n(\nx\n+\n3\n)\n/6\n​\nif\nx\n≤\n−\n3\n,\nif\nx\n≥\n+\n3\n,\notherwise\n​\nParameters\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nHardswish\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardswish.html#hardswish",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Hardswish",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L478",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardswish.html#torch.nn.Hardswish",
    "https://arxiv.org/abs/1905.02244",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardtanh.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LeakyReLU",
  "page_text": "LeakyReLU\n¶\nclass\ntorch.nn.\nLeakyReLU\n(\nnegative_slope\n=\n0.01\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the LeakyReLU function element-wise.\nLeakyReLU\n(\nx\n)\n=\nmax\n⁡\n(\n0\n,\nx\n)\n+\nnegative_slope\n∗\nmin\n⁡\n(\n0\n,\nx\n)\n\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)\nLeakyReLU\n(\nx\n)\n=\nmax\n(\n0\n,\nx\n)\n+\nnegative_slope\n∗\nmin\n(\n0\n,\nx\n)\nor\nLeakyReLU\n(\nx\n)\n=\n{\nx\n,\nif\nx\n≥\n0\nnegative_slope\n×\nx\n,\notherwise\n\\text{LeakyReLU}(x) =\n\\begin{cases}\nx, & \\text{ if } x \\geq 0 \\\\\n\\text{negative\\_slope} \\times x, & \\text{ otherwise }\n\\end{cases}\nLeakyReLU\n(\nx\n)\n=\n{\nx\n,\nnegative_slope\n×\nx\n,\n​\nif\nx\n≥\n0\notherwise\n​\nParameters\nnegative_slope\n(\nfloat\n) – Controls the angle of the negative slope (which is used for\nnegative input values). Default: 1e-2\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\nwhere\n*\nmeans, any number of additional\ndimensions\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input\nExamples:\n>>>\nm\n=\nnn\n.\nLeakyReLU\n(\n0.1\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#leakyrelu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#LeakyReLU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L783",
    "https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSigmoid.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Hardswish.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LogSigmoid",
  "page_text": "LogSigmoid\n¶\nclass\ntorch.nn.\nLogSigmoid\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nApplies the Logsigmoid function element-wise.\nLogSigmoid\n(\nx\n)\n=\nlog\n⁡\n(\n1\n1\n+\nexp\n⁡\n(\n−\nx\n)\n)\n\\text{LogSigmoid}(x) = \\log\\left(\\frac{ 1 }{ 1 + \\exp(-x)}\\right)\nLogSigmoid\n(\nx\n)\n=\nlo\ng\n(\n1\n+\nexp\n(\n−\nx\n)\n1\n​\n)\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nLogSigmoid\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSigmoid.html#logsigmoid",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#LogSigmoid",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L835",
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSigmoid.html#torch.nn.LogSigmoid",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MultiheadAttention",
  "page_text": "MultiheadAttention\n¶\nclass\ntorch.nn.\nMultiheadAttention\n(\nembed_dim\n,\nnum_heads\n,\ndropout\n=\n0.0\n,\nbias\n=\nTrue\n,\nadd_bias_kv\n=\nFalse\n,\nadd_zero_attn\n=\nFalse\n,\nkdim\n=\nNone\n,\nvdim\n=\nNone\n,\nbatch_first\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nAllows the model to jointly attend to information from different representation subspaces.\nNote\nSee\nthis tutorial\nfor an in depth discussion of the performant building blocks PyTorch offers for building your own\ntransformer layers.\nMethod described in the paper:\nAttention Is All You Need\n.\nMulti-Head Attention is defined as:\nMultiHead\n(\nQ\n,\nK\n,\nV\n)\n=\nConcat\n(\nhead\n1\n,\n…\n,\nhead\nh\n)\nW\nO\n\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1,\\dots,\\text{head}_h)W^O\nMultiHead\n(\nQ\n,\nK\n,\nV\n)\n=\nConcat\n(\nhead\n1\n​\n,\n…\n,\nhead\nh\n​\n)\nW\nO\nwhere\nhead\ni\n=\nAttention\n(\nQ\nW\ni\nQ\n,\nK\nW\ni\nK\n,\nV\nW\ni\nV\n)\n\\text{head}_i = \\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)\nhead\ni\n​\n=\nAttention\n(\nQ\nW\ni\nQ\n​\n,\nK\nW\ni\nK\n​\n,\nV\nW\ni\nV\n​\n)\n.\nnn.MultiheadAttention\nwill use the optimized implementations of\nscaled_dot_product_attention()\nwhen possible.\nIn addition to support for the new\nscaled_dot_product_attention()\nfunction, for speeding up Inference, MHA will use\nfastpath inference with support for Nested Tensors, iff:\nself attention is being computed (i.e.,\nquery\n,\nkey\n, and\nvalue\nare the same tensor).\ninputs are batched (3D) with\nbatch_first==True\nEither autograd is disabled (using\ntorch.inference_mode\nor\ntorch.no_grad\n) or no tensor argument\nrequires_grad\ntraining is disabled (using\n.eval()\n)\nadd_bias_kv\nis\nFalse\nadd_zero_attn\nis\nFalse\nkdim\nand\nvdim\nare equal to\nembed_dim\nif a\nNestedTensor\nis passed, neither\nkey_padding_mask\nnor\nattn_mask\nis passed\nautocast is disabled\nIf the optimized inference fastpath implementation is in use, a\nNestedTensor\ncan be passed for\nquery\n/\nkey\n/\nvalue\nto represent padding more efficiently than using a\npadding mask. In this case, a\nNestedTensor\nwill be returned, and an additional speedup proportional to the fraction of the input\nthat is padding can be expected.\nParameters\nembed_dim\n– Total dimension of the model.\nnum_heads\n– Number of parallel attention heads. Note that\nembed_dim\nwill be split\nacross\nnum_heads\n(i.e. each head will have dimension\nembed_dim\n//\nnum_heads\n).\ndropout\n– Dropout probability on\nattn_output_weights\n. Default:\n0.0\n(no dropout).\nbias\n– If specified, adds bias to input / output projection layers. Default:\nTrue\n.\nadd_bias_kv\n– If specified, adds bias to the key and value sequences at dim=0. Default:\nFalse\n.\nadd_zero_attn\n– If specified, adds a new batch of zeros to the key and value sequences at dim=1.\nDefault:\nFalse\n.\nkdim\n– Total number of features for keys. Default:\nNone\n(uses\nkdim=embed_dim\n).\nvdim\n– Total number of features for values. Default:\nNone\n(uses\nvdim=embed_dim\n).\nbatch_first\n– If\nTrue\n, then the input and output tensors are provided\nas (batch, seq, feature). Default:\nFalse\n(seq, batch, feature).\nExamples:\n>>>\nmultihead_attn\n=\nnn\n.\nMultiheadAttention\n(\nembed_dim\n,\nnum_heads\n)\n>>>\nattn_output\n,\nattn_output_weights\n=\nmultihead_attn\n(\nquery\n,\nkey\n,\nvalue\n)\nforward\n(\nquery\n,\nkey\n,\nvalue\n,\nkey_padding_mask\n=\nNone\n,\nneed_weights\n=\nTrue\n,\nattn_mask\n=\nNone\n,\naverage_attn_weights\n=\nTrue\n,\nis_causal\n=\nFalse\n)\n[source]\n[source]\n¶\nCompute attention outputs using query, key, and value embeddings.\nSupports optional parameters for padding, masks and attention weights.\nParameters\nquery\n(\nTensor\n) – Query embeddings of shape\n(\nL\n,\nE\nq\n)\n(L, E_q)\n(\nL\n,\nE\nq\n​\n)\nfor unbatched input,\n(\nL\n,\nN\n,\nE\nq\n)\n(L, N, E_q)\n(\nL\n,\nN\n,\nE\nq\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nL\n,\nE\nq\n)\n(N, L, E_q)\n(\nN\n,\nL\n,\nE\nq\n​\n)\nwhen\nbatch_first=True\n, where\nL\nL\nL\nis the target sequence length,\nN\nN\nN\nis the batch size, and\nE\nq\nE_q\nE\nq\n​\nis the query embedding dimension\nembed_dim\n.\nQueries are compared against key-value pairs to produce the output.\nSee “Attention Is All You Need” for more details.\nkey\n(\nTensor\n) – Key embeddings of shape\n(\nS\n,\nE\nk\n)\n(S, E_k)\n(\nS\n,\nE\nk\n​\n)\nfor unbatched input,\n(\nS\n,\nN\n,\nE\nk\n)\n(S, N, E_k)\n(\nS\n,\nN\n,\nE\nk\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nS\n,\nE\nk\n)\n(N, S, E_k)\n(\nN\n,\nS\n,\nE\nk\n​\n)\nwhen\nbatch_first=True\n, where\nS\nS\nS\nis the source sequence length,\nN\nN\nN\nis the batch size, and\nE\nk\nE_k\nE\nk\n​\nis the key embedding dimension\nkdim\n.\nSee “Attention Is All You Need” for more details.\nvalue\n(\nTensor\n) – Value embeddings of shape\n(\nS\n,\nE\nv\n)\n(S, E_v)\n(\nS\n,\nE\nv\n​\n)\nfor unbatched input,\n(\nS\n,\nN\n,\nE\nv\n)\n(S, N, E_v)\n(\nS\n,\nN\n,\nE\nv\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nS\n,\nE\nv\n)\n(N, S, E_v)\n(\nN\n,\nS\n,\nE\nv\n​\n)\nwhen\nbatch_first=True\n, where\nS\nS\nS\nis the source\nsequence length,\nN\nN\nN\nis the batch size, and\nE\nv\nE_v\nE\nv\n​\nis the value embedding dimension\nvdim\n.\nSee “Attention Is All You Need” for more details.\nkey_padding_mask\n(\nOptional\n[\nTensor\n]\n) – If specified, a mask of shape\n(\nN\n,\nS\n)\n(N, S)\n(\nN\n,\nS\n)\nindicating which elements within\nkey\nto ignore for the purpose of attention (i.e. treat as “padding”). For unbatched\nquery\n, shape should be\n(\nS\n)\n(S)\n(\nS\n)\n.\nBinary and float masks are supported.\nFor a binary mask, a\nTrue\nvalue indicates that the corresponding\nkey\nvalue will be ignored for\nthe purpose of attention. For a float mask, it will be directly added to the corresponding\nkey\nvalue.\nneed_weights\n(\nbool\n) – If specified, returns\nattn_output_weights\nin addition to\nattn_outputs\n.\nSet\nneed_weights=False\nto use the optimized\nscaled_dot_product_attention\nand achieve the best performance for MHA.\nDefault:\nTrue\n.\nattn_mask\n(\nOptional\n[\nTensor\n]\n) – If specified, a 2D or 3D mask preventing attention to certain positions. Must be of shape\n(\nL\n,\nS\n)\n(L, S)\n(\nL\n,\nS\n)\nor\n(\nN\n⋅\nnum_heads\n,\nL\n,\nS\n)\n(N\\cdot\\text{num\\_heads}, L, S)\n(\nN\n⋅\nnum_heads\n,\nL\n,\nS\n)\n, where\nN\nN\nN\nis the batch size,\nL\nL\nL\nis the target sequence length, and\nS\nS\nS\nis the source sequence length. A 2D mask will be\nbroadcasted across the batch while a 3D mask allows for a different mask for each entry in the batch.\nBinary and float masks are supported. For a binary mask, a\nTrue\nvalue indicates that the\ncorresponding position is not allowed to attend. For a float mask, the mask values will be added to\nthe attention weight.\nIf both attn_mask and key_padding_mask are supplied, their types should match.\naverage_attn_weights\n(\nbool\n) – If true, indicates that the returned\nattn_weights\nshould be averaged across\nheads. Otherwise,\nattn_weights\nare provided separately per head. Note that this flag only has an\neffect when\nneed_weights=True\n. Default:\nTrue\n(i.e. average weights across heads)\nis_causal\n(\nbool\n) – If specified, applies a causal mask as attention mask.\nDefault:\nFalse\n.\nWarning:\nis_causal\nprovides a hint that\nattn_mask\nis the\ncausal mask. Providing incorrect hints can result in\nincorrect execution, including forward and backward\ncompatibility.\nReturn type\nTuple\n[\nTensor\n,\nOptional\n[\nTensor\n]]\nOutputs:\nattn_output\n- Attention outputs of shape\n(\nL\n,\nE\n)\n(L, E)\n(\nL\n,\nE\n)\nwhen input is unbatched,\n(\nL\n,\nN\n,\nE\n)\n(L, N, E)\n(\nL\n,\nN\n,\nE\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nL\n,\nE\n)\n(N, L, E)\n(\nN\n,\nL\n,\nE\n)\nwhen\nbatch_first=True\n,\nwhere\nL\nL\nL\nis the target sequence length,\nN\nN\nN\nis the batch size, and\nE\nE\nE\nis the\nembedding dimension\nembed_dim\n.\nattn_output_weights\n- Only returned when\nneed_weights=True\n. If\naverage_attn_weights=True\n,\nreturns attention weights averaged across heads of shape\n(\nL\n,\nS\n)\n(L, S)\n(\nL\n,\nS\n)\nwhen input is unbatched or\n(\nN\n,\nL\n,\nS\n)\n(N, L, S)\n(\nN\n,\nL\n,\nS\n)\n, where\nN\nN\nN\nis the batch size,\nL\nL\nL\nis the target sequence length, and\nS\nS\nS\nis the source sequence length. If\naverage_attn_weights=False\n, returns attention weights per\nhead of shape\n(\nnum_heads\n,\nL\n,\nS\n)\n(\\text{num\\_heads}, L, S)\n(\nnum_heads\n,\nL\n,\nS\n)\nwhen input is unbatched or\n(\nN\n,\nnum_heads\n,\nL\n,\nS\n)\n(N, \\text{num\\_heads}, L, S)\n(\nN\n,\nnum_heads\n,\nL\n,\nS\n)\n.\nNote\nbatch_first\nargument is ignored for unbatched inputs.\nmerge_masks\n(\nattn_mask\n,\nkey_padding_mask\n,\nquery\n)\n[source]\n[source]\n¶\nDetermine mask type and combine masks if necessary.\nIf only one mask is provided, that mask\nand the corresponding mask type will be returned. If both masks are provided, they will be both\nexpanded to shape\n(batch_size,\nnum_heads,\nseq_len,\nseq_len)\n, combined with logical\nor\nand mask type 2 will be returned\n:param attn_mask: attention mask of shape\n(seq_len,\nseq_len)\n, mask type 0\n:param key_padding_mask: padding mask of shape\n(batch_size,\nseq_len)\n, mask type 1\n:param query: query embeddings of shape\n(batch_size,\nseq_len,\nembed_dim)\nReturns\nmerged mask\nmask_type: merged mask type (0, 1, or 2)\nReturn type\nmerged_mask\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#multiheadattention",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L973",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention",
    "https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html",
    "https://arxiv.org/abs/1706.03762",
    "https://pytorch.org/docs/stable/nested.html",
    "https://pytorch.org/docs/stable/nested.html",
    "https://pytorch.org/docs/stable/nested.html",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1139",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention.forward",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention.merge_masks",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1399",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention.merge_masks",
    "https://pytorch.org/docs/stable/generated/torch.nn.PReLU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSigmoid.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.PReLU",
  "page_text": "PReLU\n¶\nclass\ntorch.nn.\nPReLU\n(\nnum_parameters\n=\n1\n,\ninit\n=\n0.25\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies the element-wise PReLU function.\nPReLU\n(\nx\n)\n=\nmax\n⁡\n(\n0\n,\nx\n)\n+\na\n∗\nmin\n⁡\n(\n0\n,\nx\n)\n\\text{PReLU}(x) = \\max(0,x) + a * \\min(0,x)\nPReLU\n(\nx\n)\n=\nmax\n(\n0\n,\nx\n)\n+\na\n∗\nmin\n(\n0\n,\nx\n)\nor\nPReLU\n(\nx\n)\n=\n{\nx\n,\nif\nx\n≥\n0\na\nx\n,\notherwise\n\\text{PReLU}(x) =\n\\begin{cases}\nx, & \\text{ if } x \\ge 0 \\\\\nax, & \\text{ otherwise }\n\\end{cases}\nPReLU\n(\nx\n)\n=\n{\nx\n,\na\nx\n,\n​\nif\nx\n≥\n0\notherwise\n​\nHere\na\na\na\nis a learnable parameter. When called without arguments,\nnn.PReLU()\nuses a single\nparameter\na\na\na\nacross all input channels. If called with\nnn.PReLU(nChannels)\n,\na separate\na\na\na\nis used for each input channel.\nNote\nweight decay should not be used when learning\na\na\na\nfor good performance.\nNote\nChannel dim is the 2nd dim of input. When input has dims < 2, then there is\nno channel dim and the number of channels = 1.\nParameters\nnum_parameters\n(\nint\n) – number of\na\na\na\nto learn.\nAlthough it takes an int as input, there is only two values are legitimate:\n1, or the number of channels at input. Default: 1\ninit\n(\nfloat\n) – the initial value of\na\na\na\n. Default: 0.25\nShape:\nInput:\n(\n∗\n)\n( *)\n(\n∗\n)\nwhere\n*\nmeans, any number of additional\ndimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nVariables\nweight\n(\nTensor\n) – the learnable weights of shape (\nnum_parameters\n).\nExamples:\n>>>\nm\n=\nnn\n.\nPReLU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.PReLU.html#prelu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#PReLU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1450",
    "https://pytorch.org/docs/stable/generated/torch.nn.PReLU.html#torch.nn.PReLU",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ReLU",
  "page_text": "ReLU\n¶\nclass\ntorch.nn.\nReLU\n(\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the rectified linear unit function element-wise.\nReLU\n(\nx\n)\n=\n(\nx\n)\n+\n=\nmax\n⁡\n(\n0\n,\nx\n)\n\\text{ReLU}(x) = (x)^+ = \\max(0, x)\nReLU\n(\nx\n)\n=\n(\nx\n)\n+\n=\nmax\n(\n0\n,\nx\n)\nParameters\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nReLU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nAn\nimplementation\nof\nCReLU\n-\nhttps\n:\n//\narxiv\n.\norg\n/\nabs\n/\n1603.05201\n>>>\nm\n=\nnn\n.\nReLU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n.\nunsqueeze\n(\n0\n)\n>>>\noutput\n=\ntorch\n.\ncat\n((\nm\n(\ninput\n),\nm\n(\n-\ninput\n)))\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#ReLU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L97",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU6.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.PReLU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ReLU6",
  "page_text": "ReLU6\n¶\nclass\ntorch.nn.\nReLU6\n(\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the ReLU6 function element-wise.\nReLU6\n(\nx\n)\n=\nmin\n⁡\n(\nmax\n⁡\n(\n0\n,\nx\n)\n,\n6\n)\n\\text{ReLU6}(x) = \\min(\\max(0,x), 6)\nReLU6\n(\nx\n)\n=\nmin\n(\nmax\n(\n0\n,\nx\n)\n,\n6\n)\nParameters\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nReLU6\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU6.html#relu6",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#ReLU6",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L276",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU6.html#torch.nn.ReLU6",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.RReLU",
  "page_text": "RReLU\n¶\nclass\ntorch.nn.\nRReLU\n(\nlower\n=\n0.125\n,\nupper\n=\n0.3333333333333333\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the randomized leaky rectified linear unit function, element-wise.\nMethod described in the paper:\nEmpirical Evaluation of Rectified Activations in Convolutional Network\n.\nThe function is defined as:\nRReLU\n(\nx\n)\n=\n{\nx\nif\nx\n≥\n0\na\nx\notherwise\n\\text{RReLU}(x) =\n\\begin{cases}\n    x & \\text{if } x \\geq 0 \\\\\n    ax & \\text{ otherwise }\n\\end{cases}\nRReLU\n(\nx\n)\n=\n{\nx\na\nx\n​\nif\nx\n≥\n0\notherwise\n​\nwhere\na\na\na\nis randomly sampled from uniform distribution\nU\n(\nlower\n,\nupper\n)\n\\mathcal{U}(\\text{lower}, \\text{upper})\nU\n(\nlower\n,\nupper\n)\nduring training while during\nevaluation\na\na\na\nis fixed with\na\n=\nlower\n+\nupper\n2\na = \\frac{\\text{lower} + \\text{upper}}{2}\na\n=\n2\nlower\n+\nupper\n​\n.\nParameters\nlower\n(\nfloat\n) – lower bound of the uniform distribution. Default:\n1\n8\n\\frac{1}{8}\n8\n1\n​\nupper\n(\nfloat\n) – upper bound of the uniform distribution. Default:\n1\n3\n\\frac{1}{3}\n3\n1\n​\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nRReLU\n(\n0.1\n,\n0.3\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html#rrelu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#RReLU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L140",
    "https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html#torch.nn.RReLU",
    "https://arxiv.org/abs/1505.00853",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.SELU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ReLU6.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.SELU",
  "page_text": "SELU\n¶\nclass\ntorch.nn.\nSELU\n(\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the SELU function element-wise.\nSELU\n(\nx\n)\n=\nscale\n∗\n(\nmax\n⁡\n(\n0\n,\nx\n)\n+\nmin\n⁡\n(\n0\n,\nα\n∗\n(\nexp\n⁡\n(\nx\n)\n−\n1\n)\n)\n)\n\\text{SELU}(x) = \\text{scale} * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))\nSELU\n(\nx\n)\n=\nscale\n∗\n(\nmax\n(\n0\n,\nx\n)\n+\nmin\n(\n0\n,\nα\n∗\n(\nexp\n(\nx\n)\n−\n1\n)))\nwith\nα\n=\n1.6732632423543772848170429916717\n\\alpha = 1.6732632423543772848170429916717\nα\n=\n1.6732632423543772848170429916717\nand\nscale\n=\n1.0507009873554804934193349852946\n\\text{scale} = 1.0507009873554804934193349852946\nscale\n=\n1.0507009873554804934193349852946\n.\nWarning\nWhen using\nkaiming_normal\nor\nkaiming_normal_\nfor initialisation,\nnonlinearity='linear'\nshould be used instead of\nnonlinearity='selu'\nin order to get\nSelf-Normalizing Neural Networks\n.\nSee\ntorch.nn.init.calculate_gain()\nfor more information.\nMore details can be found in the paper\nSelf-Normalizing Neural Networks\n.\nParameters\ninplace\n(\nbool\n,\noptional\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nSELU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.SELU.html#selu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#SELU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L613",
    "https://pytorch.org/docs/stable/generated/torch.nn.SELU.html#torch.nn.SELU",
    "https://arxiv.org/abs/1706.02515",
    "https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.calculate_gain",
    "https://arxiv.org/abs/1706.02515",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.CELU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.CELU",
  "page_text": "CELU\n¶\nclass\ntorch.nn.\nCELU\n(\nalpha\n=\n1.0\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the CELU function element-wise.\nCELU\n(\nx\n)\n=\nmax\n⁡\n(\n0\n,\nx\n)\n+\nmin\n⁡\n(\n0\n,\nα\n∗\n(\nexp\n⁡\n(\nx\n/\nα\n)\n−\n1\n)\n)\n\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))\nCELU\n(\nx\n)\n=\nmax\n(\n0\n,\nx\n)\n+\nmin\n(\n0\n,\nα\n∗\n(\nexp\n(\nx\n/\nα\n)\n−\n1\n))\nMore details can be found in the paper\nContinuously Differentiable Exponential Linear Units\n.\nParameters\nalpha\n(\nfloat\n) – the\nα\n\\alpha\nα\nvalue for the CELU formulation. Default: 1.0\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nCELU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CELU.html#celu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#CELU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L568",
    "https://pytorch.org/docs/stable/generated/torch.nn.CELU.html#torch.nn.CELU",
    "https://arxiv.org/abs/1704.07483",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.GELU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.SELU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.GELU",
  "page_text": "GELU\n¶\nclass\ntorch.nn.\nGELU\n(\napproximate\n=\n'none'\n)\n[source]\n[source]\n¶\nApplies the Gaussian Error Linear Units function.\nGELU\n(\nx\n)\n=\nx\n∗\nΦ\n(\nx\n)\n\\text{GELU}(x) = x * \\Phi(x)\nGELU\n(\nx\n)\n=\nx\n∗\nΦ\n(\nx\n)\nwhere\nΦ\n(\nx\n)\n\\Phi(x)\nΦ\n(\nx\n)\nis the Cumulative Distribution Function for Gaussian Distribution.\nWhen the approximate argument is ‘tanh’, Gelu is estimated with:\nGELU\n(\nx\n)\n=\n0.5\n∗\nx\n∗\n(\n1\n+\nTanh\n(\n2\n/\nπ\n∗\n(\nx\n+\n0.044715\n∗\nx\n3\n)\n)\n)\n\\text{GELU}(x) = 0.5 * x * (1 + \\text{Tanh}(\\sqrt{2 / \\pi} * (x + 0.044715 * x^3)))\nGELU\n(\nx\n)\n=\n0.5\n∗\nx\n∗\n(\n1\n+\nTanh\n(\n2/\nπ\n​\n∗\n(\nx\n+\n0.044715\n∗\nx\n3\n)))\nParameters\napproximate\n(\nstr\n,\noptional\n) – the gelu approximation algorithm to use:\n'none'\n|\n'tanh'\n. Default:\n'none'\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nGELU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.GELU.html#gelu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#GELU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L698",
    "https://pytorch.org/docs/stable/generated/torch.nn.GELU.html#torch.nn.GELU",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.CELU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Sigmoid",
  "page_text": "Sigmoid\n¶\nclass\ntorch.nn.\nSigmoid\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nApplies the Sigmoid function element-wise.\nSigmoid\n(\nx\n)\n=\nσ\n(\nx\n)\n=\n1\n1\n+\nexp\n⁡\n(\n−\nx\n)\n\\text{Sigmoid}(x) = \\sigma(x) = \\frac{1}{1 + \\exp(-x)}\nSigmoid\n(\nx\n)\n=\nσ\n(\nx\n)\n=\n1\n+\nexp\n(\n−\nx\n)\n1\n​\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nSigmoid\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#sigmoid",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Sigmoid",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L306",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid",
    "https://pytorch.org/docs/stable/generated/torch.nn.SiLU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.GELU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.SiLU",
  "page_text": "SiLU\n¶\nclass\ntorch.nn.\nSiLU\n(\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the Sigmoid Linear Unit (SiLU) function, element-wise.\nThe SiLU function is also known as the swish function.\nsilu\n(\nx\n)\n=\nx\n∗\nσ\n(\nx\n)\n,\nwhere\nσ\n(\nx\n)\nis the logistic sigmoid.\n\\text{silu}(x) = x * \\sigma(x), \\text{where } \\sigma(x) \\text{ is the logistic sigmoid.}\nsilu\n(\nx\n)\n=\nx\n∗\nσ\n(\nx\n)\n,\nwhere\nσ\n(\nx\n)\nis the logistic sigmoid.\nNote\nSee\nGaussian Error Linear Units (GELUs)\nwhere the SiLU (Sigmoid Linear Unit) was originally coined, and see\nSigmoid-Weighted Linear Units for Neural Network Function Approximation\nin Reinforcement Learning\nand\nSwish:\na Self-Gated Activation Function\nwhere the SiLU was experimented with later.\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nSiLU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.SiLU.html#silu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#SiLU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L395",
    "https://pytorch.org/docs/stable/generated/torch.nn.SiLU.html#torch.nn.SiLU",
    "https://arxiv.org/abs/1606.08415",
    "https://arxiv.org/abs/1702.03118",
    "https://arxiv.org/abs/1710.05941v1",
    "https://pytorch.org/docs/stable/generated/torch.nn.Mish.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Mish",
  "page_text": "Mish\n¶\nclass\ntorch.nn.\nMish\n(\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies the Mish function, element-wise.\nMish: A Self Regularized Non-Monotonic Neural Activation Function.\nMish\n(\nx\n)\n=\nx\n∗\nTanh\n(\nSoftplus\n(\nx\n)\n)\n\\text{Mish}(x) = x * \\text{Tanh}(\\text{Softplus}(x))\nMish\n(\nx\n)\n=\nx\n∗\nTanh\n(\nSoftplus\n(\nx\n))\nNote\nSee\nMish: A Self Regularized Non-Monotonic Neural Activation Function\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nMish\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Mish.html#mish",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Mish",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L439",
    "https://pytorch.org/docs/stable/generated/torch.nn.Mish.html#torch.nn.Mish",
    "https://arxiv.org/abs/1908.08681",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.SiLU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Softplus",
  "page_text": "Softplus\n¶\nclass\ntorch.nn.\nSoftplus\n(\nbeta\n=\n1.0\n,\nthreshold\n=\n20.0\n)\n[source]\n[source]\n¶\nApplies the Softplus function element-wise.\nSoftplus\n(\nx\n)\n=\n1\nβ\n∗\nlog\n⁡\n(\n1\n+\nexp\n⁡\n(\nβ\n∗\nx\n)\n)\n\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))\nSoftplus\n(\nx\n)\n=\nβ\n1\n​\n∗\nlo\ng\n(\n1\n+\nexp\n(\nβ\n∗\nx\n))\nSoftPlus is a smooth approximation to the ReLU function and can be used\nto constrain the output of a machine to always be positive.\nFor numerical stability the implementation reverts to the linear function\nwhen\ni\nn\np\nu\nt\n×\nβ\n>\nt\nh\nr\ne\ns\nh\no\nl\nd\ninput \\times \\beta > threshold\nin\np\nu\nt\n×\nβ\n>\nt\nh\nres\nh\no\nl\nd\n.\nParameters\nbeta\n(\nfloat\n) – the\nβ\n\\beta\nβ\nvalue for the Softplus formulation. Default: 1\nthreshold\n(\nfloat\n) – values above this revert to a linear function. Default: 20\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nSoftplus\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html#softplus",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softplus",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L858",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html#torch.nn.Softplus",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softshrink.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Mish.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Softshrink",
  "page_text": "Softshrink\n¶\nclass\ntorch.nn.\nSoftshrink\n(\nlambd\n=\n0.5\n)\n[source]\n[source]\n¶\nApplies the soft shrinkage function element-wise.\nSoftShrinkage\n(\nx\n)\n=\n{\nx\n−\nλ\n,\nif\nx\n>\nλ\nx\n+\nλ\n,\nif\nx\n<\n−\nλ\n0\n,\notherwise\n\\text{SoftShrinkage}(x) =\n\\begin{cases}\nx - \\lambda, & \\text{ if } x > \\lambda \\\\\nx + \\lambda, & \\text{ if } x < -\\lambda \\\\\n0, & \\text{ otherwise }\n\\end{cases}\nSoftShrinkage\n(\nx\n)\n=\n⎩\n⎨\n⎧\n​\nx\n−\nλ\n,\nx\n+\nλ\n,\n0\n,\n​\nif\nx\n>\nλ\nif\nx\n<\n−\nλ\notherwise\n​\nParameters\nlambd\n(\nfloat\n) – the\nλ\n\\lambda\nλ\n(must be no less than zero) value for the Softshrink formulation. Default: 0.5\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nSoftshrink\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Softshrink.html#softshrink",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softshrink",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L903",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softshrink.html#torch.nn.Softshrink",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softsign.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Softsign",
  "page_text": "Softsign\n¶\nclass\ntorch.nn.\nSoftsign\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nApplies the element-wise Softsign function.\nSoftSign\n(\nx\n)\n=\nx\n1\n+\n∣\nx\n∣\n\\text{SoftSign}(x) = \\frac{x}{ 1 + |x|}\nSoftSign\n(\nx\n)\n=\n1\n+\n∣\nx\n∣\nx\n​\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nSoftsign\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Softsign.html#softsign",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softsign",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1523",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softsign.html#torch.nn.Softsign",
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softshrink.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Tanh",
  "page_text": "Tanh\n¶\nclass\ntorch.nn.\nTanh\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nApplies the Hyperbolic Tangent (Tanh) function element-wise.\nTanh is defined as:\nTanh\n(\nx\n)\n=\ntanh\n⁡\n(\nx\n)\n=\nexp\n⁡\n(\nx\n)\n−\nexp\n⁡\n(\n−\nx\n)\nexp\n⁡\n(\nx\n)\n+\nexp\n⁡\n(\n−\nx\n)\n\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)} {\\exp(x) + \\exp(-x)}\nTanh\n(\nx\n)\n=\ntanh\n(\nx\n)\n=\nexp\n(\nx\n)\n+\nexp\n(\n−\nx\n)\nexp\n(\nx\n)\n−\nexp\n(\n−\nx\n)\n​\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nTanh\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html#tanh",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Tanh",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L370",
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html#torch.nn.Tanh",
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanhshrink.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softsign.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Tanhshrink",
  "page_text": "Tanhshrink\n¶\nclass\ntorch.nn.\nTanhshrink\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nApplies the element-wise Tanhshrink function.\nTanhshrink\n(\nx\n)\n=\nx\n−\ntanh\n⁡\n(\nx\n)\n\\text{Tanhshrink}(x) = x - \\tanh(x)\nTanhshrink\n(\nx\n)\n=\nx\n−\ntanh\n(\nx\n)\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nTanhshrink\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanhshrink.html#tanhshrink",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Tanhshrink",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1546",
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanhshrink.html#torch.nn.Tanhshrink",
    "https://pytorch.org/docs/stable/generated/torch.nn.Threshold.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Threshold",
  "page_text": "Threshold\n¶\nclass\ntorch.nn.\nThreshold\n(\nthreshold\n,\nvalue\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nThresholds each element of the input Tensor.\nThreshold is defined as:\ny\n=\n{\nx\n,\nif\nx\n>\nthreshold\nvalue\n,\notherwise\ny =\n\\begin{cases}\nx, &\\text{ if } x > \\text{threshold} \\\\\n\\text{value}, &\\text{ otherwise }\n\\end{cases}\ny\n=\n{\nx\n,\nvalue\n,\n​\nif\nx\n>\nthreshold\notherwise\n​\nParameters\nthreshold\n(\nfloat\n) – The value to threshold at\nvalue\n(\nfloat\n) – The value to replace with\ninplace\n(\nbool\n) – can optionally do the operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nThreshold\n(\n0.1\n,\n20\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Threshold.html#threshold",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Threshold",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L48",
    "https://pytorch.org/docs/stable/generated/torch.nn.Threshold.html#torch.nn.Threshold",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.GLU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Tanhshrink.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.GLU",
  "page_text": "GLU\n¶\nclass\ntorch.nn.\nGLU\n(\ndim\n=\n-1\n)\n[source]\n[source]\n¶\nApplies the gated linear unit function.\nG\nL\nU\n(\na\n,\nb\n)\n=\na\n⊗\nσ\n(\nb\n)\n{GLU}(a, b)= a \\otimes \\sigma(b)\nG\nLU\n(\na\n,\nb\n)\n=\na\n⊗\nσ\n(\nb\n)\nwhere\na\na\na\nis the first half\nof the input matrices and\nb\nb\nb\nis the second half.\nParameters\ndim\n(\nint\n) – the dimension on which to split the input. Default: -1\nShape:\nInput:\n(\n∗\n1\n,\nN\n,\n∗\n2\n)\n(\\ast_1, N, \\ast_2)\n(\n∗\n1\n​\n,\nN\n,\n∗\n2\n​\n)\nwhere\n*\nmeans, any number of additional\ndimensions\nOutput:\n(\n∗\n1\n,\nM\n,\n∗\n2\n)\n(\\ast_1, M, \\ast_2)\n(\n∗\n1\n​\n,\nM\n,\n∗\n2\n​\n)\nwhere\nM\n=\nN\n/\n2\nM=N/2\nM\n=\nN\n/2\nExamples:\n>>>\nm\n=\nnn\n.\nGLU\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n4\n,\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.GLU.html#glu",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#GLU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L663",
    "https://pytorch.org/docs/stable/generated/torch.nn.GLU.html#torch.nn.GLU",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmin.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Threshold.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Softmin",
  "page_text": "Softmin\n¶\nclass\ntorch.nn.\nSoftmin\n(\ndim\n=\nNone\n)\n[source]\n[source]\n¶\nApplies the Softmin function to an n-dimensional input Tensor.\nRescales them so that the elements of the n-dimensional output Tensor\nlie in the range\n[0, 1]\nand sum to 1.\nSoftmin is defined as:\nSoftmin\n(\nx\ni\n)\n=\nexp\n⁡\n(\n−\nx\ni\n)\n∑\nj\nexp\n⁡\n(\n−\nx\nj\n)\n\\text{Softmin}(x_{i}) = \\frac{\\exp(-x_i)}{\\sum_j \\exp(-x_j)}\nSoftmin\n(\nx\ni\n​\n)\n=\n∑\nj\n​\nexp\n(\n−\nx\nj\n​\n)\nexp\n(\n−\nx\ni\n​\n)\n​\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\nwhere\n*\nmeans, any number of additional\ndimensions\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input\nParameters\ndim\n(\nint\n) – A dimension along which Softmin will be computed (so every slice\nalong dim will sum to 1).\nReturns\na Tensor of the same dimension and shape as the input, with\nvalues in the range [0, 1]\nReturn type\nNone\nExamples:\n>>>\nm\n=\nnn\n.\nSoftmin\n(\ndim\n=\n1\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmin.html#softmin",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softmin",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1569",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmin.html#torch.nn.Softmin",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.GLU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Softmax",
  "page_text": "Softmax\n¶\nclass\ntorch.nn.\nSoftmax\n(\ndim\n=\nNone\n)\n[source]\n[source]\n¶\nApplies the Softmax function to an n-dimensional input Tensor.\nRescales them so that the elements of the n-dimensional output Tensor\nlie in the range [0,1] and sum to 1.\nSoftmax is defined as:\nSoftmax\n(\nx\ni\n)\n=\nexp\n⁡\n(\nx\ni\n)\n∑\nj\nexp\n⁡\n(\nx\nj\n)\n\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\nSoftmax\n(\nx\ni\n​\n)\n=\n∑\nj\n​\nexp\n(\nx\nj\n​\n)\nexp\n(\nx\ni\n​\n)\n​\nWhen the input Tensor is a sparse tensor then the unspecified\nvalues are treated as\n-inf\n.\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\nwhere\n*\nmeans, any number of additional\ndimensions\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input\nReturns\na Tensor of the same dimension and shape as the input with\nvalues in the range [0, 1]\nParameters\ndim\n(\nint\n) – A dimension along which Softmax will be computed (so every slice\nalong dim will sum to 1).\nReturn type\nNone\nNote\nThis module doesn’t work directly with NLLLoss,\nwhich expects the Log to be computed between the Softmax and itself.\nUse\nLogSoftmax\ninstead (it’s faster and has better numerical properties).\nExamples:\n>>>\nm\n=\nnn\n.\nSoftmax\n(\ndim\n=\n1\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#softmax",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softmax",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1619",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmax2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmin.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Softmax2d",
  "page_text": "Softmax2d\n¶\nclass\ntorch.nn.\nSoftmax2d\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nApplies SoftMax over features to each spatial location.\nWhen given an image of\nChannels\nx\nHeight\nx\nWidth\n, it will\napply\nSoftmax\nto each location\n(\nC\nh\na\nn\nn\ne\nl\ns\n,\nh\ni\n,\nw\nj\n)\n(Channels, h_i, w_j)\n(\nC\nhann\ne\nl\ns\n,\nh\ni\n​\n,\nw\nj\n​\n)\nShape:\nInput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\n(same shape as input)\nReturns\na Tensor of the same dimension and shape as the input with\nvalues in the range [0, 1]\nReturn type\nNone\nExamples:\n>>>\nm\n=\nnn\n.\nSoftmax2d\n()\n>>>\n# you softmax over the 2nd dimension\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n,\n12\n,\n13\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmax2d.html#softmax2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softmax2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1678",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmax2d.html#torch.nn.Softmax2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LogSoftmax",
  "page_text": "LogSoftmax\n¶\nclass\ntorch.nn.\nLogSoftmax\n(\ndim\n=\nNone\n)\n[source]\n[source]\n¶\nApplies the\nlog\n⁡\n(\nSoftmax\n(\nx\n)\n)\n\\log(\\text{Softmax}(x))\nlo\ng\n(\nSoftmax\n(\nx\n))\nfunction to an n-dimensional input Tensor.\nThe LogSoftmax formulation can be simplified as:\nLogSoftmax\n(\nx\ni\n)\n=\nlog\n⁡\n(\nexp\n⁡\n(\nx\ni\n)\n∑\nj\nexp\n⁡\n(\nx\nj\n)\n)\n\\text{LogSoftmax}(x_{i}) = \\log\\left(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} \\right)\nLogSoftmax\n(\nx\ni\n​\n)\n=\nlo\ng\n(\n∑\nj\n​\nexp\n(\nx\nj\n​\n)\nexp\n(\nx\ni\n​\n)\n​\n)\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\nwhere\n*\nmeans, any number of additional\ndimensions\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input\nParameters\ndim\n(\nint\n) – A dimension along which LogSoftmax will be computed.\nReturns\na Tensor of the same dimension and shape as the input with\nvalues in the range [-inf, 0)\nReturn type\nNone\nExamples:\n>>>\nm\n=\nnn\n.\nLogSoftmax\n(\ndim\n=\n1\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#logsoftmax",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#LogSoftmax",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/activation.py#L1708",
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Softmax2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AdaptiveLogSoftmaxWithLoss",
  "page_text": "AdaptiveLogSoftmaxWithLoss\n¶\nclass\ntorch.nn.\nAdaptiveLogSoftmaxWithLoss\n(\nin_features\n,\nn_classes\n,\ncutoffs\n,\ndiv_value\n=\n4.0\n,\nhead_bias\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nEfficient softmax approximation.\nAs described in\nEfficient softmax approximation for GPUs by Edouard Grave, Armand Joulin,\nMoustapha Cissé, David Grangier, and Hervé Jégou\n.\nAdaptive softmax is an approximate strategy for training models with large\noutput spaces. It is most effective when the label distribution is highly\nimbalanced, for example in natural language modelling, where the word\nfrequency distribution approximately follows the\nZipf’s law\n.\nAdaptive softmax partitions the labels into several clusters, according to\ntheir frequency. These clusters may contain different number of targets\neach.\nAdditionally, clusters containing less frequent labels assign lower\ndimensional embeddings to those labels, which speeds up the computation.\nFor each minibatch, only clusters for which at least one target is\npresent are evaluated.\nThe idea is that the clusters which are accessed frequently\n(like the first one, containing most frequent labels), should also be cheap\nto compute – that is, contain a small number of assigned labels.\nWe highly recommend taking a look at the original paper for more details.\ncutoffs\nshould be an ordered Sequence of integers sorted\nin the increasing order.\nIt controls number of clusters and the partitioning of targets into\nclusters. For example setting\ncutoffs\n=\n[10,\n100,\n1000]\nmeans that first\n10\ntargets will be assigned\nto the ‘head’ of the adaptive softmax, targets\n11, 12, …, 100\nwill be\nassigned to the first cluster, and targets\n101, 102, …, 1000\nwill be\nassigned to the second cluster, while targets\n1001, 1002, …, n_classes - 1\nwill be assigned\nto the last, third cluster.\ndiv_value\nis used to compute the size of each additional cluster,\nwhich is given as\n⌊\nin_features\ndiv_value\ni\nd\nx\n⌋\n\\left\\lfloor\\frac{\\texttt{in\\_features}}{\\texttt{div\\_value}^{idx}}\\right\\rfloor\n⌊\ndiv_value\ni\nd\nx\nin_features\n​\n⌋\n,\nwhere\ni\nd\nx\nidx\ni\nd\nx\nis the cluster index (with clusters\nfor less frequent words having larger indices,\nand indices starting from\n1\n1\n1\n).\nhead_bias\nif set to True, adds a bias term to the ‘head’ of the\nadaptive softmax. See paper for details. Set to False in the official\nimplementation.\nWarning\nLabels passed as inputs to this module should be sorted according to\ntheir frequency. This means that the most frequent label should be\nrepresented by the index\n0\n, and the least frequent\nlabel should be represented by the index\nn_classes - 1\n.\nNote\nThis module returns a\nNamedTuple\nwith\noutput\nand\nloss\nfields. See further documentation for details.\nNote\nTo compute log-probabilities for all classes, the\nlog_prob\nmethod can be used.\nParameters\nin_features\n(\nint\n) – Number of features in the input tensor\nn_classes\n(\nint\n) – Number of classes in the dataset\ncutoffs\n(\nSequence\n) – Cutoffs used to assign targets to their buckets\ndiv_value\n(\nfloat\n,\noptional\n) – value used as an exponent to compute sizes\nof the clusters. Default: 4.0\nhead_bias\n(\nbool\n,\noptional\n) – If\nTrue\n, adds a bias term to the ‘head’ of the\nadaptive softmax. Default:\nFalse\nReturns\noutput\nis a Tensor of size\nN\ncontaining computed target\nlog probabilities for each example\nloss\nis a Scalar representing the computed negative\nlog likelihood loss\nReturn type\nNamedTuple\nwith\noutput\nand\nloss\nfields\nShape:\ninput:\n(\nN\n,\nin_features\n)\n(N, \\texttt{in\\_features})\n(\nN\n,\nin_features\n)\nor\n(\nin_features\n)\n(\\texttt{in\\_features})\n(\nin_features\n)\ntarget:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\nwhere each value satisfies\n0\n<\n=\ntarget[i]\n<\n=\nn_classes\n0 <= \\texttt{target[i]} <= \\texttt{n\\_classes}\n0\n<=\ntarget[i]\n<=\nn_classes\noutput1:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\noutput2:\nScalar\nlog_prob\n(\ninput\n)\n[source]\n[source]\n¶\nCompute log probabilities for all\nn_classes\n\\texttt{n\\_classes}\nn_classes\n.\nParameters\ninput\n(\nTensor\n) – a minibatch of examples\nReturns\nlog-probabilities of for each class\nc\nc\nc\nin range\n0\n<\n=\nc\n<\n=\nn_classes\n0 <= c <= \\texttt{n\\_classes}\n0\n<=\nc\n<=\nn_classes\n, where\nn_classes\n\\texttt{n\\_classes}\nn_classes\nis a\nparameter passed to\nAdaptiveLogSoftmaxWithLoss\nconstructor.\nReturn type\nTensor\nShape:\nInput:\n(\nN\n,\nin_features\n)\n(N, \\texttt{in\\_features})\n(\nN\n,\nin_features\n)\nOutput:\n(\nN\n,\nn_classes\n)\n(N, \\texttt{n\\_classes})\n(\nN\n,\nn_classes\n)\npredict\n(\ninput\n)\n[source]\n[source]\n¶\nReturn the class with the highest probability for each example in the input minibatch.\nThis is equivalent to\nself.log_prob(input).argmax(dim=1)\n, but is more efficient in some cases.\nParameters\ninput\n(\nTensor\n) – a minibatch of examples\nReturns\na class with the highest probability for each example\nReturn type\noutput (\nTensor\n)\nShape:\nInput:\n(\nN\n,\nin_features\n)\n(N, \\texttt{in\\_features})\n(\nN\n,\nin_features\n)\nOutput:\n(\nN\n)\n(N)\n(\nN\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#adaptivelogsoftmaxwithloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/adaptive.py#L20",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss",
    "https://arxiv.org/abs/1609.04309",
    "https://en.wikipedia.org/wiki/Zipf%27s_law",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss.log_prob",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/adaptive.py#L279",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss.predict",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/adaptive.py#L298",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss.predict",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.BatchNorm1d",
  "page_text": "BatchNorm1d\n¶\nclass\ntorch.nn.\nBatchNorm1d\n(\nnum_features\n,\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Batch Normalization over a 2D or 3D input.\nMethod described in the paper\nBatch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift\n.\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{\\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable parameter vectors\nof size\nC\n(where\nC\nis the number of features or channels of the input). By default, the\nelements of\nγ\n\\gamma\nγ\nare set to 1 and the elements of\nβ\n\\beta\nβ\nare set to 0.\nAt train time in the forward pass, the variance is calculated via the biased estimator,\nequivalent to\ntorch.var(input,\nunbiased=False)\n. However, the value stored in the\nmoving average of the variance is calculated via the unbiased  estimator, equivalent to\ntorch.var(input,\nunbiased=True)\n.\nAlso by default, during training this layer keeps running estimates of its\ncomputed mean and variance, which are then used for normalization during\nevaluation. The running estimates are kept with a default\nmomentum\nof 0.1.\nIf\ntrack_running_stats\nis set to\nFalse\n, this layer then does not\nkeep running estimates, and batch statistics are instead used during\nevaluation time as well.\nNote\nThis\nmomentum\nargument is different from one used in optimizer\nclasses and the conventional notion of momentum. Mathematically, the\nupdate rule for running statistics here is\nx\n^\nnew\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t\nx\n^\nnew\n​\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n​\n,\nwhere\nx\n^\n\\hat{x}\nx\n^\nis the estimated statistic and\nx\nt\nx_t\nx\nt\n​\nis the\nnew observed value.\nBecause the Batch Normalization is done over the\nC\ndimension, computing statistics\non\n(N, L)\nslices, it’s common terminology to call this Temporal Batch Normalization.\nParameters\nnum_features\n(\nint\n) – number of features or channels\nC\nC\nC\nof the input\neps\n(\nfloat\n) – a value added to the denominator for numerical stability.\nDefault: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var\ncomputation. Can be set to\nNone\nfor cumulative moving average\n(i.e. simple average). Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters. Default:\nTrue\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics, and initializes statistics\nbuffers\nrunning_mean\nand\nrunning_var\nas\nNone\n.\nWhen these buffers are\nNone\n, this module always uses batch statistics.\nin both training and eval modes. Default:\nTrue\nShape:\nInput:\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\nor\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\n, where\nN\nN\nN\nis the batch size,\nC\nC\nC\nis the number of features or channels, and\nL\nL\nL\nis the sequence length\nOutput:\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\nor\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\n(same shape as input)\nExamples:\n>>>\n# With Learnable Parameters\n>>>\nm\n=\nnn\n.\nBatchNorm1d\n(\n100\n)\n>>>\n# Without Learnable Parameters\n>>>\nm\n=\nnn\n.\nBatchNorm1d\n(\n100\n,\naffine\n=\nFalse\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n100\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#batchnorm1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L268",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d",
    "https://arxiv.org/abs/1502.03167",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.BatchNorm2d",
  "page_text": "BatchNorm2d\n¶\nclass\ntorch.nn.\nBatchNorm2d\n(\nnum_features\n,\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Batch Normalization over a 4D input.\n4D is a mini-batch of 2D inputs\nwith additional channel dimension. Method described in the paper\nBatch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift\n.\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable parameter vectors\nof size\nC\n(where\nC\nis the input size). By default, the elements of\nγ\n\\gamma\nγ\nare set\nto 1 and the elements of\nβ\n\\beta\nβ\nare set to 0. At train time in the forward pass, the\nstandard-deviation is calculated via the biased estimator, equivalent to\ntorch.var(input,\nunbiased=False)\n. However, the value stored in the moving average of the\nstandard-deviation is calculated via the unbiased  estimator, equivalent to\ntorch.var(input,\nunbiased=True)\n.\nAlso by default, during training this layer keeps running estimates of its\ncomputed mean and variance, which are then used for normalization during\nevaluation. The running estimates are kept with a default\nmomentum\nof 0.1.\nIf\ntrack_running_stats\nis set to\nFalse\n, this layer then does not\nkeep running estimates, and batch statistics are instead used during\nevaluation time as well.\nNote\nThis\nmomentum\nargument is different from one used in optimizer\nclasses and the conventional notion of momentum. Mathematically, the\nupdate rule for running statistics here is\nx\n^\nnew\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t\nx\n^\nnew\n​\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n​\n,\nwhere\nx\n^\n\\hat{x}\nx\n^\nis the estimated statistic and\nx\nt\nx_t\nx\nt\n​\nis the\nnew observed value.\nBecause the Batch Normalization is done over the\nC\ndimension, computing statistics\non\n(N, H, W)\nslices, it’s common terminology to call this Spatial Batch Normalization.\nParameters\nnum_features\n(\nint\n) –\nC\nC\nC\nfrom an expected input of size\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\neps\n(\nfloat\n) – a value added to the denominator for numerical stability.\nDefault: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var\ncomputation. Can be set to\nNone\nfor cumulative moving average\n(i.e. simple average). Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters. Default:\nTrue\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics, and initializes statistics\nbuffers\nrunning_mean\nand\nrunning_var\nas\nNone\n.\nWhen these buffers are\nNone\n, this module always uses batch statistics.\nin both training and eval modes. Default:\nTrue\nShape:\nInput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nOutput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(same shape as input)\nExamples:\n>>>\n# With Learnable Parameters\n>>>\nm\n=\nnn\n.\nBatchNorm2d\n(\n100\n)\n>>>\n# Without Learnable Parameters\n>>>\nm\n=\nnn\n.\nBatchNorm2d\n(\n100\n,\naffine\n=\nFalse\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n100\n,\n35\n,\n45\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#batchnorm2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L378",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d",
    "https://arxiv.org/abs/1502.03167",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.BatchNorm3d",
  "page_text": "BatchNorm3d\n¶\nclass\ntorch.nn.\nBatchNorm3d\n(\nnum_features\n,\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Batch Normalization over a 5D input.\n5D is a mini-batch of 3D inputs with additional channel dimension as described in the paper\nBatch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift\n.\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe mean and standard-deviation are calculated per-dimension over\nthe mini-batches and\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable parameter vectors\nof size\nC\n(where\nC\nis the input size). By default, the elements of\nγ\n\\gamma\nγ\nare set\nto 1 and the elements of\nβ\n\\beta\nβ\nare set to 0. At train time in the forward pass, the\nstandard-deviation is calculated via the biased estimator, equivalent to\ntorch.var(input,\nunbiased=False)\n. However, the value stored in the moving average of the\nstandard-deviation is calculated via the unbiased  estimator, equivalent to\ntorch.var(input,\nunbiased=True)\n.\nAlso by default, during training this layer keeps running estimates of its\ncomputed mean and variance, which are then used for normalization during\nevaluation. The running estimates are kept with a default\nmomentum\nof 0.1.\nIf\ntrack_running_stats\nis set to\nFalse\n, this layer then does not\nkeep running estimates, and batch statistics are instead used during\nevaluation time as well.\nNote\nThis\nmomentum\nargument is different from one used in optimizer\nclasses and the conventional notion of momentum. Mathematically, the\nupdate rule for running statistics here is\nx\n^\nnew\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t\nx\n^\nnew\n​\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n​\n,\nwhere\nx\n^\n\\hat{x}\nx\n^\nis the estimated statistic and\nx\nt\nx_t\nx\nt\n​\nis the\nnew observed value.\nBecause the Batch Normalization is done over the\nC\ndimension, computing statistics\non\n(N, D, H, W)\nslices, it’s common terminology to call this Volumetric Batch Normalization\nor Spatio-temporal Batch Normalization.\nParameters\nnum_features\n(\nint\n) –\nC\nC\nC\nfrom an expected input of size\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\neps\n(\nfloat\n) – a value added to the denominator for numerical stability.\nDefault: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var\ncomputation. Can be set to\nNone\nfor cumulative moving average\n(i.e. simple average). Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters. Default:\nTrue\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics, and initializes statistics\nbuffers\nrunning_mean\nand\nrunning_var\nas\nNone\n.\nWhen these buffers are\nNone\n, this module always uses batch statistics.\nin both training and eval modes. Default:\nTrue\nShape:\nInput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nOutput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(same shape as input)\nExamples:\n>>>\n# With Learnable Parameters\n>>>\nm\n=\nnn\n.\nBatchNorm3d\n(\n100\n)\n>>>\n# Without Learnable Parameters\n>>>\nm\n=\nnn\n.\nBatchNorm3d\n(\n100\n,\naffine\n=\nFalse\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n100\n,\n35\n,\n45\n,\n10\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm3d.html#batchnorm3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L489",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm3d.html#torch.nn.BatchNorm3d",
    "https://arxiv.org/abs/1502.03167",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyBatchNorm1d",
  "page_text": "LazyBatchNorm1d\n¶\nclass\ntorch.nn.\nLazyBatchNorm1d\n(\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.BatchNorm1d\nmodule with lazy initialization.\nLazy initialization based on the\nnum_features\nargument of the\nBatchNorm1d\nthat is inferred\nfrom the\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\n,\nbias\n,\nrunning_mean\nand\nrunning_var\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\neps\n(\nfloat\n) – a value added to the denominator for numerical stability.\nDefault: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var\ncomputation. Can be set to\nNone\nfor cumulative moving average\n(i.e. simple average). Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters. Default:\nTrue\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics, and initializes statistics\nbuffers\nrunning_mean\nand\nrunning_var\nas\nNone\n.\nWhen these buffers are\nNone\n, this module always uses batch statistics.\nin both training and eval modes. Default:\nTrue\ncls_to_become\n[source]\n¶\nalias of\nBatchNorm1d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm1d.html#lazybatchnorm1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#LazyBatchNorm1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L344",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm1d.html#torch.nn.LazyBatchNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L268",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm1d.html#torch.nn.LazyBatchNorm1d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyBatchNorm2d",
  "page_text": "LazyBatchNorm2d\n¶\nclass\ntorch.nn.\nLazyBatchNorm2d\n(\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.BatchNorm2d\nmodule with lazy initialization.\nLazy initialization is done for the\nnum_features\nargument of the\nBatchNorm2d\nthat is inferred\nfrom the\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\n,\nbias\n,\nrunning_mean\nand\nrunning_var\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\neps\n(\nfloat\n) – a value added to the denominator for numerical stability.\nDefault: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var\ncomputation. Can be set to\nNone\nfor cumulative moving average\n(i.e. simple average). Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters. Default:\nTrue\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics, and initializes statistics\nbuffers\nrunning_mean\nand\nrunning_var\nas\nNone\n.\nWhen these buffers are\nNone\n, this module always uses batch statistics.\nin both training and eval modes. Default:\nTrue\ncls_to_become\n[source]\n¶\nalias of\nBatchNorm2d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm2d.html#lazybatchnorm2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#LazyBatchNorm2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L455",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm2d.html#torch.nn.LazyBatchNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L378",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm2d.html#torch.nn.LazyBatchNorm2d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyBatchNorm3d",
  "page_text": "LazyBatchNorm3d\n¶\nclass\ntorch.nn.\nLazyBatchNorm3d\n(\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.BatchNorm3d\nmodule with lazy initialization.\nLazy initialization is done for the\nnum_features\nargument of the\nBatchNorm3d\nthat is inferred\nfrom the\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\n,\nbias\n,\nrunning_mean\nand\nrunning_var\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\neps\n(\nfloat\n) – a value added to the denominator for numerical stability.\nDefault: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var\ncomputation. Can be set to\nNone\nfor cumulative moving average\n(i.e. simple average). Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters. Default:\nTrue\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics, and initializes statistics\nbuffers\nrunning_mean\nand\nrunning_var\nas\nNone\n.\nWhen these buffers are\nNone\n, this module always uses batch statistics.\nin both training and eval modes. Default:\nTrue\ncls_to_become\n[source]\n¶\nalias of\nBatchNorm3d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm3d.html#lazybatchnorm3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#LazyBatchNorm3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L566",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm3d.html#torch.nn.LazyBatchNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm3d.html#torch.nn.BatchNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm3d.html#torch.nn.BatchNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L489",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm3d.html#torch.nn.LazyBatchNorm3d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm3d.html#torch.nn.BatchNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.GroupNorm",
  "page_text": "GroupNorm\n¶\nclass\ntorch.nn.\nGroupNorm\n(\nnum_groups\n,\nnum_channels\n,\neps\n=\n1e-05\n,\naffine\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Group Normalization over a mini-batch of inputs.\nThis layer implements the operation as described in\nthe paper\nGroup Normalization\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe input channels are separated into\nnum_groups\ngroups, each containing\nnum_channels\n/\nnum_groups\nchannels.\nnum_channels\nmust be divisible by\nnum_groups\n. The mean and standard-deviation are calculated\nseparately over the each group.\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable\nper-channel affine transform parameter vectors of size\nnum_channels\nif\naffine\nis\nTrue\n.\nThe variance is calculated via the biased estimator, equivalent to\ntorch.var(input, unbiased=False)\n.\nThis layer uses statistics computed from input data in both training and\nevaluation modes.\nParameters\nnum_groups\n(\nint\n) – number of groups to separate the channels into\nnum_channels\n(\nint\n) – number of channels expected in input\neps\n(\nfloat\n) – a value added to the denominator for numerical stability. Default: 1e-5\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module\nhas learnable per-channel affine parameters initialized to ones (for weights)\nand zeros (for biases). Default:\nTrue\n.\nShape:\nInput:\n(\nN\n,\nC\n,\n∗\n)\n(N, C, *)\n(\nN\n,\nC\n,\n∗\n)\nwhere\nC\n=\nnum_channels\nC=\\text{num\\_channels}\nC\n=\nnum_channels\nOutput:\n(\nN\n,\nC\n,\n∗\n)\n(N, C, *)\n(\nN\n,\nC\n,\n∗\n)\n(same shape as input)\nExamples:\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n6\n,\n10\n,\n10\n)\n>>>\n# Separate 6 channels into 3 groups\n>>>\nm\n=\nnn\n.\nGroupNorm\n(\n3\n,\n6\n)\n>>>\n# Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n>>>\nm\n=\nnn\n.\nGroupNorm\n(\n6\n,\n6\n)\n>>>\n# Put all 6 channels into a single group (equivalent with LayerNorm)\n>>>\nm\n=\nnn\n.\nGroupNorm\n(\n1\n,\n6\n)\n>>>\n# Activating the module\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html#groupnorm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#GroupNorm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L228",
    "https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html#torch.nn.GroupNorm",
    "https://arxiv.org/abs/1803.08494",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyBatchNorm3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.SyncBatchNorm",
  "page_text": "SyncBatchNorm\n¶\nclass\ntorch.nn.\nSyncBatchNorm\n(\nnum_features\n,\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\nprocess_group\n=\nNone\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Batch Normalization over a N-Dimensional input.\nThe N-D input is a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper\nBatch Normalization: Accelerating Deep Network Training by Reducing\nInternal Covariate Shift\n.\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe mean and standard-deviation are calculated per-dimension over all\nmini-batches of the same process groups.\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable parameter vectors of size\nC\n(where\nC\nis the input size).\nBy default, the elements of\nγ\n\\gamma\nγ\nare sampled from\nU\n(\n0\n,\n1\n)\n\\mathcal{U}(0, 1)\nU\n(\n0\n,\n1\n)\nand the elements of\nβ\n\\beta\nβ\nare set to 0.\nThe standard-deviation is calculated via the biased estimator, equivalent to\ntorch.var(input, unbiased=False)\n.\nAlso by default, during training this layer keeps running estimates of its\ncomputed mean and variance, which are then used for normalization during\nevaluation. The running estimates are kept with a default\nmomentum\nof 0.1.\nIf\ntrack_running_stats\nis set to\nFalse\n, this layer then does not\nkeep running estimates, and batch statistics are instead used during\nevaluation time as well.\nNote\nThis\nmomentum\nargument is different from one used in optimizer\nclasses and the conventional notion of momentum. Mathematically, the\nupdate rule for running statistics here is\nx\n^\nnew\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t\nx\n^\nnew\n​\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n​\n,\nwhere\nx\n^\n\\hat{x}\nx\n^\nis the estimated statistic and\nx\nt\nx_t\nx\nt\n​\nis the\nnew observed value.\nBecause the Batch Normalization is done for each channel in the\nC\ndimension, computing\nstatistics on\n(N,\n+)\nslices, it’s common terminology to call this Volumetric Batch\nNormalization or Spatio-temporal Batch Normalization.\nCurrently\nSyncBatchNorm\nonly supports\nDistributedDataParallel\n(DDP) with single GPU per process. Use\ntorch.nn.SyncBatchNorm.convert_sync_batchnorm()\nto convert\nBatchNorm*D\nlayer to\nSyncBatchNorm\nbefore wrapping\nNetwork with DDP.\nParameters\nnum_features\n(\nint\n) –\nC\nC\nC\nfrom an expected input of size\n(\nN\n,\nC\n,\n+\n)\n(N, C, +)\n(\nN\n,\nC\n,\n+\n)\neps\n(\nfloat\n) – a value added to the denominator for numerical stability.\nDefault:\n1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var\ncomputation. Can be set to\nNone\nfor cumulative moving average\n(i.e. simple average). Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters. Default:\nTrue\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics, and initializes statistics\nbuffers\nrunning_mean\nand\nrunning_var\nas\nNone\n.\nWhen these buffers are\nNone\n, this module always uses batch statistics.\nin both training and eval modes. Default:\nTrue\nprocess_group\n(\nOptional\n[\nAny\n]\n) – synchronization of stats happen within each process group\nindividually. Default behavior is synchronization across the whole\nworld\nShape:\nInput:\n(\nN\n,\nC\n,\n+\n)\n(N, C, +)\n(\nN\n,\nC\n,\n+\n)\nOutput:\n(\nN\n,\nC\n,\n+\n)\n(N, C, +)\n(\nN\n,\nC\n,\n+\n)\n(same shape as input)\nNote\nSynchronization of batchnorm statistics occurs only while training, i.e.\nsynchronization is disabled when\nmodel.eval()\nis set or if\nself.training\nis otherwise\nFalse\n.\nExamples:\n>>>\n# With Learnable Parameters\n>>>\nm\n=\nnn\n.\nSyncBatchNorm\n(\n100\n)\n>>>\n# creating process group (optional)\n>>>\n# ranks is a list of int identifying rank ids.\n>>>\nranks\n=\nlist\n(\nrange\n(\n8\n))\n>>>\nr1\n,\nr2\n=\nranks\n[:\n4\n],\nranks\n[\n4\n:]\n>>>\n# Note: every rank calls into new_group for every\n>>>\n# process group created, even if that rank is not\n>>>\n# part of the group.\n>>>\nprocess_groups\n=\n[\ntorch\n.\ndistributed\n.\nnew_group\n(\npids\n)\nfor\npids\nin\n[\nr1\n,\nr2\n]]\n>>>\nprocess_group\n=\nprocess_groups\n[\n0\nif\ndist\n.\nget_rank\n()\n<=\n3\nelse\n1\n]\n>>>\n# Without Learnable Parameters\n>>>\nm\n=\nnn\n.\nBatchNorm3d\n(\n100\n,\naffine\n=\nFalse\n,\nprocess_group\n=\nprocess_group\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n100\n,\n35\n,\n45\n,\n10\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\n# network is nn.BatchNorm layer\n>>>\nsync_bn_network\n=\nnn\n.\nSyncBatchNorm\n.\nconvert_sync_batchnorm\n(\nnetwork\n,\nprocess_group\n)\n>>>\n# only single gpu per process is currently supported\n>>>\nddp_sync_bn_network\n=\ntorch\n.\nnn\n.\nparallel\n.\nDistributedDataParallel\n(\n>>>\nsync_bn_network\n,\n>>>\ndevice_ids\n=\n[\nargs\n.\nlocal_rank\n],\n>>>\noutput_device\n=\nargs\n.\nlocal_rank\n)\nclassmethod\nconvert_sync_batchnorm\n(\nmodule\n,\nprocess_group\n=\nNone\n)\n[source]\n[source]\n¶\nConverts all\nBatchNorm*D\nlayers in the model to\ntorch.nn.SyncBatchNorm\nlayers.\nParameters\nmodule\n(\nnn.Module\n) – module containing one or more\nBatchNorm*D\nlayers\nprocess_group\n(\noptional\n) – process group to scope synchronization,\ndefault is the whole world\nReturns\nThe original\nmodule\nwith the converted\ntorch.nn.SyncBatchNorm\nlayers. If the original\nmodule\nis a\nBatchNorm*D\nlayer,\na new\ntorch.nn.SyncBatchNorm\nlayer object will be returned\ninstead.\nExample:\n>>>\n# Network with nn.BatchNorm layer\n>>>\nmodule\n=\ntorch\n.\nnn\n.\nSequential\n(\n>>>\ntorch\n.\nnn\n.\nLinear\n(\n20\n,\n100\n),\n>>>\ntorch\n.\nnn\n.\nBatchNorm1d\n(\n100\n),\n>>>\n)\n.\ncuda\n()\n>>>\n# creating process group (optional)\n>>>\n# ranks is a list of int identifying rank ids.\n>>>\nranks\n=\nlist\n(\nrange\n(\n8\n))\n>>>\nr1\n,\nr2\n=\nranks\n[:\n4\n],\nranks\n[\n4\n:]\n>>>\n# Note: every rank calls into new_group for every\n>>>\n# process group created, even if that rank is not\n>>>\n# part of the group.\n>>>\nprocess_groups\n=\n[\ntorch\n.\ndistributed\n.\nnew_group\n(\npids\n)\nfor\npids\nin\n[\nr1\n,\nr2\n]]\n>>>\nprocess_group\n=\nprocess_groups\n[\n0\nif\ndist\n.\nget_rank\n()\n<=\n3\nelse\n1\n]\n>>>\nsync_bn_module\n=\ntorch\n.\nnn\n.\nSyncBatchNorm\n.\nconvert_sync_batchnorm\n(\nmodule\n,\nprocess_group\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#syncbatchnorm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#SyncBatchNorm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L600",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm",
    "https://arxiv.org/abs/1502.03167",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm.convert_sync_batchnorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#SyncBatchNorm.convert_sync_batchnorm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/batchnorm.py#L822",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm.convert_sync_batchnorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.InstanceNorm1d",
  "page_text": "InstanceNorm1d\n¶\nclass\ntorch.nn.\nInstanceNorm1d\n(\nnum_features\n,\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nFalse\n,\ntrack_running_stats\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Instance Normalization.\nThis operation applies Instance Normalization\nover a 2D (unbatched) or 3D (batched) input as described in the paper\nInstance Normalization: The Missing Ingredient for Fast Stylization\n.\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch.\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable parameter vectors\nof size\nC\n(where\nC\nis the number of features or channels of the input) if\naffine\nis\nTrue\n.\nThe variance is calculated via the biased estimator, equivalent to\ntorch.var(input, unbiased=False)\n.\nBy default, this layer uses instance statistics computed from input data in\nboth training and evaluation modes.\nIf\ntrack_running_stats\nis set to\nTrue\n, during training this\nlayer keeps running estimates of its computed mean and variance, which are\nthen used for normalization during evaluation. The running estimates are\nkept with a default\nmomentum\nof 0.1.\nNote\nThis\nmomentum\nargument is different from one used in optimizer\nclasses and the conventional notion of momentum. Mathematically, the\nupdate rule for running statistics here is\nx\n^\nnew\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t\nx\n^\nnew\n​\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n​\n,\nwhere\nx\n^\n\\hat{x}\nx\n^\nis the estimated statistic and\nx\nt\nx_t\nx\nt\n​\nis the\nnew observed value.\nNote\nInstanceNorm1d\nand\nLayerNorm\nare very similar, but\nhave some subtle differences.\nInstanceNorm1d\nis applied\non each channel of channeled data like multidimensional time series, but\nLayerNorm\nis usually applied on entire sample and often in NLP\ntasks. Additionally,\nLayerNorm\napplies elementwise affine\ntransform, while\nInstanceNorm1d\nusually don’t apply affine\ntransform.\nParameters\nnum_features\n(\nint\n) – number of features or channels\nC\nC\nC\nof the input\neps\n(\nfloat\n) – a value added to the denominator for numerical stability. Default: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var computation. Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault:\nFalse\n.\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\nor\n(\nC\n,\nL\n)\n(C, L)\n(\nC\n,\nL\n)\nOutput:\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\nor\n(\nC\n,\nL\n)\n(C, L)\n(\nC\n,\nL\n)\n(same shape as input)\nExamples:\n>>>\n# Without Learnable Parameters\n>>>\nm\n=\nnn\n.\nInstanceNorm1d\n(\n100\n)\n>>>\n# With Learnable Parameters\n>>>\nm\n=\nnn\n.\nInstanceNorm1d\n(\n100\n,\naffine\n=\nTrue\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n100\n,\n40\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html#instancenorm1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/instancenorm.html#InstanceNorm1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L127",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d",
    "https://arxiv.org/abs/1607.08022",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.SyncBatchNorm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.InstanceNorm2d",
  "page_text": "InstanceNorm2d\n¶\nclass\ntorch.nn.\nInstanceNorm2d\n(\nnum_features\n,\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nFalse\n,\ntrack_running_stats\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Instance Normalization.\nThis operation applies Instance Normalization\nover a 4D input (a mini-batch of 2D inputs\nwith additional channel dimension) as described in the paper\nInstance Normalization: The Missing Ingredient for Fast Stylization\n.\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch.\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable parameter vectors\nof size\nC\n(where\nC\nis the input size) if\naffine\nis\nTrue\n.\nThe standard-deviation is calculated via the biased estimator, equivalent to\ntorch.var(input, unbiased=False)\n.\nBy default, this layer uses instance statistics computed from input data in\nboth training and evaluation modes.\nIf\ntrack_running_stats\nis set to\nTrue\n, during training this\nlayer keeps running estimates of its computed mean and variance, which are\nthen used for normalization during evaluation. The running estimates are\nkept with a default\nmomentum\nof 0.1.\nNote\nThis\nmomentum\nargument is different from one used in optimizer\nclasses and the conventional notion of momentum. Mathematically, the\nupdate rule for running statistics here is\nx\n^\nnew\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t\nx\n^\nnew\n​\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n​\n,\nwhere\nx\n^\n\\hat{x}\nx\n^\nis the estimated statistic and\nx\nt\nx_t\nx\nt\n​\nis the\nnew observed value.\nNote\nInstanceNorm2d\nand\nLayerNorm\nare very similar, but\nhave some subtle differences.\nInstanceNorm2d\nis applied\non each channel of channeled data like RGB images, but\nLayerNorm\nis usually applied on entire sample and often in NLP\ntasks. Additionally,\nLayerNorm\napplies elementwise affine\ntransform, while\nInstanceNorm2d\nusually don’t apply affine\ntransform.\nParameters\nnum_features\n(\nint\n) –\nC\nC\nC\nfrom an expected input of size\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\neps\n(\nfloat\n) – a value added to the denominator for numerical stability. Default: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var computation. Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault:\nFalse\n.\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\nOutput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\n(same shape as input)\nExamples:\n>>>\n# Without Learnable Parameters\n>>>\nm\n=\nnn\n.\nInstanceNorm2d\n(\n100\n)\n>>>\n# With Learnable Parameters\n>>>\nm\n=\nnn\n.\nInstanceNorm2d\n(\n100\n,\naffine\n=\nTrue\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n100\n,\n35\n,\n45\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#instancenorm2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/instancenorm.html#InstanceNorm2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L241",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d",
    "https://arxiv.org/abs/1607.08022",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.InstanceNorm3d",
  "page_text": "InstanceNorm3d\n¶\nclass\ntorch.nn.\nInstanceNorm3d\n(\nnum_features\n,\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nFalse\n,\ntrack_running_stats\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Instance Normalization.\nThis operation applies Instance Normalization\nover a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper\nInstance Normalization: The Missing Ingredient for Fast Stylization\n.\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe mean and standard-deviation are calculated per-dimension separately\nfor each object in a mini-batch.\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable parameter vectors\nof size C (where C is the input size) if\naffine\nis\nTrue\n.\nThe standard-deviation is calculated via the biased estimator, equivalent to\ntorch.var(input, unbiased=False)\n.\nBy default, this layer uses instance statistics computed from input data in\nboth training and evaluation modes.\nIf\ntrack_running_stats\nis set to\nTrue\n, during training this\nlayer keeps running estimates of its computed mean and variance, which are\nthen used for normalization during evaluation. The running estimates are\nkept with a default\nmomentum\nof 0.1.\nNote\nThis\nmomentum\nargument is different from one used in optimizer\nclasses and the conventional notion of momentum. Mathematically, the\nupdate rule for running statistics here is\nx\n^\nnew\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n\\hat{x}_\\text{new} = (1 - \\text{momentum}) \\times \\hat{x} + \\text{momentum} \\times x_t\nx\n^\nnew\n​\n=\n(\n1\n−\nmomentum\n)\n×\nx\n^\n+\nmomentum\n×\nx\nt\n​\n,\nwhere\nx\n^\n\\hat{x}\nx\n^\nis the estimated statistic and\nx\nt\nx_t\nx\nt\n​\nis the\nnew observed value.\nNote\nInstanceNorm3d\nand\nLayerNorm\nare very similar, but\nhave some subtle differences.\nInstanceNorm3d\nis applied\non each channel of channeled data like 3D models with RGB color, but\nLayerNorm\nis usually applied on entire sample and often in NLP\ntasks. Additionally,\nLayerNorm\napplies elementwise affine\ntransform, while\nInstanceNorm3d\nusually don’t apply affine\ntransform.\nParameters\nnum_features\n(\nint\n) –\nC\nC\nC\nfrom an expected input of size\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\neps\n(\nfloat\n) – a value added to the denominator for numerical stability. Default: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var computation. Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault:\nFalse\n.\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\nOutput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(same shape as input)\nExamples:\n>>>\n# Without Learnable Parameters\n>>>\nm\n=\nnn\n.\nInstanceNorm3d\n(\n100\n)\n>>>\n# With Learnable Parameters\n>>>\nm\n=\nnn\n.\nInstanceNorm3d\n(\n100\n,\naffine\n=\nTrue\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n100\n,\n35\n,\n45\n,\n10\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html#instancenorm3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/instancenorm.html#InstanceNorm3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L358",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d",
    "https://arxiv.org/abs/1607.08022",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyInstanceNorm1d",
  "page_text": "LazyInstanceNorm1d\n¶\nclass\ntorch.nn.\nLazyInstanceNorm1d\n(\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.InstanceNorm1d\nmodule with lazy initialization of the\nnum_features\nargument.\nThe\nnum_features\nargument of the\nInstanceNorm1d\nis inferred from the\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\n,\nbias\n,\nrunning_mean\nand\nrunning_var\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nnum_features\n–\nC\nC\nC\nfrom an expected input of size\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\nor\n(\nC\n,\nL\n)\n(C, L)\n(\nC\n,\nL\n)\neps\n(\nfloat\n) – a value added to the denominator for numerical stability. Default: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var computation. Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault:\nFalse\n.\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\nor\n(\nC\n,\nL\n)\n(C, L)\n(\nC\n,\nL\n)\nOutput:\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\nor\n(\nC\n,\nL\n)\n(C, L)\n(\nC\n,\nL\n)\n(same shape as input)\ncls_to_become\n[source]\n¶\nalias of\nInstanceNorm1d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm1d.html#lazyinstancenorm1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/instancenorm.html#LazyInstanceNorm1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm1d.html#torch.nn.LazyInstanceNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L127",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm1d.html#torch.nn.LazyInstanceNorm1d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyInstanceNorm2d",
  "page_text": "LazyInstanceNorm2d\n¶\nclass\ntorch.nn.\nLazyInstanceNorm2d\n(\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.InstanceNorm2d\nmodule with lazy initialization of the\nnum_features\nargument.\nThe\nnum_features\nargument of the\nInstanceNorm2d\nis inferred from the\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\n,\nbias\n,\nrunning_mean\nand\nrunning_var\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nnum_features\n–\nC\nC\nC\nfrom an expected input of size\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\neps\n(\nfloat\n) – a value added to the denominator for numerical stability. Default: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var computation. Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault:\nFalse\n.\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\nOutput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\n(same shape as input)\ncls_to_become\n[source]\n¶\nalias of\nInstanceNorm2d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm2d.html#lazyinstancenorm2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/instancenorm.html#LazyInstanceNorm2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L320",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm2d.html#torch.nn.LazyInstanceNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L241",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm2d.html#torch.nn.LazyInstanceNorm2d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyInstanceNorm3d",
  "page_text": "LazyInstanceNorm3d\n¶\nclass\ntorch.nn.\nLazyInstanceNorm3d\n(\neps\n=\n1e-05\n,\nmomentum\n=\n0.1\n,\naffine\n=\nTrue\n,\ntrack_running_stats\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.InstanceNorm3d\nmodule with lazy initialization of the\nnum_features\nargument.\nThe\nnum_features\nargument of the\nInstanceNorm3d\nis inferred from the\ninput.size(1)\n.\nThe attributes that will be lazily initialized are\nweight\n,\nbias\n,\nrunning_mean\nand\nrunning_var\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nnum_features\n–\nC\nC\nC\nfrom an expected input of size\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\neps\n(\nfloat\n) – a value added to the denominator for numerical stability. Default: 1e-5\nmomentum\n(\nOptional\n[\nfloat\n]\n) – the value used for the running_mean and running_var computation. Default: 0.1\naffine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault:\nFalse\n.\ntrack_running_stats\n(\nbool\n) – a boolean value that when set to\nTrue\n, this\nmodule tracks the running mean and variance, and when set to\nFalse\n,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default:\nFalse\nShape:\nInput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\nOutput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(same shape as input)\ncls_to_become\n[source]\n¶\nalias of\nInstanceNorm3d\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm3d.html#lazyinstancenorm3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/instancenorm.html#LazyInstanceNorm3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L436",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm3d.html#torch.nn.LazyInstanceNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/instancenorm.py#L358",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm3d.html#torch.nn.LazyInstanceNorm3d.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LayerNorm",
  "page_text": "LayerNorm\n¶\nclass\ntorch.nn.\nLayerNorm\n(\nnormalized_shape\n,\neps\n=\n1e-05\n,\nelementwise_affine\n=\nTrue\n,\nbias\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Layer Normalization over a mini-batch of inputs.\nThis layer implements the operation as described in\nthe paper\nLayer Normalization\ny\n=\nx\n−\nE\n[\nx\n]\nV\na\nr\n[\nx\n]\n+\nϵ\n∗\nγ\n+\nβ\ny = \\frac{x - \\mathrm{E}[x]}{ \\sqrt{\\mathrm{Var}[x] + \\epsilon}} * \\gamma + \\beta\ny\n=\nVar\n[\nx\n]\n+\nϵ\n​\nx\n−\nE\n[\nx\n]\n​\n∗\nγ\n+\nβ\nThe mean and standard-deviation are calculated over the last\nD\ndimensions, where\nD\nis the dimension of\nnormalized_shape\n. For example, if\nnormalized_shape\nis\n(3,\n5)\n(a 2-dimensional shape), the mean and standard-deviation are computed over\nthe last 2 dimensions of the input (i.e.\ninput.mean((-2,\n-1))\n).\nγ\n\\gamma\nγ\nand\nβ\n\\beta\nβ\nare learnable affine transform parameters of\nnormalized_shape\nif\nelementwise_affine\nis\nTrue\n.\nThe variance is calculated via the biased estimator, equivalent to\ntorch.var(input, unbiased=False)\n.\nNote\nUnlike Batch Normalization and Instance Normalization, which applies\nscalar scale and bias for each entire channel/plane with the\naffine\noption, Layer Normalization applies per-element scale and\nbias with\nelementwise_affine\n.\nThis layer uses statistics computed from input data in both training and\nevaluation modes.\nParameters\nnormalized_shape\n(\nint\nor\nlist\nor\ntorch.Size\n) –\ninput shape from an expected input\nof size\n[\n∗\n×\nnormalized_shape\n[\n0\n]\n×\nnormalized_shape\n[\n1\n]\n×\n…\n×\nnormalized_shape\n[\n−\n1\n]\n]\n[* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n    \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n[\n∗\n×\nnormalized_shape\n[\n0\n]\n×\nnormalized_shape\n[\n1\n]\n×\n…\n×\nnormalized_shape\n[\n−\n1\n]]\nIf a single integer is used, it is treated as a singleton list, and this module will\nnormalize over the last dimension which is expected to be of that specific size.\neps\n(\nfloat\n) – a value added to the denominator for numerical stability. Default: 1e-5\nelementwise_affine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module\nhas learnable per-element affine parameters initialized to ones (for weights)\nand zeros (for biases). Default:\nTrue\n.\nbias\n(\nbool\n) – If set to\nFalse\n, the layer will not learn an additive bias (only relevant if\nelementwise_affine\nis\nTrue\n). Default:\nTrue\n.\nVariables\nweight\n– the learnable weights of the module of shape\nnormalized_shape\n\\text{normalized\\_shape}\nnormalized_shape\nwhen\nelementwise_affine\nis set to\nTrue\n.\nThe values are initialized to 1.\nbias\n– the learnable bias of the module of shape\nnormalized_shape\n\\text{normalized\\_shape}\nnormalized_shape\nwhen\nelementwise_affine\nis set to\nTrue\n.\nThe values are initialized to 0.\nShape:\nInput:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\nOutput:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\n(same shape as input)\nExamples:\n>>>\n# NLP Example\n>>>\nbatch\n,\nsentence_length\n,\nembedding_dim\n=\n20\n,\n5\n,\n10\n>>>\nembedding\n=\ntorch\n.\nrandn\n(\nbatch\n,\nsentence_length\n,\nembedding_dim\n)\n>>>\nlayer_norm\n=\nnn\n.\nLayerNorm\n(\nembedding_dim\n)\n>>>\n# Activate module\n>>>\nlayer_norm\n(\nembedding\n)\n>>>\n>>>\n# Image Example\n>>>\nN\n,\nC\n,\nH\n,\nW\n=\n20\n,\n5\n,\n10\n,\n10\n>>>\ninput\n=\ntorch\n.\nrandn\n(\nN\n,\nC\n,\nH\n,\nW\n)\n>>>\n# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n>>>\n# as shown in the image below\n>>>\nlayer_norm\n=\nnn\n.\nLayerNorm\n([\nC\n,\nH\n,\nW\n])\n>>>\noutput\n=\nlayer_norm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#layernorm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#LayerNorm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L94",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm",
    "https://arxiv.org/abs/1607.06450",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://pytorch.org/docs/stable/size.html#torch.Size",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_images/layer_norm.jpg",
    "https://pytorch.org/docs/stable/generated/torch.nn.LocalResponseNorm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyInstanceNorm3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LocalResponseNorm",
  "page_text": "LocalResponseNorm\n¶\nclass\ntorch.nn.\nLocalResponseNorm\n(\nsize\n,\nalpha\n=\n0.0001\n,\nbeta\n=\n0.75\n,\nk\n=\n1.0\n)\n[source]\n[source]\n¶\nApplies local response normalization over an input signal.\nThe input signal is composed of several input planes, where channels occupy the second dimension.\nApplies normalization across channels.\nb\nc\n=\na\nc\n(\nk\n+\nα\nn\n∑\nc\n′\n=\nmax\n⁡\n(\n0\n,\nc\n−\nn\n/\n2\n)\nmin\n⁡\n(\nN\n−\n1\n,\nc\n+\nn\n/\n2\n)\na\nc\n′\n2\n)\n−\nβ\nb_{c} = a_{c}\\left(k + \\frac{\\alpha}{n}\n\\sum_{c'=\\max(0, c-n/2)}^{\\min(N-1,c+n/2)}a_{c'}^2\\right)^{-\\beta}\nb\nc\n​\n=\na\nc\n​\n​\nk\n+\nn\nα\n​\nc\n′\n=\nm\na\nx\n(\n0\n,\nc\n−\nn\n/2\n)\n∑\nm\ni\nn\n(\nN\n−\n1\n,\nc\n+\nn\n/2\n)\n​\na\nc\n′\n2\n​\n​\n−\nβ\nParameters\nsize\n(\nint\n) – amount of neighbouring channels used for normalization\nalpha\n(\nfloat\n) – multiplicative factor. Default: 0.0001\nbeta\n(\nfloat\n) – exponent. Default: 0.75\nk\n(\nfloat\n) – additive factor. Default: 1\nShape:\nInput:\n(\nN\n,\nC\n,\n∗\n)\n(N, C, *)\n(\nN\n,\nC\n,\n∗\n)\nOutput:\n(\nN\n,\nC\n,\n∗\n)\n(N, C, *)\n(\nN\n,\nC\n,\n∗\n)\n(same shape as input)\nExamples:\n>>>\nlrn\n=\nnn\n.\nLocalResponseNorm\n(\n2\n)\n>>>\nsignal_2d\n=\ntorch\n.\nrandn\n(\n32\n,\n5\n,\n24\n,\n24\n)\n>>>\nsignal_4d\n=\ntorch\n.\nrandn\n(\n16\n,\n5\n,\n7\n,\n7\n,\n7\n,\n7\n)\n>>>\noutput_2d\n=\nlrn\n(\nsignal_2d\n)\n>>>\noutput_4d\n=\nlrn\n(\nsignal_4d\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LocalResponseNorm.html#localresponsenorm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#LocalResponseNorm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L17",
    "https://pytorch.org/docs/stable/generated/torch.nn.LocalResponseNorm.html#torch.nn.LocalResponseNorm",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.RMSNorm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.RMSNorm",
  "page_text": "RMSNorm\n¶\nclass\ntorch.nn.\nRMSNorm\n(\nnormalized_shape\n,\neps\n=\nNone\n,\nelementwise_affine\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Root Mean Square Layer Normalization over a mini-batch of inputs.\nThis layer implements the operation as described in\nthe paper\nRoot Mean Square Layer Normalization\ny\ni\n=\nx\ni\nR\nM\nS\n(\nx\n)\n∗\nγ\ni\n,\nwhere\nRMS\n(\nx\n)\n=\nϵ\n+\n1\nn\n∑\ni\n=\n1\nn\nx\ni\n2\ny_i = \\frac{x_i}{\\mathrm{RMS}(x)} * \\gamma_i, \\quad\n\\text{where} \\quad \\text{RMS}(x) = \\sqrt{\\epsilon + \\frac{1}{n} \\sum_{i=1}^{n} x_i^2}\ny\ni\n​\n=\nRMS\n(\nx\n)\nx\ni\n​\n​\n∗\nγ\ni\n​\n,\nwhere\nRMS\n(\nx\n)\n=\nϵ\n+\nn\n1\n​\ni\n=\n1\n∑\nn\n​\nx\ni\n2\n​\n​\nThe RMS is taken over the last\nD\ndimensions, where\nD\nis the dimension of\nnormalized_shape\n. For example, if\nnormalized_shape\nis\n(3,\n5)\n(a 2-dimensional shape), the RMS is computed over\nthe last 2 dimensions of the input.\nParameters\nnormalized_shape\n(\nint\nor\nlist\nor\ntorch.Size\n) –\ninput shape from an expected input\nof size\n[\n∗\n×\nnormalized_shape\n[\n0\n]\n×\nnormalized_shape\n[\n1\n]\n×\n…\n×\nnormalized_shape\n[\n−\n1\n]\n]\n[* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n    \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n[\n∗\n×\nnormalized_shape\n[\n0\n]\n×\nnormalized_shape\n[\n1\n]\n×\n…\n×\nnormalized_shape\n[\n−\n1\n]]\nIf a single integer is used, it is treated as a singleton list, and this module will\nnormalize over the last dimension which is expected to be of that specific size.\neps\n(\nOptional\n[\nfloat\n]\n) – a value added to the denominator for numerical stability. Default:\ntorch.finfo(x.dtype).eps()\nelementwise_affine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module\nhas learnable per-element affine parameters initialized to ones (for weights). Default:\nTrue\n.\nShape:\nInput:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\nOutput:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\n(same shape as input)\nExamples:\n>>>\nrms_norm\n=\nnn\n.\nRMSNorm\n([\n2\n,\n3\n])\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n2\n,\n3\n)\n>>>\nrms_norm\n(\ninput\n)\nextra_repr\n(\n)\n[source]\n[source]\n¶\nExtra information about the module.\nReturn type\nstr\nforward\n(\nx\n)\n[source]\n[source]\n¶\nRuns forward pass.\nReturn type\nTensor\nreset_parameters\n(\n)\n[source]\n[source]\n¶\nResets parameters based on their initialization used in __init__.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.RMSNorm.html#rmsnorm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#RMSNorm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L321",
    "https://pytorch.org/docs/stable/generated/torch.nn.RMSNorm.html#torch.nn.RMSNorm",
    "https://arxiv.org/pdf/1910.07467.pdf",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://pytorch.org/docs/stable/size.html#torch.Size",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#RMSNorm.extra_repr",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L403",
    "https://pytorch.org/docs/stable/generated/torch.nn.RMSNorm.html#torch.nn.RMSNorm.extra_repr",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#RMSNorm.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L397",
    "https://pytorch.org/docs/stable/generated/torch.nn.RMSNorm.html#torch.nn.RMSNorm.forward",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#RMSNorm.reset_parameters",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L390",
    "https://pytorch.org/docs/stable/generated/torch.nn.RMSNorm.html#torch.nn.RMSNorm.reset_parameters",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNBase.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LocalResponseNorm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.RNNBase",
  "page_text": "RNNBase\n¶\nclass\ntorch.nn.\nRNNBase\n(\nmode\n,\ninput_size\n,\nhidden_size\n,\nnum_layers\n=\n1\n,\nbias\n=\nTrue\n,\nbatch_first\n=\nFalse\n,\ndropout\n=\n0.0\n,\nbidirectional\n=\nFalse\n,\nproj_size\n=\n0\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nBase class for RNN modules (RNN, LSTM, GRU).\nImplements aspects of RNNs shared by the RNN, LSTM, and GRU classes, such as module initialization\nand utility methods for parameter storage management.\nNote\nThe forward method is not implemented by the RNNBase class.\nNote\nLSTM and GRU classes override some methods implemented by RNNBase.\nflatten_parameters\n(\n)\n[source]\n[source]\n¶\nReset parameter data pointer so that they can use faster code paths.\nRight now, this works only if the module is on the GPU and cuDNN is enabled.\nOtherwise, it’s a no-op.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNBase.html#rnnbase",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#RNNBase",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/rnn.py#L48",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNBase.html#torch.nn.RNNBase",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#RNNBase.flatten_parameters",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/rnn.py#L224",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNBase.html#torch.nn.RNNBase.flatten_parameters",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.RMSNorm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.RNN",
  "page_text": "RNN\n¶\nclass\ntorch.nn.\nRNN\n(\ninput_size\n,\nhidden_size\n,\nnum_layers\n=\n1\n,\nnonlinearity\n=\n'tanh'\n,\nbias\n=\nTrue\n,\nbatch_first\n=\nFalse\n,\ndropout\n=\n0.0\n,\nbidirectional\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApply a multi-layer Elman RNN with\ntanh\n⁡\n\\tanh\ntanh\nor\nReLU\n\\text{ReLU}\nReLU\nnon-linearity to an input sequence. For each element in the input sequence,\neach layer computes the following function:\nh\nt\n=\ntanh\n⁡\n(\nx\nt\nW\ni\nh\nT\n+\nb\ni\nh\n+\nh\nt\n−\n1\nW\nh\nh\nT\n+\nb\nh\nh\n)\nh_t = \\tanh(x_t W_{ih}^T + b_{ih} + h_{t-1}W_{hh}^T + b_{hh})\nh\nt\n​\n=\ntanh\n(\nx\nt\n​\nW\nih\nT\n​\n+\nb\nih\n​\n+\nh\nt\n−\n1\n​\nW\nhh\nT\n​\n+\nb\nhh\n​\n)\nwhere\nh\nt\nh_t\nh\nt\n​\nis the hidden state at time\nt\n,\nx\nt\nx_t\nx\nt\n​\nis\nthe input at time\nt\n, and\nh\n(\nt\n−\n1\n)\nh_{(t-1)}\nh\n(\nt\n−\n1\n)\n​\nis the hidden state of the\nprevious layer at time\nt-1\nor the initial hidden state at time\n0\n.\nIf\nnonlinearity\nis\n'relu'\n, then\nReLU\n\\text{ReLU}\nReLU\nis used instead of\ntanh\n⁡\n\\tanh\ntanh\n.\n# Efficient implementation equivalent to the following with bidirectional=False\ndef\nforward\n(\nx\n,\nhx\n=\nNone\n):\nif\nbatch_first\n:\nx\n=\nx\n.\ntranspose\n(\n0\n,\n1\n)\nseq_len\n,\nbatch_size\n,\n_\n=\nx\n.\nsize\n()\nif\nhx\nis\nNone\n:\nhx\n=\ntorch\n.\nzeros\n(\nnum_layers\n,\nbatch_size\n,\nhidden_size\n)\nh_t_minus_1\n=\nhx\nh_t\n=\nhx\noutput\n=\n[]\nfor\nt\nin\nrange\n(\nseq_len\n):\nfor\nlayer\nin\nrange\n(\nnum_layers\n):\nh_t\n[\nlayer\n]\n=\ntorch\n.\ntanh\n(\nx\n[\nt\n]\n@\nweight_ih\n[\nlayer\n]\n.\nT\n+\nbias_ih\n[\nlayer\n]\n+\nh_t_minus_1\n[\nlayer\n]\n@\nweight_hh\n[\nlayer\n]\n.\nT\n+\nbias_hh\n[\nlayer\n]\n)\noutput\n.\nappend\n(\nh_t\n[\n-\n1\n])\nh_t_minus_1\n=\nh_t\noutput\n=\ntorch\n.\nstack\n(\noutput\n)\nif\nbatch_first\n:\noutput\n=\noutput\n.\ntranspose\n(\n0\n,\n1\n)\nreturn\noutput\n,\nh_t\nParameters\ninput_size\n– The number of expected features in the input\nx\nhidden_size\n– The number of features in the hidden state\nh\nnum_layers\n– Number of recurrent layers. E.g., setting\nnum_layers=2\nwould mean stacking two RNNs together to form a\nstacked RNN\n,\nwith the second RNN taking in outputs of the first RNN and\ncomputing the final results. Default: 1\nnonlinearity\n– The non-linearity to use. Can be either\n'tanh'\nor\n'relu'\n. Default:\n'tanh'\nbias\n– If\nFalse\n, then the layer does not use bias weights\nb_ih\nand\nb_hh\n.\nDefault:\nTrue\nbatch_first\n– If\nTrue\n, then the input and output tensors are provided\nas\n(batch, seq, feature)\ninstead of\n(seq, batch, feature)\n.\nNote that this does not apply to hidden or cell states. See the\nInputs/Outputs sections below for details.  Default:\nFalse\ndropout\n– If non-zero, introduces a\nDropout\nlayer on the outputs of each\nRNN layer except the last layer, with dropout probability equal to\ndropout\n. Default: 0\nbidirectional\n– If\nTrue\n, becomes a bidirectional RNN. Default:\nFalse\nInputs: input, hx\ninput\n: tensor of shape\n(\nL\n,\nH\ni\nn\n)\n(L, H_{in})\n(\nL\n,\nH\nin\n​\n)\nfor unbatched input,\n(\nL\n,\nN\n,\nH\ni\nn\n)\n(L, N, H_{in})\n(\nL\n,\nN\n,\nH\nin\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nL\n,\nH\ni\nn\n)\n(N, L, H_{in})\n(\nN\n,\nL\n,\nH\nin\n​\n)\nwhen\nbatch_first=True\ncontaining the features of\nthe input sequence.  The input can also be a packed variable length sequence.\nSee\ntorch.nn.utils.rnn.pack_padded_sequence()\nor\ntorch.nn.utils.rnn.pack_sequence()\nfor details.\nhx\n: tensor of shape\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, H_{out})\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n​\n)\nfor unbatched input or\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, N, H_{out})\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n​\n)\ncontaining the initial hidden\nstate for the input sequence batch. Defaults to zeros if not provided.\nwhere:\nN\n=\nbatch size\nL\n=\nsequence length\nD\n=\n2\nif bidirectional=True otherwise\n1\nH\ni\nn\n=\ninput_size\nH\no\nu\nt\n=\nhidden_size\n\\begin{aligned}\n    N ={} & \\text{batch size} \\\\\n    L ={} & \\text{sequence length} \\\\\n    D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n    H_{in} ={} & \\text{input\\_size} \\\\\n    H_{out} ={} & \\text{hidden\\_size}\n\\end{aligned}\nN\n=\nL\n=\nD\n=\nH\nin\n​\n=\nH\no\nu\nt\n​\n=\n​\nbatch size\nsequence length\n2\nif bidirectional=True otherwise\n1\ninput_size\nhidden_size\n​\nOutputs: output, h_n\noutput\n: tensor of shape\n(\nL\n,\nD\n∗\nH\no\nu\nt\n)\n(L, D * H_{out})\n(\nL\n,\nD\n∗\nH\no\nu\nt\n​\n)\nfor unbatched input,\n(\nL\n,\nN\n,\nD\n∗\nH\no\nu\nt\n)\n(L, N, D * H_{out})\n(\nL\n,\nN\n,\nD\n∗\nH\no\nu\nt\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nL\n,\nD\n∗\nH\no\nu\nt\n)\n(N, L, D * H_{out})\n(\nN\n,\nL\n,\nD\n∗\nH\no\nu\nt\n​\n)\nwhen\nbatch_first=True\ncontaining the output features\n(h_t)\nfrom the last layer of the RNN, for each\nt\n. If a\ntorch.nn.utils.rnn.PackedSequence\nhas been given as the input, the output\nwill also be a packed sequence.\nh_n\n: tensor of shape\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, H_{out})\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n​\n)\nfor unbatched input or\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, N, H_{out})\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n​\n)\ncontaining the final hidden state\nfor each element in the batch.\nVariables\nweight_ih_l[k]\n– the learnable input-hidden weights of the k-th layer,\nof shape\n(hidden_size, input_size)\nfor\nk = 0\n. Otherwise, the shape is\n(hidden_size, num_directions * hidden_size)\nweight_hh_l[k]\n– the learnable hidden-hidden weights of the k-th layer,\nof shape\n(hidden_size, hidden_size)\nbias_ih_l[k]\n– the learnable input-hidden bias of the k-th layer,\nof shape\n(hidden_size)\nbias_hh_l[k]\n– the learnable hidden-hidden bias of the k-th layer,\nof shape\n(hidden_size)\nNote\nAll the weights and biases are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\n1\nhidden_size\nk = \\frac{1}{\\text{hidden\\_size}}\nk\n=\nhidden_size\n1\n​\nNote\nFor bidirectional RNNs, forward and backward are directions 0 and 1 respectively.\nExample of splitting the output layers when\nbatch_first=False\n:\noutput.view(seq_len,\nbatch,\nnum_directions,\nhidden_size)\n.\nNote\nbatch_first\nargument is ignored for unbatched inputs.\nWarning\nThere are known non-determinism issues for RNN functions on some versions of cuDNN and CUDA.\nYou can enforce deterministic behavior by setting the following environment variables:\nOn CUDA 10.1, set environment variable\nCUDA_LAUNCH_BLOCKING=1\n.\nThis may affect performance.\nOn CUDA 10.2 or later, set environment variable\n(note the leading colon symbol)\nCUBLAS_WORKSPACE_CONFIG=:16:8\nor\nCUBLAS_WORKSPACE_CONFIG=:4096:2\n.\nSee the\ncuDNN 8 Release Notes\nfor more information.\nNote\nIf the following conditions are satisfied:\n1) cudnn is enabled,\n2) input data is on the GPU\n3) input data has dtype\ntorch.float16\n4) V100 GPU is used,\n5) input data is not in\nPackedSequence\nformat\npersistent algorithm can be selected to improve performance.\nExamples:\n>>>\nrnn\n=\nnn\n.\nRNN\n(\n10\n,\n20\n,\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n5\n,\n3\n,\n10\n)\n>>>\nh0\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n,\n20\n)\n>>>\noutput\n,\nhn\n=\nrnn\n(\ninput\n,\nh0\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#rnn",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#RNN",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/rnn.py#L469",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_8.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNBase.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LSTM",
  "page_text": "LSTM\n¶\nclass\ntorch.nn.\nLSTM\n(\ninput_size\n,\nhidden_size\n,\nnum_layers\n=\n1\n,\nbias\n=\nTrue\n,\nbatch_first\n=\nFalse\n,\ndropout\n=\n0.0\n,\nbidirectional\n=\nFalse\n,\nproj_size\n=\n0\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApply a multi-layer long short-term memory (LSTM) RNN to an input sequence.\nFor each element in the input sequence, each layer computes the following\nfunction:\ni\nt\n=\nσ\n(\nW\ni\ni\nx\nt\n+\nb\ni\ni\n+\nW\nh\ni\nh\nt\n−\n1\n+\nb\nh\ni\n)\nf\nt\n=\nσ\n(\nW\ni\nf\nx\nt\n+\nb\ni\nf\n+\nW\nh\nf\nh\nt\n−\n1\n+\nb\nh\nf\n)\ng\nt\n=\ntanh\n⁡\n(\nW\ni\ng\nx\nt\n+\nb\ni\ng\n+\nW\nh\ng\nh\nt\n−\n1\n+\nb\nh\ng\n)\no\nt\n=\nσ\n(\nW\ni\no\nx\nt\n+\nb\ni\no\n+\nW\nh\no\nh\nt\n−\n1\n+\nb\nh\no\n)\nc\nt\n=\nf\nt\n⊙\nc\nt\n−\n1\n+\ni\nt\n⊙\ng\nt\nh\nt\n=\no\nt\n⊙\ntanh\n⁡\n(\nc\nt\n)\n\\begin{array}{ll} \\\\\n    i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n    f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n    g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n    o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n    c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n    h_t = o_t \\odot \\tanh(c_t) \\\\\n\\end{array}\ni\nt\n​\n=\nσ\n(\nW\nii\n​\nx\nt\n​\n+\nb\nii\n​\n+\nW\nhi\n​\nh\nt\n−\n1\n​\n+\nb\nhi\n​\n)\nf\nt\n​\n=\nσ\n(\nW\ni\nf\n​\nx\nt\n​\n+\nb\ni\nf\n​\n+\nW\nh\nf\n​\nh\nt\n−\n1\n​\n+\nb\nh\nf\n​\n)\ng\nt\n​\n=\ntanh\n(\nW\ni\ng\n​\nx\nt\n​\n+\nb\ni\ng\n​\n+\nW\nh\ng\n​\nh\nt\n−\n1\n​\n+\nb\nh\ng\n​\n)\no\nt\n​\n=\nσ\n(\nW\ni\no\n​\nx\nt\n​\n+\nb\ni\no\n​\n+\nW\nh\no\n​\nh\nt\n−\n1\n​\n+\nb\nh\no\n​\n)\nc\nt\n​\n=\nf\nt\n​\n⊙\nc\nt\n−\n1\n​\n+\ni\nt\n​\n⊙\ng\nt\n​\nh\nt\n​\n=\no\nt\n​\n⊙\ntanh\n(\nc\nt\n​\n)\n​\nwhere\nh\nt\nh_t\nh\nt\n​\nis the hidden state at time\nt\n,\nc\nt\nc_t\nc\nt\n​\nis the cell\nstate at time\nt\n,\nx\nt\nx_t\nx\nt\n​\nis the input at time\nt\n,\nh\nt\n−\n1\nh_{t-1}\nh\nt\n−\n1\n​\nis the hidden state of the layer at time\nt-1\nor the initial hidden\nstate at time\n0\n, and\ni\nt\ni_t\ni\nt\n​\n,\nf\nt\nf_t\nf\nt\n​\n,\ng\nt\ng_t\ng\nt\n​\n,\no\nt\no_t\no\nt\n​\nare the input, forget, cell, and output gates, respectively.\nσ\n\\sigma\nσ\nis the sigmoid function, and\n⊙\n\\odot\n⊙\nis the Hadamard product.\nIn a multilayer LSTM, the input\nx\nt\n(\nl\n)\nx^{(l)}_t\nx\nt\n(\nl\n)\n​\nof the\nl\nl\nl\n-th layer\n(\nl\n≥\n2\nl \\ge 2\nl\n≥\n2\n) is the hidden state\nh\nt\n(\nl\n−\n1\n)\nh^{(l-1)}_t\nh\nt\n(\nl\n−\n1\n)\n​\nof the previous layer multiplied by\ndropout\nδ\nt\n(\nl\n−\n1\n)\n\\delta^{(l-1)}_t\nδ\nt\n(\nl\n−\n1\n)\n​\nwhere each\nδ\nt\n(\nl\n−\n1\n)\n\\delta^{(l-1)}_t\nδ\nt\n(\nl\n−\n1\n)\n​\nis a Bernoulli random\nvariable which is\n0\n0\n0\nwith probability\ndropout\n.\nIf\nproj_size\n>\n0\nis specified, LSTM with projections will be used. This changes\nthe LSTM cell in the following way. First, the dimension of\nh\nt\nh_t\nh\nt\n​\nwill be changed from\nhidden_size\nto\nproj_size\n(dimensions of\nW\nh\ni\nW_{hi}\nW\nhi\n​\nwill be changed accordingly).\nSecond, the output hidden state of each layer will be multiplied by a learnable projection\nmatrix:\nh\nt\n=\nW\nh\nr\nh\nt\nh_t = W_{hr}h_t\nh\nt\n​\n=\nW\nh\nr\n​\nh\nt\n​\n. Note that as a consequence of this, the output\nof LSTM network will be of different shape as well. See Inputs/Outputs sections below for exact\ndimensions of all variables. You can find more details in\nhttps://arxiv.org/abs/1402.1128\n.\nParameters\ninput_size\n– The number of expected features in the input\nx\nhidden_size\n– The number of features in the hidden state\nh\nnum_layers\n– Number of recurrent layers. E.g., setting\nnum_layers=2\nwould mean stacking two LSTMs together to form a\nstacked LSTM\n,\nwith the second LSTM taking in outputs of the first LSTM and\ncomputing the final results. Default: 1\nbias\n– If\nFalse\n, then the layer does not use bias weights\nb_ih\nand\nb_hh\n.\nDefault:\nTrue\nbatch_first\n– If\nTrue\n, then the input and output tensors are provided\nas\n(batch, seq, feature)\ninstead of\n(seq, batch, feature)\n.\nNote that this does not apply to hidden or cell states. See the\nInputs/Outputs sections below for details.  Default:\nFalse\ndropout\n– If non-zero, introduces a\nDropout\nlayer on the outputs of each\nLSTM layer except the last layer, with dropout probability equal to\ndropout\n. Default: 0\nbidirectional\n– If\nTrue\n, becomes a bidirectional LSTM. Default:\nFalse\nproj_size\n– If\n>\n0\n, will use LSTM with projections of corresponding size. Default: 0\nInputs: input, (h_0, c_0)\ninput\n: tensor of shape\n(\nL\n,\nH\ni\nn\n)\n(L, H_{in})\n(\nL\n,\nH\nin\n​\n)\nfor unbatched input,\n(\nL\n,\nN\n,\nH\ni\nn\n)\n(L, N, H_{in})\n(\nL\n,\nN\n,\nH\nin\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nL\n,\nH\ni\nn\n)\n(N, L, H_{in})\n(\nN\n,\nL\n,\nH\nin\n​\n)\nwhen\nbatch_first=True\ncontaining the features of\nthe input sequence.  The input can also be a packed variable length sequence.\nSee\ntorch.nn.utils.rnn.pack_padded_sequence()\nor\ntorch.nn.utils.rnn.pack_sequence()\nfor details.\nh_0\n: tensor of shape\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, H_{out})\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n​\n)\nfor unbatched input or\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, N, H_{out})\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n​\n)\ncontaining the\ninitial hidden state for each element in the input sequence.\nDefaults to zeros if (h_0, c_0) is not provided.\nc_0\n: tensor of shape\n(\nD\n∗\nnum_layers\n,\nH\nc\ne\nl\nl\n)\n(D * \\text{num\\_layers}, H_{cell})\n(\nD\n∗\nnum_layers\n,\nH\nce\nll\n​\n)\nfor unbatched input or\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\nc\ne\nl\nl\n)\n(D * \\text{num\\_layers}, N, H_{cell})\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\nce\nll\n​\n)\ncontaining the\ninitial cell state for each element in the input sequence.\nDefaults to zeros if (h_0, c_0) is not provided.\nwhere:\nN\n=\nbatch size\nL\n=\nsequence length\nD\n=\n2\nif bidirectional=True otherwise\n1\nH\ni\nn\n=\ninput_size\nH\nc\ne\nl\nl\n=\nhidden_size\nH\no\nu\nt\n=\nproj_size if proj_size\n>\n0\notherwise hidden_size\n\\begin{aligned}\n    N ={} & \\text{batch size} \\\\\n    L ={} & \\text{sequence length} \\\\\n    D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n    H_{in} ={} & \\text{input\\_size} \\\\\n    H_{cell} ={} & \\text{hidden\\_size} \\\\\n    H_{out} ={} & \\text{proj\\_size if } \\text{proj\\_size}>0 \\text{ otherwise hidden\\_size} \\\\\n\\end{aligned}\nN\n=\nL\n=\nD\n=\nH\nin\n​\n=\nH\nce\nll\n​\n=\nH\no\nu\nt\n​\n=\n​\nbatch size\nsequence length\n2\nif bidirectional=True otherwise\n1\ninput_size\nhidden_size\nproj_size if\nproj_size\n>\n0\notherwise hidden_size\n​\nOutputs: output, (h_n, c_n)\noutput\n: tensor of shape\n(\nL\n,\nD\n∗\nH\no\nu\nt\n)\n(L, D * H_{out})\n(\nL\n,\nD\n∗\nH\no\nu\nt\n​\n)\nfor unbatched input,\n(\nL\n,\nN\n,\nD\n∗\nH\no\nu\nt\n)\n(L, N, D * H_{out})\n(\nL\n,\nN\n,\nD\n∗\nH\no\nu\nt\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nL\n,\nD\n∗\nH\no\nu\nt\n)\n(N, L, D * H_{out})\n(\nN\n,\nL\n,\nD\n∗\nH\no\nu\nt\n​\n)\nwhen\nbatch_first=True\ncontaining the output features\n(h_t)\nfrom the last layer of the LSTM, for each\nt\n. If a\ntorch.nn.utils.rnn.PackedSequence\nhas been given as the input, the output\nwill also be a packed sequence. When\nbidirectional=True\n,\noutput\nwill contain\na concatenation of the forward and reverse hidden states at each time step in the sequence.\nh_n\n: tensor of shape\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, H_{out})\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n​\n)\nfor unbatched input or\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, N, H_{out})\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n​\n)\ncontaining the\nfinal hidden state for each element in the sequence. When\nbidirectional=True\n,\nh_n\nwill contain a concatenation of the final forward and reverse hidden states, respectively.\nc_n\n: tensor of shape\n(\nD\n∗\nnum_layers\n,\nH\nc\ne\nl\nl\n)\n(D * \\text{num\\_layers}, H_{cell})\n(\nD\n∗\nnum_layers\n,\nH\nce\nll\n​\n)\nfor unbatched input or\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\nc\ne\nl\nl\n)\n(D * \\text{num\\_layers}, N, H_{cell})\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\nce\nll\n​\n)\ncontaining the\nfinal cell state for each element in the sequence. When\nbidirectional=True\n,\nc_n\nwill contain a concatenation of the final forward and reverse cell states, respectively.\nVariables\nweight_ih_l[k]\n– the learnable input-hidden weights of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\n(W_ii|W_if|W_ig|W_io)\n, of shape\n(4*hidden_size, input_size)\nfor\nk = 0\n.\nOtherwise, the shape is\n(4*hidden_size, num_directions * hidden_size)\n. If\nproj_size\n>\n0\nwas specified, the shape will be\n(4*hidden_size, num_directions * proj_size)\nfor\nk > 0\nweight_hh_l[k]\n– the learnable hidden-hidden weights of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\n(W_hi|W_hf|W_hg|W_ho)\n, of shape\n(4*hidden_size, hidden_size)\n. If\nproj_size\n>\n0\nwas specified, the shape will be\n(4*hidden_size, proj_size)\n.\nbias_ih_l[k]\n– the learnable input-hidden bias of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\n(b_ii|b_if|b_ig|b_io)\n, of shape\n(4*hidden_size)\nbias_hh_l[k]\n– the learnable hidden-hidden bias of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\n(b_hi|b_hf|b_hg|b_ho)\n, of shape\n(4*hidden_size)\nweight_hr_l[k]\n– the learnable projection weights of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\nof shape\n(proj_size, hidden_size)\n. Only present when\nproj_size\n>\n0\nwas\nspecified.\nweight_ih_l[k]_reverse\n– Analogous to\nweight_ih_l[k]\nfor the reverse direction.\nOnly present when\nbidirectional=True\n.\nweight_hh_l[k]_reverse\n– Analogous to\nweight_hh_l[k]\nfor the reverse direction.\nOnly present when\nbidirectional=True\n.\nbias_ih_l[k]_reverse\n– Analogous to\nbias_ih_l[k]\nfor the reverse direction.\nOnly present when\nbidirectional=True\n.\nbias_hh_l[k]_reverse\n– Analogous to\nbias_hh_l[k]\nfor the reverse direction.\nOnly present when\nbidirectional=True\n.\nweight_hr_l[k]_reverse\n– Analogous to\nweight_hr_l[k]\nfor the reverse direction.\nOnly present when\nbidirectional=True\nand\nproj_size\n>\n0\nwas specified.\nNote\nAll the weights and biases are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\n1\nhidden_size\nk = \\frac{1}{\\text{hidden\\_size}}\nk\n=\nhidden_size\n1\n​\nNote\nFor bidirectional LSTMs, forward and backward are directions 0 and 1 respectively.\nExample of splitting the output layers when\nbatch_first=False\n:\noutput.view(seq_len,\nbatch,\nnum_directions,\nhidden_size)\n.\nNote\nFor bidirectional LSTMs,\nh_n\nis not equivalent to the last element of\noutput\n; the\nformer contains the final forward and reverse hidden states, while the latter contains the\nfinal forward hidden state and the initial reverse hidden state.\nNote\nbatch_first\nargument is ignored for unbatched inputs.\nNote\nproj_size\nshould be smaller than\nhidden_size\n.\nWarning\nThere are known non-determinism issues for RNN functions on some versions of cuDNN and CUDA.\nYou can enforce deterministic behavior by setting the following environment variables:\nOn CUDA 10.1, set environment variable\nCUDA_LAUNCH_BLOCKING=1\n.\nThis may affect performance.\nOn CUDA 10.2 or later, set environment variable\n(note the leading colon symbol)\nCUBLAS_WORKSPACE_CONFIG=:16:8\nor\nCUBLAS_WORKSPACE_CONFIG=:4096:2\n.\nSee the\ncuDNN 8 Release Notes\nfor more information.\nNote\nIf the following conditions are satisfied:\n1) cudnn is enabled,\n2) input data is on the GPU\n3) input data has dtype\ntorch.float16\n4) V100 GPU is used,\n5) input data is not in\nPackedSequence\nformat\npersistent algorithm can be selected to improve performance.\nExamples:\n>>>\nrnn\n=\nnn\n.\nLSTM\n(\n10\n,\n20\n,\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n5\n,\n3\n,\n10\n)\n>>>\nh0\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n,\n20\n)\n>>>\nc0\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n,\n20\n)\n>>>\noutput\n,\n(\nhn\n,\ncn\n)\n=\nrnn\n(\ninput\n,\n(\nh0\n,\nc0\n))\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#lstm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/rnn.py#L795",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM",
    "https://arxiv.org/abs/1402.1128",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://docs.nvidia.com/deeplearning/sdk/cudnn-release-notes/rel_8.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.GRU.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.GRU",
  "page_text": "GRU\n¶\nclass\ntorch.nn.\nGRU\n(\ninput_size\n,\nhidden_size\n,\nnum_layers\n=\n1\n,\nbias\n=\nTrue\n,\nbatch_first\n=\nFalse\n,\ndropout\n=\n0.0\n,\nbidirectional\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApply a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\nFor each element in the input sequence, each layer computes the following\nfunction:\nr\nt\n=\nσ\n(\nW\ni\nr\nx\nt\n+\nb\ni\nr\n+\nW\nh\nr\nh\n(\nt\n−\n1\n)\n+\nb\nh\nr\n)\nz\nt\n=\nσ\n(\nW\ni\nz\nx\nt\n+\nb\ni\nz\n+\nW\nh\nz\nh\n(\nt\n−\n1\n)\n+\nb\nh\nz\n)\nn\nt\n=\ntanh\n⁡\n(\nW\ni\nn\nx\nt\n+\nb\ni\nn\n+\nr\nt\n⊙\n(\nW\nh\nn\nh\n(\nt\n−\n1\n)\n+\nb\nh\nn\n)\n)\nh\nt\n=\n(\n1\n−\nz\nt\n)\n⊙\nn\nt\n+\nz\nt\n⊙\nh\n(\nt\n−\n1\n)\n\\begin{array}{ll}\n    r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n    z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n    n_t = \\tanh(W_{in} x_t + b_{in} + r_t \\odot (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n    h_t = (1 - z_t) \\odot n_t + z_t \\odot h_{(t-1)}\n\\end{array}\nr\nt\n​\n=\nσ\n(\nW\ni\nr\n​\nx\nt\n​\n+\nb\ni\nr\n​\n+\nW\nh\nr\n​\nh\n(\nt\n−\n1\n)\n​\n+\nb\nh\nr\n​\n)\nz\nt\n​\n=\nσ\n(\nW\ni\nz\n​\nx\nt\n​\n+\nb\ni\nz\n​\n+\nW\nh\nz\n​\nh\n(\nt\n−\n1\n)\n​\n+\nb\nh\nz\n​\n)\nn\nt\n​\n=\ntanh\n(\nW\nin\n​\nx\nt\n​\n+\nb\nin\n​\n+\nr\nt\n​\n⊙\n(\nW\nhn\n​\nh\n(\nt\n−\n1\n)\n​\n+\nb\nhn\n​\n))\nh\nt\n​\n=\n(\n1\n−\nz\nt\n​\n)\n⊙\nn\nt\n​\n+\nz\nt\n​\n⊙\nh\n(\nt\n−\n1\n)\n​\n​\nwhere\nh\nt\nh_t\nh\nt\n​\nis the hidden state at time\nt\n,\nx\nt\nx_t\nx\nt\n​\nis the input\nat time\nt\n,\nh\n(\nt\n−\n1\n)\nh_{(t-1)}\nh\n(\nt\n−\n1\n)\n​\nis the hidden state of the layer\nat time\nt-1\nor the initial hidden state at time\n0\n, and\nr\nt\nr_t\nr\nt\n​\n,\nz\nt\nz_t\nz\nt\n​\n,\nn\nt\nn_t\nn\nt\n​\nare the reset, update, and new gates, respectively.\nσ\n\\sigma\nσ\nis the sigmoid function, and\n⊙\n\\odot\n⊙\nis the Hadamard product.\nIn a multilayer GRU, the input\nx\nt\n(\nl\n)\nx^{(l)}_t\nx\nt\n(\nl\n)\n​\nof the\nl\nl\nl\n-th layer\n(\nl\n≥\n2\nl \\ge 2\nl\n≥\n2\n) is the hidden state\nh\nt\n(\nl\n−\n1\n)\nh^{(l-1)}_t\nh\nt\n(\nl\n−\n1\n)\n​\nof the previous layer multiplied by\ndropout\nδ\nt\n(\nl\n−\n1\n)\n\\delta^{(l-1)}_t\nδ\nt\n(\nl\n−\n1\n)\n​\nwhere each\nδ\nt\n(\nl\n−\n1\n)\n\\delta^{(l-1)}_t\nδ\nt\n(\nl\n−\n1\n)\n​\nis a Bernoulli random\nvariable which is\n0\n0\n0\nwith probability\ndropout\n.\nParameters\ninput_size\n– The number of expected features in the input\nx\nhidden_size\n– The number of features in the hidden state\nh\nnum_layers\n– Number of recurrent layers. E.g., setting\nnum_layers=2\nwould mean stacking two GRUs together to form a\nstacked GRU\n,\nwith the second GRU taking in outputs of the first GRU and\ncomputing the final results. Default: 1\nbias\n– If\nFalse\n, then the layer does not use bias weights\nb_ih\nand\nb_hh\n.\nDefault:\nTrue\nbatch_first\n– If\nTrue\n, then the input and output tensors are provided\nas\n(batch, seq, feature)\ninstead of\n(seq, batch, feature)\n.\nNote that this does not apply to hidden or cell states. See the\nInputs/Outputs sections below for details.  Default:\nFalse\ndropout\n– If non-zero, introduces a\nDropout\nlayer on the outputs of each\nGRU layer except the last layer, with dropout probability equal to\ndropout\n. Default: 0\nbidirectional\n– If\nTrue\n, becomes a bidirectional GRU. Default:\nFalse\nInputs: input, h_0\ninput\n: tensor of shape\n(\nL\n,\nH\ni\nn\n)\n(L, H_{in})\n(\nL\n,\nH\nin\n​\n)\nfor unbatched input,\n(\nL\n,\nN\n,\nH\ni\nn\n)\n(L, N, H_{in})\n(\nL\n,\nN\n,\nH\nin\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nL\n,\nH\ni\nn\n)\n(N, L, H_{in})\n(\nN\n,\nL\n,\nH\nin\n​\n)\nwhen\nbatch_first=True\ncontaining the features of\nthe input sequence.  The input can also be a packed variable length sequence.\nSee\ntorch.nn.utils.rnn.pack_padded_sequence()\nor\ntorch.nn.utils.rnn.pack_sequence()\nfor details.\nh_0\n: tensor of shape\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, H_{out})\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n​\n)\nor\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, N, H_{out})\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n​\n)\ncontaining the initial hidden state for the input sequence. Defaults to zeros if not provided.\nwhere:\nN\n=\nbatch size\nL\n=\nsequence length\nD\n=\n2\nif bidirectional=True otherwise\n1\nH\ni\nn\n=\ninput_size\nH\no\nu\nt\n=\nhidden_size\n\\begin{aligned}\n    N ={} & \\text{batch size} \\\\\n    L ={} & \\text{sequence length} \\\\\n    D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n    H_{in} ={} & \\text{input\\_size} \\\\\n    H_{out} ={} & \\text{hidden\\_size}\n\\end{aligned}\nN\n=\nL\n=\nD\n=\nH\nin\n​\n=\nH\no\nu\nt\n​\n=\n​\nbatch size\nsequence length\n2\nif bidirectional=True otherwise\n1\ninput_size\nhidden_size\n​\nOutputs: output, h_n\noutput\n: tensor of shape\n(\nL\n,\nD\n∗\nH\no\nu\nt\n)\n(L, D * H_{out})\n(\nL\n,\nD\n∗\nH\no\nu\nt\n​\n)\nfor unbatched input,\n(\nL\n,\nN\n,\nD\n∗\nH\no\nu\nt\n)\n(L, N, D * H_{out})\n(\nL\n,\nN\n,\nD\n∗\nH\no\nu\nt\n​\n)\nwhen\nbatch_first=False\nor\n(\nN\n,\nL\n,\nD\n∗\nH\no\nu\nt\n)\n(N, L, D * H_{out})\n(\nN\n,\nL\n,\nD\n∗\nH\no\nu\nt\n​\n)\nwhen\nbatch_first=True\ncontaining the output features\n(h_t)\nfrom the last layer of the GRU, for each\nt\n. If a\ntorch.nn.utils.rnn.PackedSequence\nhas been given as the input, the output\nwill also be a packed sequence.\nh_n\n: tensor of shape\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, H_{out})\n(\nD\n∗\nnum_layers\n,\nH\no\nu\nt\n​\n)\nor\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n)\n(D * \\text{num\\_layers}, N, H_{out})\n(\nD\n∗\nnum_layers\n,\nN\n,\nH\no\nu\nt\n​\n)\ncontaining the final hidden state\nfor the input sequence.\nVariables\nweight_ih_l[k]\n– the learnable input-hidden weights of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\n(W_ir|W_iz|W_in), of shape\n(3*hidden_size, input_size)\nfor\nk = 0\n.\nOtherwise, the shape is\n(3*hidden_size, num_directions * hidden_size)\nweight_hh_l[k]\n– the learnable hidden-hidden weights of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\n(W_hr|W_hz|W_hn), of shape\n(3*hidden_size, hidden_size)\nbias_ih_l[k]\n– the learnable input-hidden bias of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\n(b_ir|b_iz|b_in), of shape\n(3*hidden_size)\nbias_hh_l[k]\n– the learnable hidden-hidden bias of the\nk\nt\nh\n\\text{k}^{th}\nk\nt\nh\nlayer\n(b_hr|b_hz|b_hn), of shape\n(3*hidden_size)\nNote\nAll the weights and biases are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\n1\nhidden_size\nk = \\frac{1}{\\text{hidden\\_size}}\nk\n=\nhidden_size\n1\n​\nNote\nFor bidirectional GRUs, forward and backward are directions 0 and 1 respectively.\nExample of splitting the output layers when\nbatch_first=False\n:\noutput.view(seq_len,\nbatch,\nnum_directions,\nhidden_size)\n.\nNote\nbatch_first\nargument is ignored for unbatched inputs.\nNote\nThe calculation of new gate\nn\nt\nn_t\nn\nt\n​\nsubtly differs from the original paper and other frameworks.\nIn the original implementation, the Hadamard product\n(\n⊙\n)\n(\\odot)\n(\n⊙\n)\nbetween\nr\nt\nr_t\nr\nt\n​\nand the\nprevious hidden state\nh\n(\nt\n−\n1\n)\nh_{(t-1)}\nh\n(\nt\n−\n1\n)\n​\nis done before the multiplication with the weight matrix\nW\nand addition of bias:\nn\nt\n=\ntanh\n⁡\n(\nW\ni\nn\nx\nt\n+\nb\ni\nn\n+\nW\nh\nn\n(\nr\nt\n⊙\nh\n(\nt\n−\n1\n)\n)\n+\nb\nh\nn\n)\n\\begin{aligned}\n    n_t = \\tanh(W_{in} x_t + b_{in} + W_{hn} ( r_t \\odot h_{(t-1)} ) + b_{hn})\n\\end{aligned}\nn\nt\n​\n=\ntanh\n(\nW\nin\n​\nx\nt\n​\n+\nb\nin\n​\n+\nW\nhn\n​\n(\nr\nt\n​\n⊙\nh\n(\nt\n−\n1\n)\n​\n)\n+\nb\nhn\n​\n)\n​\nThis is in contrast to PyTorch implementation, which is done after\nW\nh\nn\nh\n(\nt\n−\n1\n)\nW_{hn} h_{(t-1)}\nW\nhn\n​\nh\n(\nt\n−\n1\n)\n​\nn\nt\n=\ntanh\n⁡\n(\nW\ni\nn\nx\nt\n+\nb\ni\nn\n+\nr\nt\n⊙\n(\nW\nh\nn\nh\n(\nt\n−\n1\n)\n+\nb\nh\nn\n)\n)\n\\begin{aligned}\n    n_t = \\tanh(W_{in} x_t + b_{in} + r_t \\odot (W_{hn} h_{(t-1)}+ b_{hn}))\n\\end{aligned}\nn\nt\n​\n=\ntanh\n(\nW\nin\n​\nx\nt\n​\n+\nb\nin\n​\n+\nr\nt\n​\n⊙\n(\nW\nhn\n​\nh\n(\nt\n−\n1\n)\n​\n+\nb\nhn\n​\n))\n​\nThis implementation differs on purpose for efficiency.\nNote\nIf the following conditions are satisfied:\n1) cudnn is enabled,\n2) input data is on the GPU\n3) input data has dtype\ntorch.float16\n4) V100 GPU is used,\n5) input data is not in\nPackedSequence\nformat\npersistent algorithm can be selected to improve performance.\nExamples:\n>>>\nrnn\n=\nnn\n.\nGRU\n(\n10\n,\n20\n,\n2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n5\n,\n3\n,\n10\n)\n>>>\nh0\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n,\n20\n)\n>>>\noutput\n,\nhn\n=\nrnn\n(\ninput\n,\nh0\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#gru",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#GRU",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/rnn.py#L1162",
    "https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.RNNCell",
  "page_text": "RNNCell\n¶\nclass\ntorch.nn.\nRNNCell\n(\ninput_size\n,\nhidden_size\n,\nbias\n=\nTrue\n,\nnonlinearity\n=\n'tanh'\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nAn Elman RNN cell with tanh or ReLU non-linearity.\nh\n′\n=\ntanh\n⁡\n(\nW\ni\nh\nx\n+\nb\ni\nh\n+\nW\nh\nh\nh\n+\nb\nh\nh\n)\nh' = \\tanh(W_{ih} x + b_{ih}  +  W_{hh} h + b_{hh})\nh\n′\n=\ntanh\n(\nW\nih\n​\nx\n+\nb\nih\n​\n+\nW\nhh\n​\nh\n+\nb\nhh\n​\n)\nIf\nnonlinearity\nis\n‘relu’\n, then ReLU is used in place of tanh.\nParameters\ninput_size\n(\nint\n) – The number of expected features in the input\nx\nhidden_size\n(\nint\n) – The number of features in the hidden state\nh\nbias\n(\nbool\n) – If\nFalse\n, then the layer does not use bias weights\nb_ih\nand\nb_hh\n.\nDefault:\nTrue\nnonlinearity\n(\nstr\n) – The non-linearity to use. Can be either\n'tanh'\nor\n'relu'\n. Default:\n'tanh'\nInputs: input, hidden\ninput\n: tensor containing input features\nhidden\n: tensor containing the initial hidden state\nDefaults to zero if not provided.\nOutputs: h’\nh’\nof shape\n(batch, hidden_size)\n: tensor containing the next hidden state\nfor each element in the batch\nShape:\ninput:\n(\nN\n,\nH\ni\nn\n)\n(N, H_{in})\n(\nN\n,\nH\nin\n​\n)\nor\n(\nH\ni\nn\n)\n(H_{in})\n(\nH\nin\n​\n)\ntensor containing input features where\nH\ni\nn\nH_{in}\nH\nin\n​\n=\ninput_size\n.\nhidden:\n(\nN\n,\nH\no\nu\nt\n)\n(N, H_{out})\n(\nN\n,\nH\no\nu\nt\n​\n)\nor\n(\nH\no\nu\nt\n)\n(H_{out})\n(\nH\no\nu\nt\n​\n)\ntensor containing the initial hidden\nstate where\nH\no\nu\nt\nH_{out}\nH\no\nu\nt\n​\n=\nhidden_size\n. Defaults to zero if not provided.\noutput:\n(\nN\n,\nH\no\nu\nt\n)\n(N, H_{out})\n(\nN\n,\nH\no\nu\nt\n​\n)\nor\n(\nH\no\nu\nt\n)\n(H_{out})\n(\nH\no\nu\nt\n​\n)\ntensor containing the next hidden state.\nVariables\nweight_ih\n(\ntorch.Tensor\n) – the learnable input-hidden weights, of shape\n(hidden_size, input_size)\nweight_hh\n(\ntorch.Tensor\n) – the learnable hidden-hidden weights, of shape\n(hidden_size, hidden_size)\nbias_ih\n– the learnable input-hidden bias, of shape\n(hidden_size)\nbias_hh\n– the learnable hidden-hidden bias, of shape\n(hidden_size)\nNote\nAll the weights and biases are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\n1\nhidden_size\nk = \\frac{1}{\\text{hidden\\_size}}\nk\n=\nhidden_size\n1\n​\nExamples:\n>>>\nrnn\n=\nnn\n.\nRNNCell\n(\n10\n,\n20\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n6\n,\n3\n,\n10\n)\n>>>\nhx\n=\ntorch\n.\nrandn\n(\n3\n,\n20\n)\n>>>\noutput\n=\n[]\n>>>\nfor\ni\nin\nrange\n(\n6\n):\n...\nhx\n=\nrnn\n(\ninput\n[\ni\n],\nhx\n)\n...\noutput\n.\nappend\n(\nhx\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html#rnncell",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#RNNCell",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/rnn.py#L1491",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html#torch.nn.RNNCell",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.GRU.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LSTMCell",
  "page_text": "LSTMCell\n¶\nclass\ntorch.nn.\nLSTMCell\n(\ninput_size\n,\nhidden_size\n,\nbias\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA long short-term memory (LSTM) cell.\ni\n=\nσ\n(\nW\ni\ni\nx\n+\nb\ni\ni\n+\nW\nh\ni\nh\n+\nb\nh\ni\n)\nf\n=\nσ\n(\nW\ni\nf\nx\n+\nb\ni\nf\n+\nW\nh\nf\nh\n+\nb\nh\nf\n)\ng\n=\ntanh\n⁡\n(\nW\ni\ng\nx\n+\nb\ni\ng\n+\nW\nh\ng\nh\n+\nb\nh\ng\n)\no\n=\nσ\n(\nW\ni\no\nx\n+\nb\ni\no\n+\nW\nh\no\nh\n+\nb\nh\no\n)\nc\n′\n=\nf\n⊙\nc\n+\ni\n⊙\ng\nh\n′\n=\no\n⊙\ntanh\n⁡\n(\nc\n′\n)\n\\begin{array}{ll}\ni = \\sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\\\\nf = \\sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\\\\ng = \\tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\\\\no = \\sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\\\\nc' = f \\odot c + i \\odot g \\\\\nh' = o \\odot \\tanh(c') \\\\\n\\end{array}\ni\n=\nσ\n(\nW\nii\n​\nx\n+\nb\nii\n​\n+\nW\nhi\n​\nh\n+\nb\nhi\n​\n)\nf\n=\nσ\n(\nW\ni\nf\n​\nx\n+\nb\ni\nf\n​\n+\nW\nh\nf\n​\nh\n+\nb\nh\nf\n​\n)\ng\n=\ntanh\n(\nW\ni\ng\n​\nx\n+\nb\ni\ng\n​\n+\nW\nh\ng\n​\nh\n+\nb\nh\ng\n​\n)\no\n=\nσ\n(\nW\ni\no\n​\nx\n+\nb\ni\no\n​\n+\nW\nh\no\n​\nh\n+\nb\nh\no\n​\n)\nc\n′\n=\nf\n⊙\nc\n+\ni\n⊙\ng\nh\n′\n=\no\n⊙\ntanh\n(\nc\n′\n)\n​\nwhere\nσ\n\\sigma\nσ\nis the sigmoid function, and\n⊙\n\\odot\n⊙\nis the Hadamard product.\nParameters\ninput_size\n(\nint\n) – The number of expected features in the input\nx\nhidden_size\n(\nint\n) – The number of features in the hidden state\nh\nbias\n(\nbool\n) – If\nFalse\n, then the layer does not use bias weights\nb_ih\nand\nb_hh\n. Default:\nTrue\nInputs: input, (h_0, c_0)\ninput\nof shape\n(batch, input_size)\nor\n(input_size)\n: tensor containing input features\nh_0\nof shape\n(batch, hidden_size)\nor\n(hidden_size)\n: tensor containing the initial hidden state\nc_0\nof shape\n(batch, hidden_size)\nor\n(hidden_size)\n: tensor containing the initial cell state\nIf\n(h_0, c_0)\nis not provided, both\nh_0\nand\nc_0\ndefault to zero.\nOutputs: (h_1, c_1)\nh_1\nof shape\n(batch, hidden_size)\nor\n(hidden_size)\n: tensor containing the next hidden state\nc_1\nof shape\n(batch, hidden_size)\nor\n(hidden_size)\n: tensor containing the next cell state\nVariables\nweight_ih\n(\ntorch.Tensor\n) – the learnable input-hidden weights, of shape\n(4*hidden_size, input_size)\nweight_hh\n(\ntorch.Tensor\n) – the learnable hidden-hidden weights, of shape\n(4*hidden_size, hidden_size)\nbias_ih\n– the learnable input-hidden bias, of shape\n(4*hidden_size)\nbias_hh\n– the learnable hidden-hidden bias, of shape\n(4*hidden_size)\nNote\nAll the weights and biases are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\n1\nhidden_size\nk = \\frac{1}{\\text{hidden\\_size}}\nk\n=\nhidden_size\n1\n​\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nExamples:\n>>>\nrnn\n=\nnn\n.\nLSTMCell\n(\n10\n,\n20\n)\n# (input_size, hidden_size)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n3\n,\n10\n)\n# (time_steps, batch, input_size)\n>>>\nhx\n=\ntorch\n.\nrandn\n(\n3\n,\n20\n)\n# (batch, hidden_size)\n>>>\ncx\n=\ntorch\n.\nrandn\n(\n3\n,\n20\n)\n>>>\noutput\n=\n[]\n>>>\nfor\ni\nin\nrange\n(\ninput\n.\nsize\n()[\n0\n]):\n...\nhx\n,\ncx\n=\nrnn\n(\ninput\n[\ni\n],\n(\nhx\n,\ncx\n))\n...\noutput\n.\nappend\n(\nhx\n)\n>>>\noutput\n=\ntorch\n.\nstack\n(\noutput\n,\ndim\n=\n0\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html#lstmcell",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTMCell",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/rnn.py#L1610",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html#torch.nn.LSTMCell",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://pytorch.org/docs/stable/generated/torch.nn.GRUCell.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.GRUCell",
  "page_text": "GRUCell\n¶\nclass\ntorch.nn.\nGRUCell\n(\ninput_size\n,\nhidden_size\n,\nbias\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA gated recurrent unit (GRU) cell.\nr\n=\nσ\n(\nW\ni\nr\nx\n+\nb\ni\nr\n+\nW\nh\nr\nh\n+\nb\nh\nr\n)\nz\n=\nσ\n(\nW\ni\nz\nx\n+\nb\ni\nz\n+\nW\nh\nz\nh\n+\nb\nh\nz\n)\nn\n=\ntanh\n⁡\n(\nW\ni\nn\nx\n+\nb\ni\nn\n+\nr\n⊙\n(\nW\nh\nn\nh\n+\nb\nh\nn\n)\n)\nh\n′\n=\n(\n1\n−\nz\n)\n⊙\nn\n+\nz\n⊙\nh\n\\begin{array}{ll}\nr = \\sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\\\\nz = \\sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\\\\nn = \\tanh(W_{in} x + b_{in} + r \\odot (W_{hn} h + b_{hn})) \\\\\nh' = (1 - z) \\odot n + z \\odot h\n\\end{array}\nr\n=\nσ\n(\nW\ni\nr\n​\nx\n+\nb\ni\nr\n​\n+\nW\nh\nr\n​\nh\n+\nb\nh\nr\n​\n)\nz\n=\nσ\n(\nW\ni\nz\n​\nx\n+\nb\ni\nz\n​\n+\nW\nh\nz\n​\nh\n+\nb\nh\nz\n​\n)\nn\n=\ntanh\n(\nW\nin\n​\nx\n+\nb\nin\n​\n+\nr\n⊙\n(\nW\nhn\n​\nh\n+\nb\nhn\n​\n))\nh\n′\n=\n(\n1\n−\nz\n)\n⊙\nn\n+\nz\n⊙\nh\n​\nwhere\nσ\n\\sigma\nσ\nis the sigmoid function, and\n⊙\n\\odot\n⊙\nis the Hadamard product.\nParameters\ninput_size\n(\nint\n) – The number of expected features in the input\nx\nhidden_size\n(\nint\n) – The number of features in the hidden state\nh\nbias\n(\nbool\n) – If\nFalse\n, then the layer does not use bias weights\nb_ih\nand\nb_hh\n. Default:\nTrue\nInputs: input, hidden\ninput\n: tensor containing input features\nhidden\n: tensor containing the initial hidden\nstate for each element in the batch.\nDefaults to zero if not provided.\nOutputs: h’\nh’\n: tensor containing the next hidden state\nfor each element in the batch\nShape:\ninput:\n(\nN\n,\nH\ni\nn\n)\n(N, H_{in})\n(\nN\n,\nH\nin\n​\n)\nor\n(\nH\ni\nn\n)\n(H_{in})\n(\nH\nin\n​\n)\ntensor containing input features where\nH\ni\nn\nH_{in}\nH\nin\n​\n=\ninput_size\n.\nhidden:\n(\nN\n,\nH\no\nu\nt\n)\n(N, H_{out})\n(\nN\n,\nH\no\nu\nt\n​\n)\nor\n(\nH\no\nu\nt\n)\n(H_{out})\n(\nH\no\nu\nt\n​\n)\ntensor containing the initial hidden\nstate where\nH\no\nu\nt\nH_{out}\nH\no\nu\nt\n​\n=\nhidden_size\n. Defaults to zero if not provided.\noutput:\n(\nN\n,\nH\no\nu\nt\n)\n(N, H_{out})\n(\nN\n,\nH\no\nu\nt\n​\n)\nor\n(\nH\no\nu\nt\n)\n(H_{out})\n(\nH\no\nu\nt\n​\n)\ntensor containing the next hidden state.\nVariables\nweight_ih\n(\ntorch.Tensor\n) – the learnable input-hidden weights, of shape\n(3*hidden_size, input_size)\nweight_hh\n(\ntorch.Tensor\n) – the learnable hidden-hidden weights, of shape\n(3*hidden_size, hidden_size)\nbias_ih\n– the learnable input-hidden bias, of shape\n(3*hidden_size)\nbias_hh\n– the learnable hidden-hidden bias, of shape\n(3*hidden_size)\nNote\nAll the weights and biases are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\n1\nhidden_size\nk = \\frac{1}{\\text{hidden\\_size}}\nk\n=\nhidden_size\n1\n​\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nExamples:\n>>>\nrnn\n=\nnn\n.\nGRUCell\n(\n10\n,\n20\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n6\n,\n3\n,\n10\n)\n>>>\nhx\n=\ntorch\n.\nrandn\n(\n3\n,\n20\n)\n>>>\noutput\n=\n[]\n>>>\nfor\ni\nin\nrange\n(\n6\n):\n...\nhx\n=\nrnn\n(\ninput\n[\ni\n],\nhx\n)\n...\noutput\n.\nappend\n(\nhx\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.GRUCell.html#grucell",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#GRUCell",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/rnn.py#L1720",
    "https://pytorch.org/docs/stable/generated/torch.nn.GRUCell.html#torch.nn.GRUCell",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Transformer",
  "page_text": "Transformer\n¶\nclass\ntorch.nn.\nTransformer\n(\nd_model=512\n,\nnhead=8\n,\nnum_encoder_layers=6\n,\nnum_decoder_layers=6\n,\ndim_feedforward=2048\n,\ndropout=0.1\n,\nactivation=<function\nrelu>\n,\ncustom_encoder=None\n,\ncustom_decoder=None\n,\nlayer_norm_eps=1e-05\n,\nbatch_first=False\n,\nnorm_first=False\n,\nbias=True\n,\ndevice=None\n,\ndtype=None\n)\n[source]\n[source]\n¶\nA transformer model.\nNote\nSee\nthis tutorial\nfor an in depth discussion of the performant building blocks PyTorch offers for building your own\ntransformer layers.\nUser is able to modify the attributes as needed. The architecture\nis based on the paper “Attention Is All You Need”. Ashish Vaswani, Noam Shazeer,\nNiki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and\nIllia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information\nProcessing Systems, pages 6000-6010.\nParameters\nd_model\n(\nint\n) – the number of expected features in the encoder/decoder inputs (default=512).\nnhead\n(\nint\n) – the number of heads in the multiheadattention models (default=8).\nnum_encoder_layers\n(\nint\n) – the number of sub-encoder-layers in the encoder (default=6).\nnum_decoder_layers\n(\nint\n) – the number of sub-decoder-layers in the decoder (default=6).\ndim_feedforward\n(\nint\n) – the dimension of the feedforward network model (default=2048).\ndropout\n(\nfloat\n) – the dropout value (default=0.1).\nactivation\n(\nUnion\n[\nstr\n,\nCallable\n[\n[\nTensor\n]\n,\nTensor\n]\n]\n) – the activation function of encoder/decoder intermediate layer, can be a string\n(“relu” or “gelu”) or a unary callable. Default: relu\ncustom_encoder\n(\nOptional\n[\nAny\n]\n) – custom encoder (default=None).\ncustom_decoder\n(\nOptional\n[\nAny\n]\n) – custom decoder (default=None).\nlayer_norm_eps\n(\nfloat\n) – the eps value in layer normalization components (default=1e-5).\nbatch_first\n(\nbool\n) – If\nTrue\n, then the input and output tensors are provided\nas (batch, seq, feature). Default:\nFalse\n(seq, batch, feature).\nnorm_first\n(\nbool\n) – if\nTrue\n, encoder and decoder layers will perform LayerNorms before\nother attention and feedforward operations, otherwise after. Default:\nFalse\n(after).\nbias\n(\nbool\n) – If set to\nFalse\n,\nLinear\nand\nLayerNorm\nlayers will not learn an additive\nbias. Default:\nTrue\n.\nExamples::\n>>>\ntransformer_model\n=\nnn\n.\nTransformer\n(\nnhead\n=\n16\n,\nnum_encoder_layers\n=\n12\n)\n>>>\nsrc\n=\ntorch\n.\nrand\n((\n10\n,\n32\n,\n512\n))\n>>>\ntgt\n=\ntorch\n.\nrand\n((\n20\n,\n32\n,\n512\n))\n>>>\nout\n=\ntransformer_model\n(\nsrc\n,\ntgt\n)\nNote: A full example to apply nn.Transformer module for the word language model is available in\nhttps://github.com/pytorch/examples/tree/master/word_language_model\nforward\n(\nsrc\n,\ntgt\n,\nsrc_mask\n=\nNone\n,\ntgt_mask\n=\nNone\n,\nmemory_mask\n=\nNone\n,\nsrc_key_padding_mask\n=\nNone\n,\ntgt_key_padding_mask\n=\nNone\n,\nmemory_key_padding_mask\n=\nNone\n,\nsrc_is_causal\n=\nNone\n,\ntgt_is_causal\n=\nNone\n,\nmemory_is_causal\n=\nFalse\n)\n[source]\n[source]\n¶\nTake in and process masked source/target sequences.\nNote\nIf a boolean tensor is provided for any of the [src/tgt/memory]_mask arguments, positions with a\nTrue\nvalue are\nnot allowed to participate in the attention,\nwhich is the opposite of the definition for\nattn_mask\nin\ntorch.nn.functional.scaled_dot_product_attention()\n.\nParameters\nsrc\n(\nTensor\n) – the sequence to the encoder (required).\ntgt\n(\nTensor\n) – the sequence to the decoder (required).\nsrc_mask\n(\nOptional\n[\nTensor\n]\n) – the additive mask for the src sequence (optional).\ntgt_mask\n(\nOptional\n[\nTensor\n]\n) – the additive mask for the tgt sequence (optional).\nmemory_mask\n(\nOptional\n[\nTensor\n]\n) – the additive mask for the encoder output (optional).\nsrc_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the Tensor mask for src keys per batch (optional).\ntgt_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the Tensor mask for tgt keys per batch (optional).\nmemory_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the Tensor mask for memory keys per batch (optional).\nsrc_is_causal\n(\nOptional\n[\nbool\n]\n) – If specified, applies a causal mask as\nsrc_mask\n.\nDefault:\nNone\n; try to detect a causal mask.\nWarning:\nsrc_is_causal\nprovides a hint that\nsrc_mask\nis\nthe causal mask. Providing incorrect hints can result in\nincorrect execution, including forward and backward\ncompatibility.\ntgt_is_causal\n(\nOptional\n[\nbool\n]\n) – If specified, applies a causal mask as\ntgt_mask\n.\nDefault:\nNone\n; try to detect a causal mask.\nWarning:\ntgt_is_causal\nprovides a hint that\ntgt_mask\nis\nthe causal mask. Providing incorrect hints can result in\nincorrect execution, including forward and backward\ncompatibility.\nmemory_is_causal\n(\nbool\n) – If specified, applies a causal mask as\nmemory_mask\n.\nDefault:\nFalse\n.\nWarning:\nmemory_is_causal\nprovides a hint that\nmemory_mask\nis the causal mask. Providing incorrect\nhints can result in incorrect execution, including\nforward and backward compatibility.\nReturn type\nTensor\nShape:\nsrc:\n(\nS\n,\nE\n)\n(S, E)\n(\nS\n,\nE\n)\nfor unbatched input,\n(\nS\n,\nN\n,\nE\n)\n(S, N, E)\n(\nS\n,\nN\n,\nE\n)\nif\nbatch_first=False\nor\n(N, S, E)\nif\nbatch_first=True\n.\ntgt:\n(\nT\n,\nE\n)\n(T, E)\n(\nT\n,\nE\n)\nfor unbatched input,\n(\nT\n,\nN\n,\nE\n)\n(T, N, E)\n(\nT\n,\nN\n,\nE\n)\nif\nbatch_first=False\nor\n(N, T, E)\nif\nbatch_first=True\n.\nsrc_mask:\n(\nS\n,\nS\n)\n(S, S)\n(\nS\n,\nS\n)\nor\n(\nN\n⋅\nnum_heads\n,\nS\n,\nS\n)\n(N\\cdot\\text{num\\_heads}, S, S)\n(\nN\n⋅\nnum_heads\n,\nS\n,\nS\n)\n.\ntgt_mask:\n(\nT\n,\nT\n)\n(T, T)\n(\nT\n,\nT\n)\nor\n(\nN\n⋅\nnum_heads\n,\nT\n,\nT\n)\n(N\\cdot\\text{num\\_heads}, T, T)\n(\nN\n⋅\nnum_heads\n,\nT\n,\nT\n)\n.\nmemory_mask:\n(\nT\n,\nS\n)\n(T, S)\n(\nT\n,\nS\n)\n.\nsrc_key_padding_mask:\n(\nS\n)\n(S)\n(\nS\n)\nfor unbatched input otherwise\n(\nN\n,\nS\n)\n(N, S)\n(\nN\n,\nS\n)\n.\ntgt_key_padding_mask:\n(\nT\n)\n(T)\n(\nT\n)\nfor unbatched input otherwise\n(\nN\n,\nT\n)\n(N, T)\n(\nN\n,\nT\n)\n.\nmemory_key_padding_mask:\n(\nS\n)\n(S)\n(\nS\n)\nfor unbatched input otherwise\n(\nN\n,\nS\n)\n(N, S)\n(\nN\n,\nS\n)\n.\nNote: [src/tgt/memory]_mask ensures that position\ni\ni\ni\nis allowed to attend the unmasked\npositions. If a BoolTensor is provided, positions with\nTrue\nare not allowed to attend while\nFalse\nvalues will be unchanged. If a FloatTensor\nis provided, it will be added to the attention weight.\n[src/tgt/memory]_key_padding_mask provides specified elements in the key to be ignored by\nthe attention. If a BoolTensor is provided, the positions with the\nvalue of\nTrue\nwill be ignored while the position with the value of\nFalse\nwill be unchanged.\noutput:\n(\nT\n,\nE\n)\n(T, E)\n(\nT\n,\nE\n)\nfor unbatched input,\n(\nT\n,\nN\n,\nE\n)\n(T, N, E)\n(\nT\n,\nN\n,\nE\n)\nif\nbatch_first=False\nor\n(N, T, E)\nif\nbatch_first=True\n.\nNote: Due to the multi-head attention architecture in the transformer model,\nthe output sequence length of a transformer is same as the input sequence\n(i.e. target) length of the decoder.\nwhere\nS\nS\nS\nis the source sequence length,\nT\nT\nT\nis the target sequence length,\nN\nN\nN\nis the\nbatch size,\nE\nE\nE\nis the feature number\nExamples\n>>>\noutput\n=\ntransformer_model\n(\nsrc\n,\ntgt\n,\nsrc_mask\n=\nsrc_mask\n,\ntgt_mask\n=\ntgt_mask\n)\nstatic\ngenerate_square_subsequent_mask\n(\nsz\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nGenerate a square causal mask for the sequence.\nThe masked positions are filled with float(‘-inf’). Unmasked positions are filled with float(0.0).\nReturn type\nTensor\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#transformer",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L57",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer",
    "https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/typing.html#typing.Callable",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://github.com/pytorch/examples/tree/master/word_language_model",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L173",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer.forward",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html#torch.nn.functional.scaled_dot_product_attention",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#Transformer.generate_square_subsequent_mask",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L291",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer.generate_square_subsequent_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.GRUCell.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.TransformerEncoder",
  "page_text": "TransformerEncoder\n¶\nclass\ntorch.nn.\nTransformerEncoder\n(\nencoder_layer\n,\nnum_layers\n,\nnorm\n=\nNone\n,\nenable_nested_tensor\n=\nTrue\n,\nmask_check\n=\nTrue\n)\n[source]\n[source]\n¶\nTransformerEncoder is a stack of N encoder layers.\nNote\nSee\nthis tutorial\nfor an in depth discussion of the performant building blocks PyTorch offers for building your own\ntransformer layers.\nUsers can build the BERT(\nhttps://arxiv.org/abs/1810.04805\n) model with corresponding parameters.\nParameters\nencoder_layer\n(\nTransformerEncoderLayer\n) – an instance of the TransformerEncoderLayer() class (required).\nnum_layers\n(\nint\n) – the number of sub-encoder-layers in the encoder (required).\nnorm\n(\nOptional\n[\nModule\n]\n) – the layer normalization component (optional).\nenable_nested_tensor\n(\nbool\n) – if True, input will automatically convert to nested tensor\n(and convert back on output). This will improve the overall performance of\nTransformerEncoder when padding rate is high. Default:\nTrue\n(enabled).\nExamples::\n>>>\nencoder_layer\n=\nnn\n.\nTransformerEncoderLayer\n(\nd_model\n=\n512\n,\nnhead\n=\n8\n)\n>>>\ntransformer_encoder\n=\nnn\n.\nTransformerEncoder\n(\nencoder_layer\n,\nnum_layers\n=\n6\n)\n>>>\nsrc\n=\ntorch\n.\nrand\n(\n10\n,\n32\n,\n512\n)\n>>>\nout\n=\ntransformer_encoder\n(\nsrc\n)\nforward\n(\nsrc\n,\nmask\n=\nNone\n,\nsrc_key_padding_mask\n=\nNone\n,\nis_causal\n=\nNone\n)\n[source]\n[source]\n¶\nPass the input through the encoder layers in turn.\nParameters\nsrc\n(\nTensor\n) – the sequence to the encoder (required).\nmask\n(\nOptional\n[\nTensor\n]\n) – the mask for the src sequence (optional).\nsrc_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the src keys per batch (optional).\nis_causal\n(\nOptional\n[\nbool\n]\n) – If specified, applies a causal mask as\nmask\n.\nDefault:\nNone\n; try to detect a causal mask.\nWarning:\nis_causal\nprovides a hint that\nmask\nis the\ncausal mask. Providing incorrect hints can result in\nincorrect execution, including forward and backward\ncompatibility.\nReturn type\nTensor\nShape:\nsee the docs in\nTransformer\n.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#transformerencoder",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoder",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L310",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder",
    "https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html",
    "https://arxiv.org/abs/1810.04805",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoder.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L390",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder.forward",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.TransformerDecoder",
  "page_text": "TransformerDecoder\n¶\nclass\ntorch.nn.\nTransformerDecoder\n(\ndecoder_layer\n,\nnum_layers\n,\nnorm\n=\nNone\n)\n[source]\n[source]\n¶\nTransformerDecoder is a stack of N decoder layers.\nNote\nSee\nthis tutorial\nfor an in depth discussion of the performant building blocks PyTorch offers for building your own\ntransformer layers.\nParameters\ndecoder_layer\n(\nTransformerDecoderLayer\n) – an instance of the TransformerDecoderLayer() class (required).\nnum_layers\n(\nint\n) – the number of sub-decoder-layers in the decoder (required).\nnorm\n(\nOptional\n[\nModule\n]\n) – the layer normalization component (optional).\nExamples::\n>>>\ndecoder_layer\n=\nnn\n.\nTransformerDecoderLayer\n(\nd_model\n=\n512\n,\nnhead\n=\n8\n)\n>>>\ntransformer_decoder\n=\nnn\n.\nTransformerDecoder\n(\ndecoder_layer\n,\nnum_layers\n=\n6\n)\n>>>\nmemory\n=\ntorch\n.\nrand\n(\n10\n,\n32\n,\n512\n)\n>>>\ntgt\n=\ntorch\n.\nrand\n(\n20\n,\n32\n,\n512\n)\n>>>\nout\n=\ntransformer_decoder\n(\ntgt\n,\nmemory\n)\nforward\n(\ntgt\n,\nmemory\n,\ntgt_mask\n=\nNone\n,\nmemory_mask\n=\nNone\n,\ntgt_key_padding_mask\n=\nNone\n,\nmemory_key_padding_mask\n=\nNone\n,\ntgt_is_causal\n=\nNone\n,\nmemory_is_causal\n=\nFalse\n)\n[source]\n[source]\n¶\nPass the inputs (and mask) through the decoder layer in turn.\nParameters\ntgt\n(\nTensor\n) – the sequence to the decoder (required).\nmemory\n(\nTensor\n) – the sequence from the last layer of the encoder (required).\ntgt_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the tgt sequence (optional).\nmemory_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the memory sequence (optional).\ntgt_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the tgt keys per batch (optional).\nmemory_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the memory keys per batch (optional).\ntgt_is_causal\n(\nOptional\n[\nbool\n]\n) – If specified, applies a causal mask as\ntgt\nmask\n.\nDefault:\nNone\n; try to detect a causal mask.\nWarning:\ntgt_is_causal\nprovides a hint that\ntgt_mask\nis\nthe causal mask. Providing incorrect hints can result in\nincorrect execution, including forward and backward\ncompatibility.\nmemory_is_causal\n(\nbool\n) – If specified, applies a causal mask as\nmemory\nmask\n.\nDefault:\nFalse\n.\nWarning:\nmemory_is_causal\nprovides a hint that\nmemory_mask\nis the causal mask. Providing incorrect\nhints can result in incorrect execution, including\nforward and backward compatibility.\nReturn type\nTensor\nShape:\nsee the docs in\nTransformer\n.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#transformerdecoder",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerDecoder",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L533",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder",
    "https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html#torch.nn.TransformerDecoderLayer",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerDecoder.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L568",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder.forward",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.TransformerEncoderLayer",
  "page_text": "TransformerEncoderLayer\n¶\nclass\ntorch.nn.\nTransformerEncoderLayer\n(\nd_model\n,\nnhead\n,\ndim_feedforward=2048\n,\ndropout=0.1\n,\nactivation=<function\nrelu>\n,\nlayer_norm_eps=1e-05\n,\nbatch_first=False\n,\nnorm_first=False\n,\nbias=True\n,\ndevice=None\n,\ndtype=None\n)\n[source]\n[source]\n¶\nTransformerEncoderLayer is made up of self-attn and feedforward network.\nNote\nSee\nthis tutorial\nfor an in depth discussion of the performant building blocks PyTorch offers for building your own\ntransformer layers.\nThis standard encoder layer is based on the paper “Attention Is All You Need”.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nLukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in\nNeural Information Processing Systems, pages 6000-6010. Users may modify or implement\nin a different way during application.\nTransformerEncoderLayer can handle either traditional torch.tensor inputs,\nor Nested Tensor inputs.  Derived classes are expected to similarly accept\nboth input formats.  (Not all combinations of inputs are currently\nsupported by TransformerEncoderLayer while Nested Tensor is in prototype\nstate.)\nIf you are implementing a custom layer, you may derive it either from\nthe Module or TransformerEncoderLayer class.  If your custom layer\nsupports both torch.Tensors and Nested Tensors inputs, make its\nimplementation a derived class of TransformerEncoderLayer. If your custom\nLayer supports only torch.Tensor inputs, derive its implementation from\nModule.\nParameters\nd_model\n(\nint\n) – the number of expected features in the input (required).\nnhead\n(\nint\n) – the number of heads in the multiheadattention models (required).\ndim_feedforward\n(\nint\n) – the dimension of the feedforward network model (default=2048).\ndropout\n(\nfloat\n) – the dropout value (default=0.1).\nactivation\n(\nUnion\n[\nstr\n,\nCallable\n[\n[\nTensor\n]\n,\nTensor\n]\n]\n) – the activation function of the intermediate layer, can be a string\n(“relu” or “gelu”) or a unary callable. Default: relu\nlayer_norm_eps\n(\nfloat\n) – the eps value in layer normalization components (default=1e-5).\nbatch_first\n(\nbool\n) – If\nTrue\n, then the input and output tensors are provided\nas (batch, seq, feature). Default:\nFalse\n(seq, batch, feature).\nnorm_first\n(\nbool\n) – if\nTrue\n, layer norm is done prior to attention and feedforward\noperations, respectively. Otherwise it’s done after. Default:\nFalse\n(after).\nbias\n(\nbool\n) – If set to\nFalse\n,\nLinear\nand\nLayerNorm\nlayers will not learn an additive\nbias. Default:\nTrue\n.\nExamples::\n>>>\nencoder_layer\n=\nnn\n.\nTransformerEncoderLayer\n(\nd_model\n=\n512\n,\nnhead\n=\n8\n)\n>>>\nsrc\n=\ntorch\n.\nrand\n(\n10\n,\n32\n,\n512\n)\n>>>\nout\n=\nencoder_layer\n(\nsrc\n)\nAlternatively, when\nbatch_first\nis\nTrue\n:\n>>>\nencoder_layer\n=\nnn\n.\nTransformerEncoderLayer\n(\nd_model\n=\n512\n,\nnhead\n=\n8\n,\nbatch_first\n=\nTrue\n)\n>>>\nsrc\n=\ntorch\n.\nrand\n(\n32\n,\n10\n,\n512\n)\n>>>\nout\n=\nencoder_layer\n(\nsrc\n)\nFast path:\nforward() will use a special optimized implementation described in\nFlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\nif all of the following\nconditions are met:\nEither autograd is disabled (using\ntorch.inference_mode\nor\ntorch.no_grad\n) or no tensor\nargument\nrequires_grad\ntraining is disabled (using\n.eval()\n)\nbatch_first is\nTrue\nand the input is batched (i.e.,\nsrc.dim()\n==\n3\n)\nactivation is one of:\n\"relu\"\n,\n\"gelu\"\n,\ntorch.functional.relu\n, or\ntorch.functional.gelu\nat most one of\nsrc_mask\nand\nsrc_key_padding_mask\nis passed\nif src is a\nNestedTensor\n, neither\nsrc_mask\nnor\nsrc_key_padding_mask\nis passed\nthe two\nLayerNorm\ninstances have a consistent\neps\nvalue (this will naturally be the case\nunless the caller has manually modified one without modifying the other)\nIf the optimized implementation is in use, a\nNestedTensor\ncan be\npassed for\nsrc\nto represent padding more efficiently than using a padding\nmask. In this case, a\nNestedTensor\nwill be\nreturned, and an additional speedup proportional to the fraction of the input that\nis padding can be expected.\nforward\n(\nsrc\n,\nsrc_mask\n=\nNone\n,\nsrc_key_padding_mask\n=\nNone\n,\nis_causal\n=\nFalse\n)\n[source]\n[source]\n¶\nPass the input through the encoder layer.\nParameters\nsrc\n(\nTensor\n) – the sequence to the encoder layer (required).\nsrc_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the src sequence (optional).\nsrc_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the src keys per batch (optional).\nis_causal\n(\nbool\n) – If specified, applies a causal mask as\nsrc\nmask\n.\nDefault:\nFalse\n.\nWarning:\nis_causal\nprovides a hint that\nsrc_mask\nis the\ncausal mask. Providing incorrect hints can result in\nincorrect execution, including forward and backward\ncompatibility.\nReturn type\nTensor\nShape:\nsee the docs in\nTransformer\n.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html#transformerencoderlayer",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L630",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer",
    "https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/typing.html#typing.Callable",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://arxiv.org/abs/2205.14135",
    "https://pytorch.org/docs/stable/nested.html",
    "https://pytorch.org/docs/stable/nested.html",
    "https://pytorch.org/docs/stable/nested.html",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L766",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer.forward",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.TransformerDecoderLayer",
  "page_text": "TransformerDecoderLayer\n¶\nclass\ntorch.nn.\nTransformerDecoderLayer\n(\nd_model\n,\nnhead\n,\ndim_feedforward=2048\n,\ndropout=0.1\n,\nactivation=<function\nrelu>\n,\nlayer_norm_eps=1e-05\n,\nbatch_first=False\n,\nnorm_first=False\n,\nbias=True\n,\ndevice=None\n,\ndtype=None\n)\n[source]\n[source]\n¶\nTransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.\nNote\nSee\nthis tutorial\nfor an in depth discussion of the performant building blocks PyTorch offers for building your own\ntransformer layers.\nThis standard decoder layer is based on the paper “Attention Is All You Need”.\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\nLukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in\nNeural Information Processing Systems, pages 6000-6010. Users may modify or implement\nin a different way during application.\nParameters\nd_model\n(\nint\n) – the number of expected features in the input (required).\nnhead\n(\nint\n) – the number of heads in the multiheadattention models (required).\ndim_feedforward\n(\nint\n) – the dimension of the feedforward network model (default=2048).\ndropout\n(\nfloat\n) – the dropout value (default=0.1).\nactivation\n(\nUnion\n[\nstr\n,\nCallable\n[\n[\nTensor\n]\n,\nTensor\n]\n]\n) – the activation function of the intermediate layer, can be a string\n(“relu” or “gelu”) or a unary callable. Default: relu\nlayer_norm_eps\n(\nfloat\n) – the eps value in layer normalization components (default=1e-5).\nbatch_first\n(\nbool\n) – If\nTrue\n, then the input and output tensors are provided\nas (batch, seq, feature). Default:\nFalse\n(seq, batch, feature).\nnorm_first\n(\nbool\n) – if\nTrue\n, layer norm is done prior to self attention, multihead\nattention and feedforward operations, respectively. Otherwise it’s done after.\nDefault:\nFalse\n(after).\nbias\n(\nbool\n) – If set to\nFalse\n,\nLinear\nand\nLayerNorm\nlayers will not learn an additive\nbias. Default:\nTrue\n.\nExamples::\n>>>\ndecoder_layer\n=\nnn\n.\nTransformerDecoderLayer\n(\nd_model\n=\n512\n,\nnhead\n=\n8\n)\n>>>\nmemory\n=\ntorch\n.\nrand\n(\n10\n,\n32\n,\n512\n)\n>>>\ntgt\n=\ntorch\n.\nrand\n(\n20\n,\n32\n,\n512\n)\n>>>\nout\n=\ndecoder_layer\n(\ntgt\n,\nmemory\n)\nAlternatively, when\nbatch_first\nis\nTrue\n:\n>>>\ndecoder_layer\n=\nnn\n.\nTransformerDecoderLayer\n(\nd_model\n=\n512\n,\nnhead\n=\n8\n,\nbatch_first\n=\nTrue\n)\n>>>\nmemory\n=\ntorch\n.\nrand\n(\n32\n,\n10\n,\n512\n)\n>>>\ntgt\n=\ntorch\n.\nrand\n(\n32\n,\n20\n,\n512\n)\n>>>\nout\n=\ndecoder_layer\n(\ntgt\n,\nmemory\n)\nforward\n(\ntgt\n,\nmemory\n,\ntgt_mask\n=\nNone\n,\nmemory_mask\n=\nNone\n,\ntgt_key_padding_mask\n=\nNone\n,\nmemory_key_padding_mask\n=\nNone\n,\ntgt_is_causal\n=\nFalse\n,\nmemory_is_causal\n=\nFalse\n)\n[source]\n[source]\n¶\nPass the inputs (and mask) through the decoder layer.\nParameters\ntgt\n(\nTensor\n) – the sequence to the decoder layer (required).\nmemory\n(\nTensor\n) – the sequence from the last layer of the encoder (required).\ntgt_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the tgt sequence (optional).\nmemory_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the memory sequence (optional).\ntgt_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the tgt keys per batch (optional).\nmemory_key_padding_mask\n(\nOptional\n[\nTensor\n]\n) – the mask for the memory keys per batch (optional).\ntgt_is_causal\n(\nbool\n) – If specified, applies a causal mask as\ntgt\nmask\n.\nDefault:\nFalse\n.\nWarning:\ntgt_is_causal\nprovides a hint that\ntgt_mask\nis\nthe causal mask. Providing incorrect hints can result in\nincorrect execution, including forward and backward\ncompatibility.\nmemory_is_causal\n(\nbool\n) – If specified, applies a causal mask as\nmemory\nmask\n.\nDefault:\nFalse\n.\nWarning:\nmemory_is_causal\nprovides a hint that\nmemory_mask\nis the causal mask. Providing incorrect\nhints can result in incorrect execution, including\nforward and backward compatibility.\nReturn type\nTensor\nShape:\nsee the docs in\nTransformer\n.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html#transformerdecoderlayer",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerDecoderLayer",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L951",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html#torch.nn.TransformerDecoderLayer",
    "https://pytorch.org/tutorials/intermediate/transformer_building_blocks.html",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/typing.html#typing.Callable",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerDecoderLayer.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/transformer.py#L1052",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html#torch.nn.TransformerDecoderLayer.forward",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer",
    "https://pytorch.org/docs/stable/generated/torch.nn.Identity.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Identity",
  "page_text": "Identity\n¶\nclass\ntorch.nn.\nIdentity\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nA placeholder identity operator that is argument-insensitive.\nParameters\nargs\n(\nAny\n) – any argument (unused)\nkwargs\n(\nAny\n) – any keyword argument (unused)\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nm\n=\nnn\n.\nIdentity\n(\n54\n,\nunused_argument1\n=\n0.1\n,\nunused_argument2\n=\nFalse\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n128\n,\n20\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\nprint\n(\noutput\n.\nsize\n())\ntorch.Size([128, 20])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Identity.html#identity",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Identity",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/linear.py#L22",
    "https://pytorch.org/docs/stable/generated/torch.nn.Identity.html#torch.nn.Identity",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://docs.python.org/3/library/typing.html#typing.Any",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Linear",
  "page_text": "Linear\n¶\nclass\ntorch.nn.\nLinear\n(\nin_features\n,\nout_features\n,\nbias\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies an affine linear transformation to the incoming data:\ny\n=\nx\nA\nT\n+\nb\ny = xA^T + b\ny\n=\nx\nA\nT\n+\nb\n.\nThis module supports\nTensorFloat32\n.\nOn certain ROCm devices, when using float16 inputs this module will use\ndifferent precision\nfor backward.\nParameters\nin_features\n(\nint\n) – size of each input sample\nout_features\n(\nint\n) – size of each output sample\nbias\n(\nbool\n) – If set to\nFalse\n, the layer will not learn an additive bias.\nDefault:\nTrue\nShape:\nInput:\n(\n∗\n,\nH\ni\nn\n)\n(*, H_{in})\n(\n∗\n,\nH\nin\n​\n)\nwhere\n∗\n*\n∗\nmeans any number of\ndimensions including none and\nH\ni\nn\n=\nin_features\nH_{in} = \\text{in\\_features}\nH\nin\n​\n=\nin_features\n.\nOutput:\n(\n∗\n,\nH\no\nu\nt\n)\n(*, H_{out})\n(\n∗\n,\nH\no\nu\nt\n​\n)\nwhere all but the last dimension\nare the same shape as the input and\nH\no\nu\nt\n=\nout_features\nH_{out} = \\text{out\\_features}\nH\no\nu\nt\n​\n=\nout_features\n.\nVariables\nweight\n(\ntorch.Tensor\n) – the learnable weights of the module of shape\n(\nout_features\n,\nin_features\n)\n(\\text{out\\_features}, \\text{in\\_features})\n(\nout_features\n,\nin_features\n)\n. The values are\ninitialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\n, where\nk\n=\n1\nin_features\nk = \\frac{1}{\\text{in\\_features}}\nk\n=\nin_features\n1\n​\nbias\n– the learnable bias of the module of shape\n(\nout_features\n)\n(\\text{out\\_features})\n(\nout_features\n)\n.\nIf\nbias\nis\nTrue\n, the values are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\n1\nin_features\nk = \\frac{1}{\\text{in\\_features}}\nk\n=\nin_features\n1\n​\nExamples:\n>>>\nm\n=\nnn\n.\nLinear\n(\n20\n,\n30\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n128\n,\n20\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\nprint\n(\noutput\n.\nsize\n())\ntorch.Size([128, 30])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#linear",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/linear.py#L50",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/notes/cuda.html#tf32-on-ampere",
    "https://pytorch.org/docs/stable/notes/numerical_accuracy.html#fp16-on-mi200",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Bilinear.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Identity.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Bilinear",
  "page_text": "Bilinear\n¶\nclass\ntorch.nn.\nBilinear\n(\nin1_features\n,\nin2_features\n,\nout_features\n,\nbias\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a bilinear transformation to the incoming data:\ny\n=\nx\n1\nT\nA\nx\n2\n+\nb\ny = x_1^T A x_2 + b\ny\n=\nx\n1\nT\n​\nA\nx\n2\n​\n+\nb\n.\nParameters\nin1_features\n(\nint\n) – size of each first input sample\nin2_features\n(\nint\n) – size of each second input sample\nout_features\n(\nint\n) – size of each output sample\nbias\n(\nbool\n) – If set to False, the layer will not learn an additive bias.\nDefault:\nTrue\nShape:\nInput1:\n(\n∗\n,\nH\ni\nn\n1\n)\n(*, H_{in1})\n(\n∗\n,\nH\nin\n1\n​\n)\nwhere\nH\ni\nn\n1\n=\nin1_features\nH_{in1}=\\text{in1\\_features}\nH\nin\n1\n​\n=\nin1_features\nand\n∗\n*\n∗\nmeans any number of additional dimensions including none. All but the last dimension\nof the inputs should be the same.\nInput2:\n(\n∗\n,\nH\ni\nn\n2\n)\n(*, H_{in2})\n(\n∗\n,\nH\nin\n2\n​\n)\nwhere\nH\ni\nn\n2\n=\nin2_features\nH_{in2}=\\text{in2\\_features}\nH\nin\n2\n​\n=\nin2_features\n.\nOutput:\n(\n∗\n,\nH\no\nu\nt\n)\n(*, H_{out})\n(\n∗\n,\nH\no\nu\nt\n​\n)\nwhere\nH\no\nu\nt\n=\nout_features\nH_{out}=\\text{out\\_features}\nH\no\nu\nt\n​\n=\nout_features\nand all but the last dimension are the same shape as the input.\nVariables\nweight\n(\ntorch.Tensor\n) – the learnable weights of the module of shape\n(\nout_features\n,\nin1_features\n,\nin2_features\n)\n(\\text{out\\_features}, \\text{in1\\_features}, \\text{in2\\_features})\n(\nout_features\n,\nin1_features\n,\nin2_features\n)\n.\nThe values are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\n, where\nk\n=\n1\nin1_features\nk = \\frac{1}{\\text{in1\\_features}}\nk\n=\nin1_features\n1\n​\nbias\n– the learnable bias of the module of shape\n(\nout_features\n)\n(\\text{out\\_features})\n(\nout_features\n)\n.\nIf\nbias\nis\nTrue\n, the values are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\n, where\nk\n=\n1\nin1_features\nk = \\frac{1}{\\text{in1\\_features}}\nk\n=\nin1_features\n1\n​\nExamples:\n>>>\nm\n=\nnn\n.\nBilinear\n(\n20\n,\n30\n,\n40\n)\n>>>\ninput1\n=\ntorch\n.\nrandn\n(\n128\n,\n20\n)\n>>>\ninput2\n=\ntorch\n.\nrandn\n(\n128\n,\n30\n)\n>>>\noutput\n=\nm\n(\ninput1\n,\ninput2\n)\n>>>\nprint\n(\noutput\n.\nsize\n())\ntorch.Size([128, 40])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Bilinear.html#bilinear",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Bilinear",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/linear.py#L150",
    "https://pytorch.org/docs/stable/generated/torch.nn.Bilinear.html#torch.nn.Bilinear",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.LazyLinear",
  "page_text": "LazyLinear\n¶\nclass\ntorch.nn.\nLazyLinear\n(\nout_features\n,\nbias\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA\ntorch.nn.Linear\nmodule where\nin_features\nis inferred.\nIn this module, the\nweight\nand\nbias\nare of\ntorch.nn.UninitializedParameter\nclass. They will be initialized after the first call to\nforward\nis done and the\nmodule will become a regular\ntorch.nn.Linear\nmodule. The\nin_features\nargument\nof the\nLinear\nis inferred from the\ninput.shape[-1]\n.\nCheck the\ntorch.nn.modules.lazy.LazyModuleMixin\nfor further documentation\non lazy modules and their limitations.\nParameters\nout_features\n(\nint\n) – size of each output sample\nbias\n(\nUninitializedParameter\n) – If set to\nFalse\n, the layer will not learn an additive bias.\nDefault:\nTrue\nVariables\nweight\n(\ntorch.nn.parameter.UninitializedParameter\n) – the learnable weights of the module of shape\n(\nout_features\n,\nin_features\n)\n(\\text{out\\_features}, \\text{in\\_features})\n(\nout_features\n,\nin_features\n)\n. The values are\ninitialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\n, where\nk\n=\n1\nin_features\nk = \\frac{1}{\\text{in\\_features}}\nk\n=\nin_features\n1\n​\nbias\n(\ntorch.nn.parameter.UninitializedParameter\n) – the learnable bias of the module of shape\n(\nout_features\n)\n(\\text{out\\_features})\n(\nout_features\n)\n.\nIf\nbias\nis\nTrue\n, the values are initialized from\nU\n(\n−\nk\n,\nk\n)\n\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})\nU\n(\n−\nk\n​\n,\nk\n​\n)\nwhere\nk\n=\n1\nin_features\nk = \\frac{1}{\\text{in\\_features}}\nk\n=\nin_features\n1\n​\ncls_to_become\n[source]\n¶\nalias of\nLinear\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#lazylinear",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#LazyLinear",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/linear.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/linear.py#L50",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear.cls_to_become",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Bilinear.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Dropout",
  "page_text": "Dropout\n¶\nclass\ntorch.nn.\nDropout\n(\np\n=\n0.5\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nDuring training, randomly zeroes some of the elements of the input tensor with probability\np\n.\nThe zeroed elements are chosen independently for each forward call and are sampled from a Bernoulli distribution.\nEach channel will be zeroed out independently on every forward call.\nThis has proven to be an effective technique for regularization and\npreventing the co-adaptation of neurons as described in the paper\nImproving neural networks by preventing co-adaptation of feature\ndetectors\n.\nFurthermore, the outputs are scaled by a factor of\n1\n1\n−\np\n\\frac{1}{1-p}\n1\n−\np\n1\n​\nduring\ntraining. This means that during evaluation the module simply computes an\nidentity function.\nParameters\np\n(\nfloat\n) – probability of an element to be zeroed. Default: 0.5\ninplace\n(\nbool\n) – If set to\nTrue\n, will do this operation in-place. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n. Input can be of any shape\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n. Output is of the same shape as input\nExamples:\n>>>\nm\n=\nnn\n.\nDropout\n(\np\n=\n0.2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#dropout",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/dropout.html#Dropout",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/dropout.py#L35",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout",
    "https://arxiv.org/abs/1207.0580",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout1d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Dropout1d",
  "page_text": "Dropout1d\n¶\nclass\ntorch.nn.\nDropout1d\n(\np\n=\n0.5\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nRandomly zero out entire channels.\nA channel is a 1D feature map,\ne.g., the\nj\nj\nj\n-th channel of the\ni\ni\ni\n-th sample in the\nbatched input is a 1D tensor\ninput\n[\ni\n,\nj\n]\n\\text{input}[i, j]\ninput\n[\ni\n,\nj\n]\n.\nEach channel will be zeroed out independently on every forward call with\nprobability\np\nusing samples from a Bernoulli distribution.\nUsually the input comes from\nnn.Conv1d\nmodules.\nAs described in the paper\nEfficient Object Localization Using Convolutional Networks\n,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d. dropout\nwill not regularize the activations and will otherwise just result\nin an effective learning rate decrease.\nIn this case,\nnn.Dropout1d()\nwill help promote independence between\nfeature maps and should be used instead.\nParameters\np\n(\nfloat\n,\noptional\n) – probability of an element to be zero-ed.\ninplace\n(\nbool\n,\noptional\n) – If set to\nTrue\n, will do this operation\nin-place\nShape:\nInput:\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\nor\n(\nC\n,\nL\n)\n(C, L)\n(\nC\n,\nL\n)\n.\nOutput:\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\nor\n(\nC\n,\nL\n)\n(C, L)\n(\nC\n,\nL\n)\n(same shape as input).\nExamples:\n>>>\nm\n=\nnn\n.\nDropout1d\n(\np\n=\n0.2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n32\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout1d.html#dropout1d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/dropout.html#Dropout1d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/dropout.py#L73",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout1d.html#torch.nn.Dropout1d",
    "https://arxiv.org/abs/1411.4280",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Dropout2d",
  "page_text": "Dropout2d\n¶\nclass\ntorch.nn.\nDropout2d\n(\np\n=\n0.5\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nRandomly zero out entire channels.\nA channel is a 2D feature map,\ne.g., the\nj\nj\nj\n-th channel of the\ni\ni\ni\n-th sample in the\nbatched input is a 2D tensor\ninput\n[\ni\n,\nj\n]\n\\text{input}[i, j]\ninput\n[\ni\n,\nj\n]\n.\nEach channel will be zeroed out independently on every forward call with\nprobability\np\nusing samples from a Bernoulli distribution.\nUsually the input comes from\nnn.Conv2d\nmodules.\nAs described in the paper\nEfficient Object Localization Using Convolutional Networks\n,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d. dropout\nwill not regularize the activations and will otherwise just result\nin an effective learning rate decrease.\nIn this case,\nnn.Dropout2d()\nwill help promote independence between\nfeature maps and should be used instead.\nParameters\np\n(\nfloat\n,\noptional\n) – probability of an element to be zero-ed.\ninplace\n(\nbool\n,\noptional\n) – If set to\nTrue\n, will do this operation\nin-place\nWarning\nDue to historical reasons, this class will perform 1D channel-wise dropout\nfor 3D inputs (as done by\nnn.Dropout1d\n). Thus, it currently does NOT\nsupport inputs without a batch dimension of shape\n(\nC\n,\nH\n,\nW\n)\n(C, H, W)\n(\nC\n,\nH\n,\nW\n)\n. This\nbehavior will change in a future release to interpret 3D inputs as no-batch-dim\ninputs. To maintain the old behavior, switch to\nnn.Dropout1d\n.\nShape:\nInput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\n.\nOutput:\n(\nN\n,\nC\n,\nH\n,\nW\n)\n(N, C, H, W)\n(\nN\n,\nC\n,\nH\n,\nW\n)\nor\n(\nN\n,\nC\n,\nL\n)\n(N, C, L)\n(\nN\n,\nC\n,\nL\n)\n(same shape as input).\nExamples:\n>>>\nm\n=\nnn\n.\nDropout2d\n(\np\n=\n0.2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n32\n,\n32\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html#dropout2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/dropout.html#Dropout2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/dropout.py#L118",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html#torch.nn.Dropout2d",
    "https://arxiv.org/abs/1411.4280",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout3d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout1d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Dropout3d",
  "page_text": "Dropout3d\n¶\nclass\ntorch.nn.\nDropout3d\n(\np\n=\n0.5\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nRandomly zero out entire channels.\nA channel is a 3D feature map,\ne.g., the\nj\nj\nj\n-th channel of the\ni\ni\ni\n-th sample in the\nbatched input is a 3D tensor\ninput\n[\ni\n,\nj\n]\n\\text{input}[i, j]\ninput\n[\ni\n,\nj\n]\n.\nEach channel will be zeroed out independently on every forward call with\nprobability\np\nusing samples from a Bernoulli distribution.\nUsually the input comes from\nnn.Conv3d\nmodules.\nAs described in the paper\nEfficient Object Localization Using Convolutional Networks\n,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d. dropout\nwill not regularize the activations and will otherwise just result\nin an effective learning rate decrease.\nIn this case,\nnn.Dropout3d()\nwill help promote independence between\nfeature maps and should be used instead.\nParameters\np\n(\nfloat\n,\noptional\n) – probability of an element to be zeroed.\ninplace\n(\nbool\n,\noptional\n) – If set to\nTrue\n, will do this operation\nin-place\nShape:\nInput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(same shape as input).\nExamples:\n>>>\nm\n=\nnn\n.\nDropout3d\n(\np\n=\n0.2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n4\n,\n32\n,\n32\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout3d.html#dropout3d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/dropout.html#Dropout3d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/dropout.py#L170",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout3d.html#torch.nn.Dropout3d",
    "https://arxiv.org/abs/1411.4280",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.AlphaDropout.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.AlphaDropout",
  "page_text": "AlphaDropout\n¶\nclass\ntorch.nn.\nAlphaDropout\n(\np\n=\n0.5\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nApplies Alpha Dropout over the input.\nAlpha Dropout is a type of Dropout that maintains the self-normalizing\nproperty.\nFor an input with zero mean and unit standard deviation, the output of\nAlpha Dropout maintains the original mean and standard deviation of the\ninput.\nAlpha Dropout goes hand-in-hand with SELU activation function, which ensures\nthat the outputs have zero mean and unit standard deviation.\nDuring training, it randomly masks some of the elements of the input\ntensor with probability\np\nusing samples from a bernoulli distribution.\nThe elements to masked are randomized on every forward call, and scaled\nand shifted to maintain zero mean and unit standard deviation.\nDuring evaluation the module simply computes an identity function.\nMore details can be found in the paper\nSelf-Normalizing Neural Networks\n.\nParameters\np\n(\nfloat\n) – probability of an element to be dropped. Default: 0.5\ninplace\n(\nbool\n,\noptional\n) – If set to\nTrue\n, will do this operation\nin-place\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n. Input can be of any shape\nOutput:\n(\n∗\n)\n(*)\n(\n∗\n)\n. Output is of the same shape as input\nExamples:\n>>>\nm\n=\nnn\n.\nAlphaDropout\n(\np\n=\n0.2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.AlphaDropout.html#alphadropout",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/dropout.html#AlphaDropout",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/dropout.py#L215",
    "https://pytorch.org/docs/stable/generated/torch.nn.AlphaDropout.html#torch.nn.AlphaDropout",
    "https://arxiv.org/abs/1706.02515",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.FeatureAlphaDropout.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Dropout3d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.FeatureAlphaDropout",
  "page_text": "FeatureAlphaDropout\n¶\nclass\ntorch.nn.\nFeatureAlphaDropout\n(\np\n=\n0.5\n,\ninplace\n=\nFalse\n)\n[source]\n[source]\n¶\nRandomly masks out entire channels.\nA channel is a feature map,\ne.g. the\nj\nj\nj\n-th channel of the\ni\ni\ni\n-th sample in the batch input\nis a tensor\ninput\n[\ni\n,\nj\n]\n\\text{input}[i, j]\ninput\n[\ni\n,\nj\n]\nof the input tensor). Instead of\nsetting activations to zero, as in regular Dropout, the activations are set\nto the negative saturation value of the SELU activation function. More details\ncan be found in the paper\nSelf-Normalizing Neural Networks\n.\nEach element will be masked independently for each sample on every forward\ncall with probability\np\nusing samples from a Bernoulli distribution.\nThe elements to be masked are randomized on every forward call, and scaled\nand shifted to maintain zero mean and unit variance.\nUsually the input comes from\nnn.AlphaDropout\nmodules.\nAs described in the paper\nEfficient Object Localization Using Convolutional Networks\n,\nif adjacent pixels within feature maps are strongly correlated\n(as is normally the case in early convolution layers) then i.i.d. dropout\nwill not regularize the activations and will otherwise just result\nin an effective learning rate decrease.\nIn this case,\nnn.AlphaDropout()\nwill help promote independence between\nfeature maps and should be used instead.\nParameters\np\n(\nfloat\n,\noptional\n) – probability of an element to be zeroed. Default: 0.5\ninplace\n(\nbool\n,\noptional\n) – If set to\nTrue\n, will do this operation\nin-place\nShape:\nInput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\n.\nOutput:\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\n(N, C, D, H, W)\n(\nN\n,\nC\n,\nD\n,\nH\n,\nW\n)\nor\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(C, D, H, W)\n(\nC\n,\nD\n,\nH\n,\nW\n)\n(same shape as input).\nExamples:\n>>>\nm\n=\nnn\n.\nFeatureAlphaDropout\n(\np\n=\n0.2\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n20\n,\n16\n,\n4\n,\n32\n,\n32\n)\n>>>\noutput\n=\nm\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.FeatureAlphaDropout.html#featurealphadropout",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/dropout.html#FeatureAlphaDropout",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/dropout.py#L257",
    "https://pytorch.org/docs/stable/generated/torch.nn.FeatureAlphaDropout.html#torch.nn.FeatureAlphaDropout",
    "https://arxiv.org/abs/1706.02515",
    "https://arxiv.org/abs/1411.4280",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.AlphaDropout.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Embedding",
  "page_text": "Embedding\n¶\nclass\ntorch.nn.\nEmbedding\n(\nnum_embeddings\n,\nembedding_dim\n,\npadding_idx\n=\nNone\n,\nmax_norm\n=\nNone\n,\nnorm_type\n=\n2.0\n,\nscale_grad_by_freq\n=\nFalse\n,\nsparse\n=\nFalse\n,\n_weight\n=\nNone\n,\n_freeze\n=\nFalse\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nA simple lookup table that stores embeddings of a fixed dictionary and size.\nThis module is often used to store word embeddings and retrieve them using indices.\nThe input to the module is a list of indices, and the output is the corresponding\nword embeddings.\nParameters\nnum_embeddings\n(\nint\n) – size of the dictionary of embeddings\nembedding_dim\n(\nint\n) – the size of each embedding vector\npadding_idx\n(\nint\n,\noptional\n) – If specified, the entries at\npadding_idx\ndo not contribute to the gradient;\ntherefore, the embedding vector at\npadding_idx\nis not updated during training,\ni.e. it remains as a fixed “pad”. For a newly constructed Embedding,\nthe embedding vector at\npadding_idx\nwill default to all zeros,\nbut can be updated to another value to be used as the padding vector.\nmax_norm\n(\nfloat\n,\noptional\n) – If given, each embedding vector with norm larger than\nmax_norm\nis renormalized to have norm\nmax_norm\n.\nnorm_type\n(\nfloat\n,\noptional\n) – The p of the p-norm to compute for the\nmax_norm\noption. Default\n2\n.\nscale_grad_by_freq\n(\nbool\n,\noptional\n) – If given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default\nFalse\n.\nsparse\n(\nbool\n,\noptional\n) – If\nTrue\n, gradient w.r.t.\nweight\nmatrix will be a sparse tensor.\nSee Notes for more details regarding sparse gradients.\nVariables\nweight\n(\nTensor\n) – the learnable weights of the module of shape (num_embeddings, embedding_dim)\ninitialized from\nN\n(\n0\n,\n1\n)\n\\mathcal{N}(0, 1)\nN\n(\n0\n,\n1\n)\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, IntTensor or LongTensor of arbitrary shape containing the indices to extract\nOutput:\n(\n∗\n,\nH\n)\n(*, H)\n(\n∗\n,\nH\n)\n, where\n*\nis the input shape and\nH\n=\nembedding_dim\nH=\\text{embedding\\_dim}\nH\n=\nembedding_dim\nNote\nKeep in mind that only a limited number of optimizers support\nsparse gradients: currently it’s\noptim.SGD\n(\nCUDA\nand\nCPU\n),\noptim.SparseAdam\n(\nCUDA\nand\nCPU\n) and\noptim.Adagrad\n(\nCPU\n)\nNote\nWhen\nmax_norm\nis not\nNone\n,\nEmbedding\n’s forward method will modify the\nweight\ntensor in-place. Since tensors needed for gradient computations cannot be\nmodified in-place, performing a differentiable operation on\nEmbedding.weight\nbefore\ncalling\nEmbedding\n’s forward method requires cloning\nEmbedding.weight\nwhen\nmax_norm\nis not\nNone\n. For example:\nn\n,\nd\n,\nm\n=\n3\n,\n5\n,\n7\nembedding\n=\nnn\n.\nEmbedding\n(\nn\n,\nd\n,\nmax_norm\n=\n1.0\n)\nW\n=\ntorch\n.\nrandn\n((\nm\n,\nd\n),\nrequires_grad\n=\nTrue\n)\nidx\n=\ntorch\n.\ntensor\n([\n1\n,\n2\n])\na\n=\nembedding\n.\nweight\n.\nclone\n()\n@\nW\n.\nt\n()\n# weight must be cloned for this to be differentiable\nb\n=\nembedding\n(\nidx\n)\n@\nW\n.\nt\n()\n# modifies weight in-place\nout\n=\n(\na\n.\nunsqueeze\n(\n0\n)\n+\nb\n.\nunsqueeze\n(\n1\n))\nloss\n=\nout\n.\nsigmoid\n()\n.\nprod\n()\nloss\n.\nbackward\n()\nExamples:\n>>>\n# an Embedding module containing 10 tensors of size 3\n>>>\nembedding\n=\nnn\n.\nEmbedding\n(\n10\n,\n3\n)\n>>>\n# a batch of 2 samples of 4 indices each\n>>>\ninput\n=\ntorch\n.\nLongTensor\n([[\n1\n,\n2\n,\n4\n,\n5\n],\n[\n4\n,\n3\n,\n2\n,\n9\n]])\n>>>\nembedding\n(\ninput\n)\ntensor([[[-0.0251, -1.6902,  0.7172],\n[-0.6431,  0.0748,  0.6969],\n[ 1.4970,  1.3448, -0.9685],\n[-0.3677, -2.7265, -0.1685]],\n[[ 1.4970,  1.3448, -0.9685],\n[ 0.4362, -0.4004,  0.9400],\n[-0.6431,  0.0748,  0.6969],\n[ 0.9124, -2.3616,  1.1151]]])\n>>>\n# example with padding_idx\n>>>\nembedding\n=\nnn\n.\nEmbedding\n(\n10\n,\n3\n,\npadding_idx\n=\n0\n)\n>>>\ninput\n=\ntorch\n.\nLongTensor\n([[\n0\n,\n2\n,\n0\n,\n5\n]])\n>>>\nembedding\n(\ninput\n)\ntensor([[[ 0.0000,  0.0000,  0.0000],\n[ 0.1535, -2.0309,  0.9315],\n[ 0.0000,  0.0000,  0.0000],\n[-0.1655,  0.9897,  0.0635]]])\n>>>\n# example of changing `pad` vector\n>>>\npadding_idx\n=\n0\n>>>\nembedding\n=\nnn\n.\nEmbedding\n(\n3\n,\n3\n,\npadding_idx\n=\npadding_idx\n)\n>>>\nembedding\n.\nweight\nParameter containing:\ntensor([[ 0.0000,  0.0000,  0.0000],\n[-0.7895, -0.7089, -0.0364],\n[ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n>>>\nwith\ntorch\n.\nno_grad\n():\n...\nembedding\n.\nweight\n[\npadding_idx\n]\n=\ntorch\n.\nones\n(\n3\n)\n>>>\nembedding\n.\nweight\nParameter containing:\ntensor([[ 1.0000,  1.0000,  1.0000],\n[-0.7895, -0.7089, -0.0364],\n[ 0.6778,  0.5803,  0.2678]], requires_grad=True)\nclassmethod\nfrom_pretrained\n(\nembeddings\n,\nfreeze\n=\nTrue\n,\npadding_idx\n=\nNone\n,\nmax_norm\n=\nNone\n,\nnorm_type\n=\n2.0\n,\nscale_grad_by_freq\n=\nFalse\n,\nsparse\n=\nFalse\n)\n[source]\n[source]\n¶\nCreate Embedding instance from given 2-dimensional FloatTensor.\nParameters\nembeddings\n(\nTensor\n) – FloatTensor containing weights for the Embedding.\nFirst dimension is being passed to Embedding as\nnum_embeddings\n, second as\nembedding_dim\n.\nfreeze\n(\nbool\n,\noptional\n) – If\nTrue\n, the tensor does not get updated in the learning process.\nEquivalent to\nembedding.weight.requires_grad\n=\nFalse\n. Default:\nTrue\npadding_idx\n(\nint\n,\noptional\n) – If specified, the entries at\npadding_idx\ndo not contribute to the gradient;\ntherefore, the embedding vector at\npadding_idx\nis not updated during training,\ni.e. it remains as a fixed “pad”.\nmax_norm\n(\nfloat\n,\noptional\n) – See module initialization documentation.\nnorm_type\n(\nfloat\n,\noptional\n) – See module initialization documentation. Default\n2\n.\nscale_grad_by_freq\n(\nbool\n,\noptional\n) – See module initialization documentation. Default\nFalse\n.\nsparse\n(\nbool\n,\noptional\n) – See module initialization documentation.\nExamples:\n>>>\n# FloatTensor containing pretrained weights\n>>>\nweight\n=\ntorch\n.\nFloatTensor\n([[\n1\n,\n2.3\n,\n3\n],\n[\n4\n,\n5.1\n,\n6.3\n]])\n>>>\nembedding\n=\nnn\n.\nEmbedding\n.\nfrom_pretrained\n(\nweight\n)\n>>>\n# Get embeddings for index 1\n>>>\ninput\n=\ntorch\n.\nLongTensor\n([\n1\n])\n>>>\nembedding\n(\ninput\n)\ntensor([[ 4.0000,  5.1000,  6.3000]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#embedding",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html#Embedding",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/sparse.py#L15",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html#Embedding.from_pretrained",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/sparse.py#L214",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding.from_pretrained",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.FeatureAlphaDropout.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.EmbeddingBag",
  "page_text": "EmbeddingBag\n¶\nclass\ntorch.nn.\nEmbeddingBag\n(\nnum_embeddings\n,\nembedding_dim\n,\nmax_norm\n=\nNone\n,\nnorm_type\n=\n2.0\n,\nscale_grad_by_freq\n=\nFalse\n,\nmode\n=\n'mean'\n,\nsparse\n=\nFalse\n,\n_weight\n=\nNone\n,\ninclude_last_offset\n=\nFalse\n,\npadding_idx\n=\nNone\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nCompute sums or means of ‘bags’ of embeddings, without instantiating the intermediate embeddings.\nFor bags of constant length, no\nper_sample_weights\n, no indices equal to\npadding_idx\n,\nand with 2D inputs, this class\nwith\nmode=\"sum\"\nis equivalent to\nEmbedding\nfollowed by\ntorch.sum(dim=1)\n,\nwith\nmode=\"mean\"\nis equivalent to\nEmbedding\nfollowed by\ntorch.mean(dim=1)\n,\nwith\nmode=\"max\"\nis equivalent to\nEmbedding\nfollowed by\ntorch.max(dim=1)\n.\nHowever,\nEmbeddingBag\nis much more time and memory efficient than using a chain of these\noperations.\nEmbeddingBag also supports per-sample weights as an argument to the forward\npass. This scales the output of the Embedding before performing a weighted\nreduction as specified by\nmode\n. If\nper_sample_weights\nis passed, the\nonly supported\nmode\nis\n\"sum\"\n, which computes a weighted sum according to\nper_sample_weights\n.\nParameters\nnum_embeddings\n(\nint\n) – size of the dictionary of embeddings\nembedding_dim\n(\nint\n) – the size of each embedding vector\nmax_norm\n(\nfloat\n,\noptional\n) – If given, each embedding vector with norm larger than\nmax_norm\nis renormalized to have norm\nmax_norm\n.\nnorm_type\n(\nfloat\n,\noptional\n) – The p of the p-norm to compute for the\nmax_norm\noption. Default\n2\n.\nscale_grad_by_freq\n(\nbool\n,\noptional\n) – if given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default\nFalse\n.\nNote: this option is not supported when\nmode=\"max\"\n.\nmode\n(\nstr\n,\noptional\n) –\n\"sum\"\n,\n\"mean\"\nor\n\"max\"\n. Specifies the way to reduce the bag.\n\"sum\"\ncomputes the weighted sum, taking\nper_sample_weights\ninto consideration.\n\"mean\"\ncomputes the average of the values\nin the bag,\n\"max\"\ncomputes the max value over each bag.\nDefault:\n\"mean\"\nsparse\n(\nbool\n,\noptional\n) – if\nTrue\n, gradient w.r.t.\nweight\nmatrix will be a sparse tensor. See\nNotes for more details regarding sparse gradients. Note: this option is not\nsupported when\nmode=\"max\"\n.\ninclude_last_offset\n(\nbool\n,\noptional\n) – if\nTrue\n,\noffsets\nhas one additional element, where the last element\nis equivalent to the size of\nindices\n. This matches the CSR format.\npadding_idx\n(\nint\n,\noptional\n) – If specified, the entries at\npadding_idx\ndo not contribute to the\ngradient; therefore, the embedding vector at\npadding_idx\nis not updated\nduring training, i.e. it remains as a fixed “pad”. For a newly constructed\nEmbeddingBag, the embedding vector at\npadding_idx\nwill default to all\nzeros, but can be updated to another value to be used as the padding vector.\nNote that the embedding vector at\npadding_idx\nis excluded from the\nreduction.\nVariables\nweight\n(\nTensor\n) – the learnable weights of the module of shape\n(num_embeddings, embedding_dim)\ninitialized from\nN\n(\n0\n,\n1\n)\n\\mathcal{N}(0, 1)\nN\n(\n0\n,\n1\n)\n.\nExamples:\n>>>\n# an EmbeddingBag module containing 10 tensors of size 3\n>>>\nembedding_sum\n=\nnn\n.\nEmbeddingBag\n(\n10\n,\n3\n,\nmode\n=\n'sum'\n)\n>>>\n# a batch of 2 samples of 4 indices each\n>>>\ninput\n=\ntorch\n.\ntensor\n([\n1\n,\n2\n,\n4\n,\n5\n,\n4\n,\n3\n,\n2\n,\n9\n],\ndtype\n=\ntorch\n.\nlong\n)\n>>>\noffsets\n=\ntorch\n.\ntensor\n([\n0\n,\n4\n],\ndtype\n=\ntorch\n.\nlong\n)\n>>>\nembedding_sum\n(\ninput\n,\noffsets\n)\ntensor([[-0.8861, -5.4350, -0.0523],\n[ 1.1306, -2.5798, -1.0044]])\n>>>\n# Example with padding_idx\n>>>\nembedding_sum\n=\nnn\n.\nEmbeddingBag\n(\n10\n,\n3\n,\nmode\n=\n'sum'\n,\npadding_idx\n=\n2\n)\n>>>\ninput\n=\ntorch\n.\ntensor\n([\n2\n,\n2\n,\n2\n,\n2\n,\n4\n,\n3\n,\n2\n,\n9\n],\ndtype\n=\ntorch\n.\nlong\n)\n>>>\noffsets\n=\ntorch\n.\ntensor\n([\n0\n,\n4\n],\ndtype\n=\ntorch\n.\nlong\n)\n>>>\nembedding_sum\n(\ninput\n,\noffsets\n)\ntensor([[ 0.0000,  0.0000,  0.0000],\n[-0.7082,  3.2145, -2.6251]])\n>>>\n# An EmbeddingBag can be loaded from an Embedding like so\n>>>\nembedding\n=\nnn\n.\nEmbedding\n(\n10\n,\n3\n,\npadding_idx\n=\n2\n)\n>>>\nembedding_sum\n=\nnn\n.\nEmbeddingBag\n.\nfrom_pretrained\n(\nembedding.weight,\npadding_idx=embedding.padding_idx,\nmode='sum')\nforward\n(\ninput\n,\noffsets\n=\nNone\n,\nper_sample_weights\n=\nNone\n)\n[source]\n[source]\n¶\nForward pass of EmbeddingBag.\nParameters\ninput\n(\nTensor\n) – Tensor containing bags of indices into the embedding matrix.\noffsets\n(\nTensor\n,\noptional\n) – Only used when\ninput\nis 1D.\noffsets\ndetermines\nthe starting index position of each bag (sequence) in\ninput\n.\nper_sample_weights\n(\nTensor\n,\noptional\n) – a tensor of float / double weights, or None\nto indicate all weights should be taken to be\n1\n. If specified,\nper_sample_weights\nmust have exactly the same shape as input and is treated as having the same\noffsets\n, if those are not\nNone\n. Only supported for\nmode='sum'\n.\nReturns\nTensor output shape of\n(B, embedding_dim)\n.\nReturn type\nTensor\nNote\nA few notes about\ninput\nand\noffsets\n:\ninput\nand\noffsets\nhave to be of the same type, either int or long\nIf\ninput\nis 2D of shape\n(B, N)\n, it will be treated as\nB\nbags (sequences)\neach of fixed length\nN\n, and this will return\nB\nvalues aggregated in a way\ndepending on the\nmode\n.\noffsets\nis ignored and required to be\nNone\nin this case.\nIf\ninput\nis 1D of shape\n(N)\n, it will be treated as a concatenation of\nmultiple bags (sequences).\noffsets\nis required to be a 1D tensor containing the\nstarting index positions of each bag in\ninput\n. Therefore, for\noffsets\nof shape\n(B)\n,\ninput\nwill be viewed as having\nB\nbags. Empty bags (i.e., having 0-length) will have\nreturned vectors filled by zeros.\nclassmethod\nfrom_pretrained\n(\nembeddings\n,\nfreeze\n=\nTrue\n,\nmax_norm\n=\nNone\n,\nnorm_type\n=\n2.0\n,\nscale_grad_by_freq\n=\nFalse\n,\nmode\n=\n'mean'\n,\nsparse\n=\nFalse\n,\ninclude_last_offset\n=\nFalse\n,\npadding_idx\n=\nNone\n)\n[source]\n[source]\n¶\nCreate EmbeddingBag instance from given 2-dimensional FloatTensor.\nParameters\nembeddings\n(\nTensor\n) – FloatTensor containing weights for the EmbeddingBag.\nFirst dimension is being passed to EmbeddingBag as ‘num_embeddings’, second as ‘embedding_dim’.\nfreeze\n(\nbool\n,\noptional\n) – If\nTrue\n, the tensor does not get updated in the learning process.\nEquivalent to\nembeddingbag.weight.requires_grad\n=\nFalse\n. Default:\nTrue\nmax_norm\n(\nfloat\n,\noptional\n) – See module initialization documentation. Default:\nNone\nnorm_type\n(\nfloat\n,\noptional\n) – See module initialization documentation. Default\n2\n.\nscale_grad_by_freq\n(\nbool\n,\noptional\n) – See module initialization documentation. Default\nFalse\n.\nmode\n(\nstr\n,\noptional\n) – See module initialization documentation. Default:\n\"mean\"\nsparse\n(\nbool\n,\noptional\n) – See module initialization documentation. Default:\nFalse\n.\ninclude_last_offset\n(\nbool\n,\noptional\n) – See module initialization documentation. Default:\nFalse\n.\npadding_idx\n(\nint\n,\noptional\n) – See module initialization documentation. Default:\nNone\n.\nReturn type\nEmbeddingBag\nExamples:\n>>>\n# FloatTensor containing pretrained weights\n>>>\nweight\n=\ntorch\n.\nFloatTensor\n([[\n1\n,\n2.3\n,\n3\n],\n[\n4\n,\n5.1\n,\n6.3\n]])\n>>>\nembeddingbag\n=\nnn\n.\nEmbeddingBag\n.\nfrom_pretrained\n(\nweight\n)\n>>>\n# Get embeddings for index 1\n>>>\ninput\n=\ntorch\n.\nLongTensor\n([[\n1\n,\n0\n]])\n>>>\nembeddingbag\n(\ninput\n)\ntensor([[ 2.5000,  3.7000,  4.6500]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#embeddingbag",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html#EmbeddingBag",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/sparse.py#L269",
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding",
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html#EmbeddingBag.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/sparse.py#L427",
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag.forward",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/sparse.html#EmbeddingBag.from_pretrained",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/sparse.py#L490",
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag.from_pretrained",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag",
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineSimilarity.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.CosineSimilarity",
  "page_text": "CosineSimilarity\n¶\nclass\ntorch.nn.\nCosineSimilarity\n(\ndim\n=\n1\n,\neps\n=\n1e-08\n)\n[source]\n[source]\n¶\nReturns cosine similarity between\nx\n1\nx_1\nx\n1\n​\nand\nx\n2\nx_2\nx\n2\n​\n, computed along\ndim\n.\nsimilarity\n=\nx\n1\n⋅\nx\n2\nmax\n⁡\n(\n∥\nx\n1\n∥\n2\n⋅\n∥\nx\n2\n∥\n2\n,\nϵ\n)\n.\n\\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}.\nsimilarity\n=\nmax\n(\n∥\nx\n1\n​\n∥\n2\n​\n⋅\n∥\nx\n2\n​\n∥\n2\n​\n,\nϵ\n)\nx\n1\n​\n⋅\nx\n2\n​\n​\n.\nParameters\ndim\n(\nint\n,\noptional\n) – Dimension where cosine similarity is computed. Default: 1\neps\n(\nfloat\n,\noptional\n) – Small value to avoid division by zero.\nDefault: 1e-8\nShape:\nInput1:\n(\n∗\n1\n,\nD\n,\n∗\n2\n)\n(\\ast_1, D, \\ast_2)\n(\n∗\n1\n​\n,\nD\n,\n∗\n2\n​\n)\nwhere D is at position\ndim\nInput2:\n(\n∗\n1\n,\nD\n,\n∗\n2\n)\n(\\ast_1, D, \\ast_2)\n(\n∗\n1\n​\n,\nD\n,\n∗\n2\n​\n)\n, same number of dimensions as x1, matching x1 size at dimension\ndim\n,\nand broadcastable with x1 at other dimensions.\nOutput:\n(\n∗\n1\n,\n∗\n2\n)\n(\\ast_1, \\ast_2)\n(\n∗\n1\n​\n,\n∗\n2\n​\n)\nExamples::\n>>>\ninput1\n=\ntorch\n.\nrandn\n(\n100\n,\n128\n)\n>>>\ninput2\n=\ntorch\n.\nrandn\n(\n100\n,\n128\n)\n>>>\ncos\n=\nnn\n.\nCosineSimilarity\n(\ndim\n=\n1\n,\neps\n=\n1e-6\n)\n>>>\noutput\n=\ncos\n(\ninput1\n,\ninput2\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineSimilarity.html#cosinesimilarity",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/distance.html#CosineSimilarity",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/distance.py#L61",
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineSimilarity.html#torch.nn.CosineSimilarity",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.PairwiseDistance.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.PairwiseDistance",
  "page_text": "PairwiseDistance\n¶\nclass\ntorch.nn.\nPairwiseDistance\n(\np\n=\n2.0\n,\neps\n=\n1e-06\n,\nkeepdim\n=\nFalse\n)\n[source]\n[source]\n¶\nComputes the pairwise distance between input vectors, or between columns of input matrices.\nDistances are computed using\np\n-norm, with constant\neps\nadded to avoid division by zero\nif\np\nis negative, i.e.:\nd\ni\ns\nt\n(\nx\n,\ny\n)\n=\n∥\nx\n−\ny\n+\nϵ\ne\n∥\np\n,\n\\mathrm{dist}\\left(x, y\\right) = \\left\\Vert x-y + \\epsilon e \\right\\Vert_p,\ndist\n(\nx\n,\ny\n)\n=\n∥\nx\n−\ny\n+\nϵe\n∥\np\n​\n,\nwhere\ne\ne\ne\nis the vector of ones and the\np\n-norm is given by.\n∥\nx\n∥\np\n=\n(\n∑\ni\n=\n1\nn\n∣\nx\ni\n∣\np\n)\n1\n/\np\n.\n\\Vert x \\Vert _p = \\left( \\sum_{i=1}^n  \\vert x_i \\vert ^ p \\right) ^ {1/p}.\n∥\nx\n∥\np\n​\n=\n(\ni\n=\n1\n∑\nn\n​\n∣\nx\ni\n​\n∣\np\n)\n1/\np\n.\nParameters\np\n(\nreal\n,\noptional\n) – the norm degree. Can be negative. Default: 2\neps\n(\nfloat\n,\noptional\n) – Small value to avoid division by zero.\nDefault: 1e-6\nkeepdim\n(\nbool\n,\noptional\n) – Determines whether or not to keep the vector dimension.\nDefault: False\nShape:\nInput1:\n(\nN\n,\nD\n)\n(N, D)\n(\nN\n,\nD\n)\nor\n(\nD\n)\n(D)\n(\nD\n)\nwhere\nN = batch dimension\nand\nD = vector dimension\nInput2:\n(\nN\n,\nD\n)\n(N, D)\n(\nN\n,\nD\n)\nor\n(\nD\n)\n(D)\n(\nD\n)\n, same shape as the Input1\nOutput:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\nbased on input dimension.\nIf\nkeepdim\nis\nTrue\n, then\n(\nN\n,\n1\n)\n(N, 1)\n(\nN\n,\n1\n)\nor\n(\n1\n)\n(1)\n(\n1\n)\nbased on input dimension.\nExamples::\n>>>\npdist\n=\nnn\n.\nPairwiseDistance\n(\np\n=\n2\n)\n>>>\ninput1\n=\ntorch\n.\nrandn\n(\n100\n,\n128\n)\n>>>\ninput2\n=\ntorch\n.\nrandn\n(\n100\n,\n128\n)\n>>>\noutput\n=\npdist\n(\ninput1\n,\ninput2\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.PairwiseDistance.html#pairwisedistance",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/distance.html#PairwiseDistance",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/distance.py#L10",
    "https://pytorch.org/docs/stable/generated/torch.nn.PairwiseDistance.html#torch.nn.PairwiseDistance",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineSimilarity.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.L1Loss",
  "page_text": "L1Loss\n¶\nclass\ntorch.nn.\nL1Loss\n(\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that measures the mean absolute error (MAE) between each element in\nthe input\nx\nx\nx\nand target\ny\ny\ny\n.\nThe unreduced (i.e. with\nreduction\nset to\n'none'\n) loss can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\n,\nl\nn\n=\n∣\nx\nn\n−\ny\nn\n∣\n,\n\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\nl_n = \\left| x_n - y_n \\right|,\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n,\nl\nn\n​\n=\n∣\nx\nn\n​\n−\ny\nn\n​\n∣\n,\nwhere\nN\nN\nN\nis the batch size. If\nreduction\nis not\n'none'\n(default\n'mean'\n), then:\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘mean’;\nsum\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) =\n\\begin{cases}\n    \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n    \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n(\nL\n)\n,\nsum\n(\nL\n)\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nx\nx\nx\nand\ny\ny\ny\nare tensors of arbitrary shapes with a total\nof\nN\nN\nN\nelements each.\nThe sum operation still operates over all the elements, and divides by\nN\nN\nN\n.\nThe division by\nN\nN\nN\ncan be avoided if one sets\nreduction\n=\n'sum'\n.\nSupports real-valued and complex-valued inputs.\nParameters\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nOutput: scalar. If\nreduction\nis\n'none'\n, then\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nloss\n=\nnn\n.\nL1Loss\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n)\n>>>\noutput\n=\nloss\n(\ninput\n,\ntarget\n)\n>>>\noutput\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#l1loss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#L1Loss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L62",
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.PairwiseDistance.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MSELoss",
  "page_text": "MSELoss\n¶\nclass\ntorch.nn.\nMSELoss\n(\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that measures the mean squared error (squared L2 norm) between\neach element in the input\nx\nx\nx\nand target\ny\ny\ny\n.\nThe unreduced (i.e. with\nreduction\nset to\n'none'\n) loss can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\n,\nl\nn\n=\n(\nx\nn\n−\ny\nn\n)\n2\n,\n\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\nl_n = \\left( x_n - y_n \\right)^2,\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n,\nl\nn\n​\n=\n(\nx\nn\n​\n−\ny\nn\n​\n)\n2\n,\nwhere\nN\nN\nN\nis the batch size. If\nreduction\nis not\n'none'\n(default\n'mean'\n), then:\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘mean’;\nsum\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) =\n\\begin{cases}\n    \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n    \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n(\nL\n)\n,\nsum\n(\nL\n)\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nx\nx\nx\nand\ny\ny\ny\nare tensors of arbitrary shapes with a total\nof\nN\nN\nN\nelements each.\nThe mean operation still operates over all the elements, and divides by\nN\nN\nN\n.\nThe division by\nN\nN\nN\ncan be avoided if one sets\nreduction\n=\n'sum'\n.\nParameters\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nExamples:\n>>>\nloss\n=\nnn\n.\nMSELoss\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n)\n>>>\noutput\n=\nloss\n(\ninput\n,\ntarget\n)\n>>>\noutput\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#mseloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#MSELoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L548",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.CrossEntropyLoss",
  "page_text": "CrossEntropyLoss\n¶\nclass\ntorch.nn.\nCrossEntropyLoss\n(\nweight\n=\nNone\n,\nsize_average\n=\nNone\n,\nignore_index\n=\n-100\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n,\nlabel_smoothing\n=\n0.0\n)\n[source]\n[source]\n¶\nThis criterion computes the cross entropy loss between input logits\nand target.\nIt is useful when training a classification problem with\nC\nclasses.\nIf provided, the optional argument\nweight\nshould be a 1D\nTensor\nassigning weight to each of the classes.\nThis is particularly useful when you have an unbalanced training set.\nThe\ninput\nis expected to contain the unnormalized logits for each class (which do\nnot\nneed\nto be positive or sum to 1, in general).\ninput\nhas to be a Tensor of size\n(\nC\n)\n(C)\n(\nC\n)\nfor unbatched input,\n(\nm\ni\nn\ni\nb\na\nt\nc\nh\n,\nC\n)\n(minibatch, C)\n(\nminiba\nt\nc\nh\n,\nC\n)\nor\n(\nm\ni\nn\ni\nb\na\nt\nc\nh\n,\nC\n,\nd\n1\n,\nd\n2\n,\n.\n.\n.\n,\nd\nK\n)\n(minibatch, C, d_1, d_2, ..., d_K)\n(\nminiba\nt\nc\nh\n,\nC\n,\nd\n1\n​\n,\nd\n2\n​\n,\n...\n,\nd\nK\n​\n)\nwith\nK\n≥\n1\nK \\geq 1\nK\n≥\n1\nfor the\nK\n-dimensional case. The last being useful for higher dimension inputs, such\nas computing cross entropy loss per-pixel for 2D images.\nThe\ntarget\nthat this criterion expects should contain either:\nClass indices in the range\n[\n0\n,\nC\n)\n[0, C)\n[\n0\n,\nC\n)\nwhere\nC\nC\nC\nis the number of classes; if\nignore_index\nis specified, this loss also accepts this class index (this index\nmay not necessarily be in the class range). The unreduced (i.e. with\nreduction\nset to\n'none'\n) loss for this case can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\n,\nl\nn\n=\n−\nw\ny\nn\nlog\n⁡\nexp\n⁡\n(\nx\nn\n,\ny\nn\n)\n∑\nc\n=\n1\nC\nexp\n⁡\n(\nx\nn\n,\nc\n)\n⋅\n1\n{\ny\nn\n≠\nignore_index\n}\n\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\nl_n = - w_{y_n} \\log \\frac{\\exp(x_{n,y_n})}{\\sum_{c=1}^C \\exp(x_{n,c})}\n\\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n,\nl\nn\n​\n=\n−\nw\ny\nn\n​\n​\nlo\ng\n∑\nc\n=\n1\nC\n​\nexp\n(\nx\nn\n,\nc\n​\n)\nexp\n(\nx\nn\n,\ny\nn\n​\n​\n)\n​\n⋅\n1\n{\ny\nn\n​\n\n=\nignore_index\n}\nwhere\nx\nx\nx\nis the input,\ny\ny\ny\nis the target,\nw\nw\nw\nis the weight,\nC\nC\nC\nis the number of classes, and\nN\nN\nN\nspans the minibatch dimension as well as\nd\n1\n,\n.\n.\n.\n,\nd\nk\nd_1, ..., d_k\nd\n1\n​\n,\n...\n,\nd\nk\n​\nfor the\nK\n-dimensional case. If\nreduction\nis not\n'none'\n(default\n'mean'\n), then\nℓ\n(\nx\n,\ny\n)\n=\n{\n∑\nn\n=\n1\nN\n1\n∑\nn\n=\n1\nN\nw\ny\nn\n⋅\n1\n{\ny\nn\n≠\nignore_index\n}\nl\nn\n,\nif reduction\n=\n‘mean’;\n∑\nn\n=\n1\nN\nl\nn\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) = \\begin{cases}\n    \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n} \\cdot \\mathbb{1}\\{y_n \\not= \\text{ignore\\_index}\\}} l_n, &\n     \\text{if reduction} = \\text{`mean';}\\\\\n      \\sum_{n=1}^N l_n,  &\n      \\text{if reduction} = \\text{`sum'.}\n  \\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\n∑\nn\n=\n1\nN\n​\n∑\nn\n=\n1\nN\n​\nw\ny\nn\n​\n​\n⋅\n1\n{\ny\nn\n​\n\n=\nignore_index\n}\n1\n​\nl\nn\n​\n,\n∑\nn\n=\n1\nN\n​\nl\nn\n​\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nNote that this case is equivalent to applying\nLogSoftmax\non an input, followed by\nNLLLoss\n.\nProbabilities for each class; useful when labels beyond a single class per minibatch item\nare required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with\nreduction\nset to\n'none'\n) loss for this case can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\n,\nl\nn\n=\n−\n∑\nc\n=\n1\nC\nw\nc\nlog\n⁡\nexp\n⁡\n(\nx\nn\n,\nc\n)\n∑\ni\n=\n1\nC\nexp\n⁡\n(\nx\nn\n,\ni\n)\ny\nn\n,\nc\n\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\nl_n = - \\sum_{c=1}^C w_c \\log \\frac{\\exp(x_{n,c})}{\\sum_{i=1}^C \\exp(x_{n,i})} y_{n,c}\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n,\nl\nn\n​\n=\n−\nc\n=\n1\n∑\nC\n​\nw\nc\n​\nlo\ng\n∑\ni\n=\n1\nC\n​\nexp\n(\nx\nn\n,\ni\n​\n)\nexp\n(\nx\nn\n,\nc\n​\n)\n​\ny\nn\n,\nc\n​\nwhere\nx\nx\nx\nis the input,\ny\ny\ny\nis the target,\nw\nw\nw\nis the weight,\nC\nC\nC\nis the number of classes, and\nN\nN\nN\nspans the minibatch dimension as well as\nd\n1\n,\n.\n.\n.\n,\nd\nk\nd_1, ..., d_k\nd\n1\n​\n,\n...\n,\nd\nk\n​\nfor the\nK\n-dimensional case. If\nreduction\nis not\n'none'\n(default\n'mean'\n), then\nℓ\n(\nx\n,\ny\n)\n=\n{\n∑\nn\n=\n1\nN\nl\nn\nN\n,\nif reduction\n=\n‘mean’;\n∑\nn\n=\n1\nN\nl\nn\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) = \\begin{cases}\n    \\frac{\\sum_{n=1}^N l_n}{N}, &\n     \\text{if reduction} = \\text{`mean';}\\\\\n      \\sum_{n=1}^N l_n,  &\n      \\text{if reduction} = \\text{`sum'.}\n  \\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nN\n∑\nn\n=\n1\nN\n​\nl\nn\n​\n​\n,\n∑\nn\n=\n1\nN\n​\nl\nn\n​\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nNote\nThe performance of this criterion is generally better when\ntarget\ncontains class\nindices, as this allows for optimized computation. Consider providing\ntarget\nas\nclass probabilities only when a single class label per minibatch item is too restrictive.\nParameters\nweight\n(\nTensor\n,\noptional\n) – a manual rescaling weight given to each class.\nIf given, has to be a Tensor of size\nC\nand floating point dtype\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nignore_index\n(\nint\n,\noptional\n) – Specifies a target value that is ignored\nand does not contribute to the input gradient. When\nsize_average\nis\nTrue\n, the loss is averaged over non-ignored targets. Note that\nignore_index\nis only applicable when the target contains class indices.\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will\nbe applied,\n'mean'\n: the weighted mean of the output is taken,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in\nthe meantime, specifying either of those two args will override\nreduction\n. Default:\n'mean'\nlabel_smoothing\n(\nfloat\n,\noptional\n) – A float in [0.0, 1.0]. Specifies the amount\nof smoothing when computing the loss, where 0.0 means no smoothing. The targets\nbecome a mixture of the original ground truth and a uniform distribution as described in\nRethinking the Inception Architecture for Computer Vision\n. Default:\n0.0\n0.0\n0.0\n.\nShape:\nInput: Shape\n(\nC\n)\n(C)\n(\nC\n)\n,\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\nor\n(\nN\n,\nC\n,\nd\n1\n,\nd\n2\n,\n.\n.\n.\n,\nd\nK\n)\n(N, C, d_1, d_2, ..., d_K)\n(\nN\n,\nC\n,\nd\n1\n​\n,\nd\n2\n​\n,\n...\n,\nd\nK\n​\n)\nwith\nK\n≥\n1\nK \\geq 1\nK\n≥\n1\nin the case of\nK\n-dimensional loss.\nTarget: If containing class indices, shape\n(\n)\n()\n(\n)\n,\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\nN\n,\nd\n1\n,\nd\n2\n,\n.\n.\n.\n,\nd\nK\n)\n(N, d_1, d_2, ..., d_K)\n(\nN\n,\nd\n1\n​\n,\nd\n2\n​\n,\n...\n,\nd\nK\n​\n)\nwith\nK\n≥\n1\nK \\geq 1\nK\n≥\n1\nin the case of K-dimensional loss where each value should be between\n[\n0\n,\nC\n)\n[0, C)\n[\n0\n,\nC\n)\n.\nIf containing class probabilities, same shape as the input and each value should be between\n[\n0\n,\n1\n]\n[0, 1]\n[\n0\n,\n1\n]\n.\nOutput: If reduction is ‘none’, shape\n(\n)\n()\n(\n)\n,\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\nN\n,\nd\n1\n,\nd\n2\n,\n.\n.\n.\n,\nd\nK\n)\n(N, d_1, d_2, ..., d_K)\n(\nN\n,\nd\n1\n​\n,\nd\n2\n​\n,\n...\n,\nd\nK\n​\n)\nwith\nK\n≥\n1\nK \\geq 1\nK\n≥\n1\nin the case of K-dimensional loss, depending on the shape of the input. Otherwise, scalar.\nwhere:\nC\n=\nnumber of classes\nN\n=\nbatch size\n\\begin{aligned}\n    C ={} & \\text{number of classes} \\\\\n    N ={} & \\text{batch size} \\\\\n\\end{aligned}\nC\n=\nN\n=\n​\nnumber of classes\nbatch size\n​\nExamples:\n>>>\n# Example of target with class indices\n>>>\nloss\n=\nnn\n.\nCrossEntropyLoss\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nempty\n(\n3\n,\ndtype\n=\ntorch\n.\nlong\n)\n.\nrandom_\n(\n5\n)\n>>>\noutput\n=\nloss\n(\ninput\n,\ntarget\n)\n>>>\noutput\n.\nbackward\n()\n>>>\n>>>\n# Example of target with class probabilities\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n)\n.\nsoftmax\n(\ndim\n=\n1\n)\n>>>\noutput\n=\nloss\n(\ninput\n,\ntarget\n)\n>>>\noutput\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#crossentropyloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#CrossEntropyLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1146",
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax",
    "https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#float",
    "https://arxiv.org/abs/1512.00567",
    "https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.CTCLoss",
  "page_text": "CTCLoss\n¶\nclass\ntorch.nn.\nCTCLoss\n(\nblank\n=\n0\n,\nreduction\n=\n'mean'\n,\nzero_infinity\n=\nFalse\n)\n[source]\n[source]\n¶\nThe Connectionist Temporal Classification loss.\nCalculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the\nprobability of possible alignments of input to target, producing a loss value which is differentiable\nwith respect to each input node. The alignment of input to target is assumed to be “many-to-one”, which\nlimits the length of the target sequence such that it must be\n≤\n\\leq\n≤\nthe input length.\nParameters\nblank\n(\nint\n,\noptional\n) – blank label. Default\n0\n0\n0\n.\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the output losses will be divided by the target lengths and\nthen the mean over the batch is taken,\n'sum'\n: the output losses will be summed.\nDefault:\n'mean'\nzero_infinity\n(\nbool\n,\noptional\n) – Whether to zero infinite losses and the associated gradients.\nDefault:\nFalse\nInfinite losses mainly occur when the inputs are too short\nto be aligned to the targets.\nShape:\nLog_probs: Tensor of size\n(\nT\n,\nN\n,\nC\n)\n(T, N, C)\n(\nT\n,\nN\n,\nC\n)\nor\n(\nT\n,\nC\n)\n(T, C)\n(\nT\n,\nC\n)\n,\nwhere\nT\n=\ninput length\nT = \\text{input length}\nT\n=\ninput length\n,\nN\n=\nbatch size\nN = \\text{batch size}\nN\n=\nbatch size\n, and\nC\n=\nnumber of classes (including blank)\nC = \\text{number of classes (including blank)}\nC\n=\nnumber of classes (including blank)\n.\nThe logarithmized probabilities of the outputs (e.g. obtained with\ntorch.nn.functional.log_softmax()\n).\nTargets: Tensor of size\n(\nN\n,\nS\n)\n(N, S)\n(\nN\n,\nS\n)\nor\n(\nsum\n⁡\n(\ntarget_lengths\n)\n)\n(\\operatorname{sum}(\\text{target\\_lengths}))\n(\nsum\n(\ntarget_lengths\n))\n,\nwhere\nN\n=\nbatch size\nN = \\text{batch size}\nN\n=\nbatch size\nand\nS\n=\nmax target length, if shape is\n(\nN\n,\nS\n)\nS = \\text{max target length, if shape is } (N, S)\nS\n=\nmax target length, if shape is\n(\nN\n,\nS\n)\n.\nIt represents the target sequences. Each element in the target\nsequence is a class index. And the target index cannot be blank (default=0).\nIn the\n(\nN\n,\nS\n)\n(N, S)\n(\nN\n,\nS\n)\nform, targets are padded to the\nlength of the longest sequence, and stacked.\nIn the\n(\nsum\n⁡\n(\ntarget_lengths\n)\n)\n(\\operatorname{sum}(\\text{target\\_lengths}))\n(\nsum\n(\ntarget_lengths\n))\nform,\nthe targets are assumed to be un-padded and\nconcatenated within 1 dimension.\nInput_lengths: Tuple or tensor of size\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\n,\nwhere\nN\n=\nbatch size\nN = \\text{batch size}\nN\n=\nbatch size\n. It represents the lengths of the\ninputs (must each be\n≤\nT\n\\leq T\n≤\nT\n). And the lengths are specified\nfor each sequence to achieve masking under the assumption that sequences\nare padded to equal lengths.\nTarget_lengths: Tuple or tensor of size\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\n,\nwhere\nN\n=\nbatch size\nN = \\text{batch size}\nN\n=\nbatch size\n. It represents lengths of the targets.\nLengths are specified for each sequence to achieve masking under the\nassumption that sequences are padded to equal lengths. If target shape is\n(\nN\n,\nS\n)\n(N,S)\n(\nN\n,\nS\n)\n, target_lengths are effectively the stop index\ns\nn\ns_n\ns\nn\n​\nfor each target sequence, such that\ntarget_n\n=\ntargets[n,0:s_n]\nfor\neach target in a batch. Lengths must each be\n≤\nS\n\\leq S\n≤\nS\nIf the targets are given as a 1d tensor that is the concatenation of individual\ntargets, the target_lengths must add up to the total length of the tensor.\nOutput: scalar if\nreduction\nis\n'mean'\n(default) or\n'sum'\n. If\nreduction\nis\n'none'\n, then\n(\nN\n)\n(N)\n(\nN\n)\nif input is batched or\n(\n)\n()\n(\n)\nif input is unbatched, where\nN\n=\nbatch size\nN = \\text{batch size}\nN\n=\nbatch size\n.\nExamples:\n>>>\n# Target are to be padded\n>>>\nT\n=\n50\n# Input sequence length\n>>>\nC\n=\n20\n# Number of classes (including blank)\n>>>\nN\n=\n16\n# Batch size\n>>>\nS\n=\n30\n# Target sequence length of longest target in batch (padding length)\n>>>\nS_min\n=\n10\n# Minimum target length, for demonstration purposes\n>>>\n>>>\n# Initialize random batch of input vectors, for *size = (T,N,C)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\nT\n,\nN\n,\nC\n)\n.\nlog_softmax\n(\n2\n)\n.\ndetach\n()\n.\nrequires_grad_\n()\n>>>\n>>>\n# Initialize random batch of targets (0 = blank, 1:C = classes)\n>>>\ntarget\n=\ntorch\n.\nrandint\n(\nlow\n=\n1\n,\nhigh\n=\nC\n,\nsize\n=\n(\nN\n,\nS\n),\ndtype\n=\ntorch\n.\nlong\n)\n>>>\n>>>\ninput_lengths\n=\ntorch\n.\nfull\n(\nsize\n=\n(\nN\n,),\nfill_value\n=\nT\n,\ndtype\n=\ntorch\n.\nlong\n)\n>>>\ntarget_lengths\n=\ntorch\n.\nrandint\n(\nlow\n=\nS_min\n,\nhigh\n=\nS\n,\nsize\n=\n(\nN\n,),\ndtype\n=\ntorch\n.\nlong\n)\n>>>\nctc_loss\n=\nnn\n.\nCTCLoss\n()\n>>>\nloss\n=\nctc_loss\n(\ninput\n,\ntarget\n,\ninput_lengths\n,\ntarget_lengths\n)\n>>>\nloss\n.\nbackward\n()\n>>>\n>>>\n>>>\n# Target are to be un-padded\n>>>\nT\n=\n50\n# Input sequence length\n>>>\nC\n=\n20\n# Number of classes (including blank)\n>>>\nN\n=\n16\n# Batch size\n>>>\n>>>\n# Initialize random batch of input vectors, for *size = (T,N,C)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\nT\n,\nN\n,\nC\n)\n.\nlog_softmax\n(\n2\n)\n.\ndetach\n()\n.\nrequires_grad_\n()\n>>>\ninput_lengths\n=\ntorch\n.\nfull\n(\nsize\n=\n(\nN\n,),\nfill_value\n=\nT\n,\ndtype\n=\ntorch\n.\nlong\n)\n>>>\n>>>\n# Initialize random batch of targets (0 = blank, 1:C = classes)\n>>>\ntarget_lengths\n=\ntorch\n.\nrandint\n(\nlow\n=\n1\n,\nhigh\n=\nT\n,\nsize\n=\n(\nN\n,),\ndtype\n=\ntorch\n.\nlong\n)\n>>>\ntarget\n=\ntorch\n.\nrandint\n(\nlow\n=\n1\n,\nhigh\n=\nC\n,\nsize\n=\n(\nsum\n(\ntarget_lengths\n),),\ndtype\n=\ntorch\n.\nlong\n)\n>>>\nctc_loss\n=\nnn\n.\nCTCLoss\n()\n>>>\nloss\n=\nctc_loss\n(\ninput\n,\ntarget\n,\ninput_lengths\n,\ntarget_lengths\n)\n>>>\nloss\n.\nbackward\n()\n>>>\n>>>\n>>>\n# Target are to be un-padded and unbatched (effectively N=1)\n>>>\nT\n=\n50\n# Input sequence length\n>>>\nC\n=\n20\n# Number of classes (including blank)\n>>>\n>>>\n# Initialize random batch of input vectors, for *size = (T,C)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\nT\n,\nC\n)\n.\nlog_softmax\n(\n1\n)\n.\ndetach\n()\n.\nrequires_grad_\n()\n>>>\ninput_lengths\n=\ntorch\n.\ntensor\n(\nT\n,\ndtype\n=\ntorch\n.\nlong\n)\n>>>\n>>>\n# Initialize random batch of targets (0 = blank, 1:C = classes)\n>>>\ntarget_lengths\n=\ntorch\n.\nrandint\n(\nlow\n=\n1\n,\nhigh\n=\nT\n,\nsize\n=\n(),\ndtype\n=\ntorch\n.\nlong\n)\n>>>\ntarget\n=\ntorch\n.\nrandint\n(\nlow\n=\n1\n,\nhigh\n=\nC\n,\nsize\n=\n(\ntarget_lengths\n,),\ndtype\n=\ntorch\n.\nlong\n)\n>>>\nctc_loss\n=\nnn\n.\nCTCLoss\n()\n>>>\nloss\n=\nctc_loss\n(\ninput\n,\ntarget\n,\ninput_lengths\n,\ntarget_lengths\n)\n>>>\nloss\n.\nbackward\n()\nReference:\nA. Graves et al.: Connectionist Temporal Classification:\nLabelling Unsegmented Sequence Data with Recurrent Neural Networks:\nhttps://www.cs.toronto.edu/~graves/icml_2006.pdf\nNote\nIn order to use CuDNN, the following must be satisfied:\ntargets\nmust be\nin concatenated format, all\ninput_lengths\nmust be\nT\n.\nb\nl\na\nn\nk\n=\n0\nblank=0\nb\nl\nank\n=\n0\n,\ntarget_lengths\n≤\n256\n\\leq 256\n≤\n256\n, the integer arguments must be of\ndtype\ntorch.int32\n.\nThe regular implementation uses the (more common in PyTorch)\ntorch.long\ndtype.\nNote\nIn some circumstances when using the CUDA backend with CuDNN, this operator\nmay select a nondeterministic algorithm to increase performance. If this is\nundesirable, you can try to make the operation deterministic (potentially at\na performance cost) by setting\ntorch.backends.cudnn.deterministic\n=\nTrue\n.\nPlease see the notes on\nReproducibility\nfor background.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html#ctcloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#CTCLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1830",
    "https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html#torch.nn.CTCLoss",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax",
    "https://www.cs.toronto.edu/~graves/icml_2006.pdf",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.NLLLoss",
  "page_text": "NLLLoss\n¶\nclass\ntorch.nn.\nNLLLoss\n(\nweight\n=\nNone\n,\nsize_average\n=\nNone\n,\nignore_index\n=\n-100\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nThe negative log likelihood loss. It is useful to train a classification\nproblem with\nC\nclasses.\nIf provided, the optional argument\nweight\nshould be a 1D Tensor assigning\nweight to each of the classes. This is particularly useful when you have an\nunbalanced training set.\nThe\ninput\ngiven through a forward call is expected to contain\nlog-probabilities of each class.\ninput\nhas to be a Tensor of size either\n(\nm\ni\nn\ni\nb\na\nt\nc\nh\n,\nC\n)\n(minibatch, C)\n(\nminiba\nt\nc\nh\n,\nC\n)\nor\n(\nm\ni\nn\ni\nb\na\nt\nc\nh\n,\nC\n,\nd\n1\n,\nd\n2\n,\n.\n.\n.\n,\nd\nK\n)\n(minibatch, C, d_1, d_2, ..., d_K)\n(\nminiba\nt\nc\nh\n,\nC\n,\nd\n1\n​\n,\nd\n2\n​\n,\n...\n,\nd\nK\n​\n)\nwith\nK\n≥\n1\nK \\geq 1\nK\n≥\n1\nfor the\nK\n-dimensional case. The latter is useful for\nhigher dimension inputs, such as computing NLL loss per-pixel for 2D images.\nObtaining log-probabilities in a neural network is easily achieved by\nadding a\nLogSoftmax\nlayer in the last layer of your network.\nYou may use\nCrossEntropyLoss\ninstead, if you prefer not to add an extra\nlayer.\nThe\ntarget\nthat this loss expects should be a class index in the range\n[\n0\n,\nC\n−\n1\n]\n[0, C-1]\n[\n0\n,\nC\n−\n1\n]\nwhere\nC = number of classes\n; if\nignore_index\nis specified, this loss also accepts\nthis class index (this index may not necessarily be in the class range).\nThe unreduced (i.e. with\nreduction\nset to\n'none'\n) loss can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\n,\nl\nn\n=\n−\nw\ny\nn\nx\nn\n,\ny\nn\n,\nw\nc\n=\nweight\n[\nc\n]\n⋅\n1\n{\nc\n≠\nignore_index\n}\n,\n\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\nl_n = - w_{y_n} x_{n,y_n}, \\quad\nw_{c} = \\text{weight}[c] \\cdot \\mathbb{1}\\{c \\not= \\text{ignore\\_index}\\},\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n,\nl\nn\n​\n=\n−\nw\ny\nn\n​\n​\nx\nn\n,\ny\nn\n​\n​\n,\nw\nc\n​\n=\nweight\n[\nc\n]\n⋅\n1\n{\nc\n\n=\nignore_index\n}\n,\nwhere\nx\nx\nx\nis the input,\ny\ny\ny\nis the target,\nw\nw\nw\nis the weight, and\nN\nN\nN\nis the batch size. If\nreduction\nis not\n'none'\n(default\n'mean'\n), then\nℓ\n(\nx\n,\ny\n)\n=\n{\n∑\nn\n=\n1\nN\n1\n∑\nn\n=\n1\nN\nw\ny\nn\nl\nn\n,\nif reduction\n=\n‘mean’;\n∑\nn\n=\n1\nN\nl\nn\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) = \\begin{cases}\n    \\sum_{n=1}^N \\frac{1}{\\sum_{n=1}^N w_{y_n}} l_n, &\n    \\text{if reduction} = \\text{`mean';}\\\\\n    \\sum_{n=1}^N l_n,  &\n    \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\n∑\nn\n=\n1\nN\n​\n∑\nn\n=\n1\nN\n​\nw\ny\nn\n​\n​\n1\n​\nl\nn\n​\n,\n∑\nn\n=\n1\nN\n​\nl\nn\n​\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nParameters\nweight\n(\nTensor\n,\noptional\n) – a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size\nC\n. Otherwise, it is\ntreated as if having all ones.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nNone\nignore_index\n(\nint\n,\noptional\n) – Specifies a target value that is ignored\nand does not contribute to the input gradient. When\nsize_average\nis\nTrue\n, the loss is averaged over\nnon-ignored targets.\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nNone\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will\nbe applied,\n'mean'\n: the weighted mean of the output is taken,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in\nthe meantime, specifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape::\nInput:\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\nor\n(\nC\n)\n(C)\n(\nC\n)\n, where\nC = number of classes\n,\nN = batch size\n, or\n(\nN\n,\nC\n,\nd\n1\n,\nd\n2\n,\n.\n.\n.\n,\nd\nK\n)\n(N, C, d_1, d_2, ..., d_K)\n(\nN\n,\nC\n,\nd\n1\n​\n,\nd\n2\n​\n,\n...\n,\nd\nK\n​\n)\nwith\nK\n≥\n1\nK \\geq 1\nK\n≥\n1\nin the case of\nK\n-dimensional loss.\nTarget:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\n, where each value is\n0\n≤\ntargets\n[\ni\n]\n≤\nC\n−\n1\n0 \\leq \\text{targets}[i] \\leq C-1\n0\n≤\ntargets\n[\ni\n]\n≤\nC\n−\n1\n, or\n(\nN\n,\nd\n1\n,\nd\n2\n,\n.\n.\n.\n,\nd\nK\n)\n(N, d_1, d_2, ..., d_K)\n(\nN\n,\nd\n1\n​\n,\nd\n2\n​\n,\n...\n,\nd\nK\n​\n)\nwith\nK\n≥\n1\nK \\geq 1\nK\n≥\n1\nin the case of\nK-dimensional loss.\nOutput: If\nreduction\nis\n'none'\n, shape\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\nN\n,\nd\n1\n,\nd\n2\n,\n.\n.\n.\n,\nd\nK\n)\n(N, d_1, d_2, ..., d_K)\n(\nN\n,\nd\n1\n​\n,\nd\n2\n​\n,\n...\n,\nd\nK\n​\n)\nwith\nK\n≥\n1\nK \\geq 1\nK\n≥\n1\nin the case of K-dimensional loss.\nOtherwise, scalar.\nExamples:\n>>>\nlog_softmax\n=\nnn\n.\nLogSoftmax\n(\ndim\n=\n1\n)\n>>>\nloss_fn\n=\nnn\n.\nNLLLoss\n()\n>>>\n# input to NLLLoss is of size N x C = 3 x 5\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n,\nrequires_grad\n=\nTrue\n)\n>>>\n# each element in target must have 0 <= value < C\n>>>\ntarget\n=\ntorch\n.\ntensor\n([\n1\n,\n0\n,\n4\n])\n>>>\nloss\n=\nloss_fn\n(\nlog_softmax\n(\ninput\n),\ntarget\n)\n>>>\nloss\n.\nbackward\n()\n>>>\n>>>\n>>>\n# 2D loss example (used, for example, with image inputs)\n>>>\nN\n,\nC\n=\n5\n,\n4\n>>>\nloss_fn\n=\nnn\n.\nNLLLoss\n()\n>>>\ndata\n=\ntorch\n.\nrandn\n(\nN\n,\n16\n,\n10\n,\n10\n)\n>>>\nconv\n=\nnn\n.\nConv2d\n(\n16\n,\nC\n,\n(\n3\n,\n3\n))\n>>>\nlog_softmax\n=\nnn\n.\nLogSoftmax\n(\ndim\n=\n1\n)\n>>>\n# output of conv forward is of shape [N, C, 8, 8]\n>>>\noutput\n=\nlog_softmax\n(\nconv\n(\ndata\n))\n>>>\n# each element in target must have 0 <= value < C\n>>>\ntarget\n=\ntorch\n.\nempty\n(\nN\n,\n8\n,\n8\n,\ndtype\n=\ntorch\n.\nlong\n)\n.\nrandom_\n(\n0\n,\nC\n)\n>>>\n# input to NLLLoss is of size N x C x height (8) x width (8)\n>>>\nloss\n=\nloss_fn\n(\noutput\n,\ntarget\n)\n>>>\nloss\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#nllloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#NLLLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L131",
    "https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.PoissonNLLLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.PoissonNLLLoss",
  "page_text": "PoissonNLLLoss\n¶\nclass\ntorch.nn.\nPoissonNLLLoss\n(\nlog_input\n=\nTrue\n,\nfull\n=\nFalse\n,\nsize_average\n=\nNone\n,\neps\n=\n1e-08\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nNegative log likelihood loss with Poisson distribution of target.\nThe loss can be described as:\ntarget\n∼\nP\no\ni\ns\ns\no\nn\n(\ninput\n)\nloss\n(\ninput\n,\ntarget\n)\n=\ninput\n−\ntarget\n∗\nlog\n⁡\n(\ninput\n)\n+\nlog\n⁡\n(\ntarget!\n)\n\\text{target} \\sim \\mathrm{Poisson}(\\text{input})\n\n\\text{loss}(\\text{input}, \\text{target}) = \\text{input} - \\text{target} * \\log(\\text{input})\n                            + \\log(\\text{target!})\ntarget\n∼\nPoisson\n(\ninput\n)\nloss\n(\ninput\n,\ntarget\n)\n=\ninput\n−\ntarget\n∗\nlo\ng\n(\ninput\n)\n+\nlo\ng\n(\ntarget!\n)\nThe last term can be omitted or approximated with Stirling formula. The\napproximation is used for target values more than 1. For targets less or\nequal to 1 zeros are added to the loss.\nParameters\nlog_input\n(\nbool\n,\noptional\n) – if\nTrue\nthe loss is computed as\nexp\n⁡\n(\ninput\n)\n−\ntarget\n∗\ninput\n\\exp(\\text{input}) - \\text{target}*\\text{input}\nexp\n(\ninput\n)\n−\ntarget\n∗\ninput\n, if\nFalse\nthe loss is\ninput\n−\ntarget\n∗\nlog\n⁡\n(\ninput\n+\neps\n)\n\\text{input} - \\text{target}*\\log(\\text{input}+\\text{eps})\ninput\n−\ntarget\n∗\nlo\ng\n(\ninput\n+\neps\n)\n.\nfull\n(\nbool\n,\noptional\n) –\nwhether to compute full loss, i. e. to add the\nStirling approximation term\ntarget\n∗\nlog\n⁡\n(\ntarget\n)\n−\ntarget\n+\n0.5\n∗\nlog\n⁡\n(\n2\nπ\ntarget\n)\n.\n\\text{target}*\\log(\\text{target}) - \\text{target} + 0.5 * \\log(2\\pi\\text{target}).\ntarget\n∗\nlo\ng\n(\ntarget\n)\n−\ntarget\n+\n0.5\n∗\nlo\ng\n(\n2\nπ\ntarget\n)\n.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\neps\n(\nfloat\n,\noptional\n) – Small value to avoid evaluation of\nlog\n⁡\n(\n0\n)\n\\log(0)\nlo\ng\n(\n0\n)\nwhen\nlog_input\n=\nFalse\n. Default: 1e-8\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nExamples:\n>>>\nloss\n=\nnn\n.\nPoissonNLLLoss\n()\n>>>\nlog_input\n=\ntorch\n.\nrandn\n(\n5\n,\n2\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nrandn\n(\n5\n,\n2\n)\n>>>\noutput\n=\nloss\n(\nlog_input\n,\ntarget\n)\n>>>\noutput\n.\nbackward\n()\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nOutput: scalar by default. If\nreduction\nis\n'none'\n, then\n(\n∗\n)\n(*)\n(\n∗\n)\n,\nthe same shape as the input.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.PoissonNLLLoss.html#poissonnllloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#PoissonNLLLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L278",
    "https://pytorch.org/docs/stable/generated/torch.nn.PoissonNLLLoss.html#torch.nn.PoissonNLLLoss",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.GaussianNLLLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.GaussianNLLLoss",
  "page_text": "GaussianNLLLoss\n¶\nclass\ntorch.nn.\nGaussianNLLLoss\n(\n*\n,\nfull\n=\nFalse\n,\neps\n=\n1e-06\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nGaussian negative log likelihood loss.\nThe targets are treated as samples from Gaussian distributions with\nexpectations and variances predicted by the neural network. For a\ntarget\ntensor modelled as having Gaussian distribution with a tensor\nof expectations\ninput\nand a tensor of positive variances\nvar\nthe loss is:\nloss\n=\n1\n2\n(\nlog\n⁡\n(\nmax\n(\nvar\n,\neps\n)\n)\n+\n(\ninput\n−\ntarget\n)\n2\nmax\n(\nvar\n,\neps\n)\n)\n+\nconst.\n\\text{loss} = \\frac{1}{2}\\left(\\log\\left(\\text{max}\\left(\\text{var},\n\\ \\text{eps}\\right)\\right) + \\frac{\\left(\\text{input} - \\text{target}\\right)^2}\n{\\text{max}\\left(\\text{var}, \\ \\text{eps}\\right)}\\right) + \\text{const.}\nloss\n=\n2\n1\n​\n(\nlo\ng\n(\nmax\n(\nvar\n,\neps\n)\n)\n+\nmax\n(\nvar\n,\neps\n)\n(\ninput\n−\ntarget\n)\n2\n​\n)\n+\nconst.\nwhere\neps\nis used for stability. By default, the constant term of\nthe loss function is omitted unless\nfull\nis\nTrue\n. If\nvar\nis not the same\nsize as\ninput\n(due to a homoscedastic assumption), it must either have a final dimension\nof 1 or have one fewer dimension (with all other sizes being the same) for correct broadcasting.\nParameters\nfull\n(\nbool\n,\noptional\n) – include the constant term in the loss\ncalculation. Default:\nFalse\n.\neps\n(\nfloat\n,\noptional\n) – value used to clamp\nvar\n(see note below), for\nstability. Default: 1e-6.\nreduction\n(\nstr\n,\noptional\n) – specifies the reduction to apply to the\noutput:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction\nwill be applied,\n'mean'\n: the output is the average of all batch\nmember losses,\n'sum'\n: the output is the sum of all batch member\nlosses. Default:\n'mean'\n.\nShape:\nInput:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\nor\n(\n∗\n)\n(*)\n(\n∗\n)\nwhere\n∗\n*\n∗\nmeans any number of additional\ndimensions\nTarget:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\nor\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input, or same shape as the input\nbut with one dimension equal to 1 (to allow for broadcasting)\nVar:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\nor\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input, or same shape as the input but\nwith one dimension equal to 1, or same shape as the input but with one fewer\ndimension (to allow for broadcasting), or a scalar value\nOutput: scalar if\nreduction\nis\n'mean'\n(default) or\n'sum'\n. If\nreduction\nis\n'none'\n, then\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\n, same\nshape as the input\nExamples::\n>>>\nloss\n=\nnn\n.\nGaussianNLLLoss\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n5\n,\n2\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nrandn\n(\n5\n,\n2\n)\n>>>\nvar\n=\ntorch\n.\nones\n(\n5\n,\n2\n,\nrequires_grad\n=\nTrue\n)\n# heteroscedastic\n>>>\noutput\n=\nloss\n(\ninput\n,\ntarget\n,\nvar\n)\n>>>\noutput\n.\nbackward\n()\n>>>\nloss\n=\nnn\n.\nGaussianNLLLoss\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n5\n,\n2\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nrandn\n(\n5\n,\n2\n)\n>>>\nvar\n=\ntorch\n.\nones\n(\n5\n,\n1\n,\nrequires_grad\n=\nTrue\n)\n# homoscedastic\n>>>\noutput\n=\nloss\n(\ninput\n,\ntarget\n,\nvar\n)\n>>>\noutput\n.\nbackward\n()\nNote\nThe clamping of\nvar\nis ignored with respect to autograd, and so the\ngradients are unaffected by it.\nReference:\nNix, D. A. and Weigend, A. S., “Estimating the mean and variance of the\ntarget probability distribution”, Proceedings of 1994 IEEE International\nConference on Neural Networks (ICNN’94), Orlando, FL, USA, 1994, pp. 55-60\nvol.1, doi: 10.1109/ICNN.1994.374138.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.GaussianNLLLoss.html#gaussiannllloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#GaussianNLLLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L364",
    "https://pytorch.org/docs/stable/generated/torch.nn.GaussianNLLLoss.html#torch.nn.GaussianNLLLoss",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.PoissonNLLLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.KLDivLoss",
  "page_text": "KLDivLoss\n¶\nclass\ntorch.nn.\nKLDivLoss\n(\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n,\nlog_target\n=\nFalse\n)\n[source]\n[source]\n¶\nThe Kullback-Leibler divergence loss.\nFor tensors of the same shape\ny\npred\n,\ny\ntrue\ny_{\\text{pred}},\\ y_{\\text{true}}\ny\npred\n​\n,\ny\ntrue\n​\n,\nwhere\ny\npred\ny_{\\text{pred}}\ny\npred\n​\nis the\ninput\nand\ny\ntrue\ny_{\\text{true}}\ny\ntrue\n​\nis the\ntarget\n, we define the\npointwise KL-divergence\nas\nL\n(\ny\npred\n,\ny\ntrue\n)\n=\ny\ntrue\n⋅\nlog\n⁡\ny\ntrue\ny\npred\n=\ny\ntrue\n⋅\n(\nlog\n⁡\ny\ntrue\n−\nlog\n⁡\ny\npred\n)\nL(y_{\\text{pred}},\\ y_{\\text{true}})\n    = y_{\\text{true}} \\cdot \\log \\frac{y_{\\text{true}}}{y_{\\text{pred}}}\n    = y_{\\text{true}} \\cdot (\\log y_{\\text{true}} - \\log y_{\\text{pred}})\nL\n(\ny\npred\n​\n,\ny\ntrue\n​\n)\n=\ny\ntrue\n​\n⋅\nlo\ng\ny\npred\n​\ny\ntrue\n​\n​\n=\ny\ntrue\n​\n⋅\n(\nlo\ng\ny\ntrue\n​\n−\nlo\ng\ny\npred\n​\n)\nTo avoid underflow issues when computing this quantity, this loss expects the argument\ninput\nin the log-space. The argument\ntarget\nmay also be provided in the\nlog-space if\nlog_target\n= True\n.\nTo summarise, this function is roughly equivalent to computing\nif\nnot\nlog_target\n:\n# default\nloss_pointwise\n=\ntarget\n*\n(\ntarget\n.\nlog\n()\n-\ninput\n)\nelse\n:\nloss_pointwise\n=\ntarget\n.\nexp\n()\n*\n(\ntarget\n-\ninput\n)\nand then reducing this result depending on the argument\nreduction\nas\nif\nreduction\n==\n\"mean\"\n:\n# default\nloss\n=\nloss_pointwise\n.\nmean\n()\nelif\nreduction\n==\n\"batchmean\"\n:\n# mathematically correct\nloss\n=\nloss_pointwise\n.\nsum\n()\n/\ninput\n.\nsize\n(\n0\n)\nelif\nreduction\n==\n\"sum\"\n:\nloss\n=\nloss_pointwise\n.\nsum\n()\nelse\n:\n# reduction == \"none\"\nloss\n=\nloss_pointwise\nNote\nAs all the other losses in PyTorch, this function expects the first argument,\ninput\n, to be the output of the model (e.g. the neural network)\nand the second,\ntarget\n, to be the observations in the dataset.\nThis differs from the standard mathematical notation\nK\nL\n(\nP\n∣\n∣\nQ\n)\nKL(P\\ ||\\ Q)\nK\nL\n(\nP\n∣∣\nQ\n)\nwhere\nP\nP\nP\ndenotes the distribution of the observations and\nQ\nQ\nQ\ndenotes the model.\nWarning\nreduction\n= “mean”\ndoesn’t return the true KL divergence value, please use\nreduction\n= “batchmean”\nwhich aligns with the mathematical definition.\nParameters\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output. Default:\n“mean”\nlog_target\n(\nbool\n,\noptional\n) – Specifies whether\ntarget\nis the log space. Default:\nFalse\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nOutput: scalar by default. If\nreduction\nis\n‘none’\n, then\n(\n∗\n)\n(*)\n(\n∗\n)\n,\nsame shape as the input.\nExamples::\n>>>\nkl_loss\n=\nnn\n.\nKLDivLoss\n(\nreduction\n=\n\"batchmean\"\n)\n>>>\n# input should be a distribution in the log space\n>>>\ninput\n=\nF\n.\nlog_softmax\n(\ntorch\n.\nrandn\n(\n3\n,\n5\n,\nrequires_grad\n=\nTrue\n),\ndim\n=\n1\n)\n>>>\n# Sample a batch of distributions. Usually this would come from the dataset\n>>>\ntarget\n=\nF\n.\nsoftmax\n(\ntorch\n.\nrand\n(\n3\n,\n5\n),\ndim\n=\n1\n)\n>>>\noutput\n=\nkl_loss\n(\ninput\n,\ntarget\n)\n>>>\nkl_loss\n=\nnn\n.\nKLDivLoss\n(\nreduction\n=\n\"batchmean\"\n,\nlog_target\n=\nTrue\n)\n>>>\nlog_target\n=\nF\n.\nlog_softmax\n(\ntorch\n.\nrand\n(\n3\n,\n5\n),\ndim\n=\n1\n)\n>>>\noutput\n=\nkl_loss\n(\ninput\n,\nlog_target\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html#kldivloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#KLDivLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L449",
    "https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.GaussianNLLLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.BCELoss",
  "page_text": "BCELoss\n¶\nclass\ntorch.nn.\nBCELoss\n(\nweight\n=\nNone\n,\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that measures the Binary Cross Entropy between the target and\nthe input probabilities:\nThe unreduced (i.e. with\nreduction\nset to\n'none'\n) loss can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\n,\nl\nn\n=\n−\nw\nn\n[\ny\nn\n⋅\nlog\n⁡\nx\nn\n+\n(\n1\n−\ny\nn\n)\n⋅\nlog\n⁡\n(\n1\n−\nx\nn\n)\n]\n,\n\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\nl_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n,\nl\nn\n​\n=\n−\nw\nn\n​\n[\ny\nn\n​\n⋅\nlo\ng\nx\nn\n​\n+\n(\n1\n−\ny\nn\n​\n)\n⋅\nlo\ng\n(\n1\n−\nx\nn\n​\n)\n]\n,\nwhere\nN\nN\nN\nis the batch size. If\nreduction\nis not\n'none'\n(default\n'mean'\n), then\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘mean’;\nsum\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) = \\begin{cases}\n    \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n    \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n(\nL\n)\n,\nsum\n(\nL\n)\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nThis is used for measuring the error of a reconstruction in for example\nan auto-encoder. Note that the targets\ny\ny\ny\nshould be numbers\nbetween 0 and 1.\nNotice that if\nx\nn\nx_n\nx\nn\n​\nis either 0 or 1, one of the log terms would be\nmathematically undefined in the above loss equation. PyTorch chooses to set\nlog\n⁡\n(\n0\n)\n=\n−\n∞\n\\log (0) = -\\infty\nlo\ng\n(\n0\n)\n=\n−\n∞\n, since\nlim\n⁡\nx\n→\n0\nlog\n⁡\n(\nx\n)\n=\n−\n∞\n\\lim_{x\\to 0} \\log (x) = -\\infty\nlim\nx\n→\n0\n​\nlo\ng\n(\nx\n)\n=\n−\n∞\n.\nHowever, an infinite term in the loss equation is not desirable for several reasons.\nFor one, if either\ny\nn\n=\n0\ny_n = 0\ny\nn\n​\n=\n0\nor\n(\n1\n−\ny\nn\n)\n=\n0\n(1 - y_n) = 0\n(\n1\n−\ny\nn\n​\n)\n=\n0\n, then we would be\nmultiplying 0 with infinity. Secondly, if we have an infinite loss value, then\nwe would also have an infinite term in our gradient, since\nlim\n⁡\nx\n→\n0\nd\nd\nx\nlog\n⁡\n(\nx\n)\n=\n∞\n\\lim_{x\\to 0} \\frac{d}{dx} \\log (x) = \\infty\nlim\nx\n→\n0\n​\nd\nx\nd\n​\nlo\ng\n(\nx\n)\n=\n∞\n.\nThis would make BCELoss’s backward method nonlinear with respect to\nx\nn\nx_n\nx\nn\n​\n,\nand using it for things like linear regression would not be straight-forward.\nOur solution is that BCELoss clamps its log function outputs to be greater than\nor equal to -100. This way, we can always have a finite loss value and a linear\nbackward method.\nParameters\nweight\n(\nTensor\n,\noptional\n) – a manual rescaling weight given to the loss\nof each batch element. If given, has to be a Tensor of size\nnbatch\n.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nOutput: scalar. If\nreduction\nis\n'none'\n, then\n(\n∗\n)\n(*)\n(\n∗\n)\n, same\nshape as input.\nExamples:\n>>>\nm\n=\nnn\n.\nSigmoid\n()\n>>>\nloss\n=\nnn\n.\nBCELoss\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n3\n,\n2\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nrand\n(\n3\n,\n2\n,\nrequires_grad\n=\nFalse\n)\n>>>\noutput\n=\nloss\n(\nm\n(\ninput\n),\ntarget\n)\n>>>\noutput\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#bceloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#BCELoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L613",
    "https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.BCEWithLogitsLoss",
  "page_text": "BCEWithLogitsLoss\n¶\nclass\ntorch.nn.\nBCEWithLogitsLoss\n(\nweight\n=\nNone\n,\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n,\npos_weight\n=\nNone\n)\n[source]\n[source]\n¶\nThis loss combines a\nSigmoid\nlayer and the\nBCELoss\nin one single\nclass. This version is more numerically stable than using a plain\nSigmoid\nfollowed by a\nBCELoss\nas, by combining the operations into one layer,\nwe take advantage of the log-sum-exp trick for numerical stability.\nThe unreduced (i.e. with\nreduction\nset to\n'none'\n) loss can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\n,\nl\nn\n=\n−\nw\nn\n[\ny\nn\n⋅\nlog\n⁡\nσ\n(\nx\nn\n)\n+\n(\n1\n−\ny\nn\n)\n⋅\nlog\n⁡\n(\n1\n−\nσ\n(\nx\nn\n)\n)\n]\n,\n\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\nl_n = - w_n \\left[ y_n \\cdot \\log \\sigma(x_n)\n+ (1 - y_n) \\cdot \\log (1 - \\sigma(x_n)) \\right],\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n,\nl\nn\n​\n=\n−\nw\nn\n​\n[\ny\nn\n​\n⋅\nlo\ng\nσ\n(\nx\nn\n​\n)\n+\n(\n1\n−\ny\nn\n​\n)\n⋅\nlo\ng\n(\n1\n−\nσ\n(\nx\nn\n​\n))\n]\n,\nwhere\nN\nN\nN\nis the batch size. If\nreduction\nis not\n'none'\n(default\n'mean'\n), then\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘mean’;\nsum\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) = \\begin{cases}\n    \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n    \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n(\nL\n)\n,\nsum\n(\nL\n)\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nThis is used for measuring the error of a reconstruction in for example\nan auto-encoder. Note that the targets\nt[i]\nshould be numbers\nbetween 0 and 1.\nIt’s possible to trade off recall and precision by adding weights to positive examples.\nIn the case of multi-label classification the loss can be described as:\nℓ\nc\n(\nx\n,\ny\n)\n=\nL\nc\n=\n{\nl\n1\n,\nc\n,\n…\n,\nl\nN\n,\nc\n}\n⊤\n,\nl\nn\n,\nc\n=\n−\nw\nn\n,\nc\n[\np\nc\ny\nn\n,\nc\n⋅\nlog\n⁡\nσ\n(\nx\nn\n,\nc\n)\n+\n(\n1\n−\ny\nn\n,\nc\n)\n⋅\nlog\n⁡\n(\n1\n−\nσ\n(\nx\nn\n,\nc\n)\n)\n]\n,\n\\ell_c(x, y) = L_c = \\{l_{1,c},\\dots,l_{N,c}\\}^\\top, \\quad\nl_{n,c} = - w_{n,c} \\left[ p_c y_{n,c} \\cdot \\log \\sigma(x_{n,c})\n+ (1 - y_{n,c}) \\cdot \\log (1 - \\sigma(x_{n,c})) \\right],\nℓ\nc\n​\n(\nx\n,\ny\n)\n=\nL\nc\n​\n=\n{\nl\n1\n,\nc\n​\n,\n…\n,\nl\nN\n,\nc\n​\n}\n⊤\n,\nl\nn\n,\nc\n​\n=\n−\nw\nn\n,\nc\n​\n[\np\nc\n​\ny\nn\n,\nc\n​\n⋅\nlo\ng\nσ\n(\nx\nn\n,\nc\n​\n)\n+\n(\n1\n−\ny\nn\n,\nc\n​\n)\n⋅\nlo\ng\n(\n1\n−\nσ\n(\nx\nn\n,\nc\n​\n))\n]\n,\nwhere\nc\nc\nc\nis the class number (\nc\n>\n1\nc > 1\nc\n>\n1\nfor multi-label binary classification,\nc\n=\n1\nc = 1\nc\n=\n1\nfor single-label binary classification),\nn\nn\nn\nis the number of the sample in the batch and\np\nc\np_c\np\nc\n​\nis the weight of the positive answer for the class\nc\nc\nc\n.\np\nc\n>\n1\np_c > 1\np\nc\n​\n>\n1\nincreases the recall,\np\nc\n<\n1\np_c < 1\np\nc\n​\n<\n1\nincreases the precision.\nFor example, if a dataset contains 100 positive and 300 negative examples of a single class,\nthen\npos_weight\nfor the class should be equal to\n300\n100\n=\n3\n\\frac{300}{100}=3\n100\n300\n​\n=\n3\n.\nThe loss would act as if the dataset contains\n3\n×\n100\n=\n300\n3\\times 100=300\n3\n×\n100\n=\n300\npositive examples.\nExamples:\n>>>\ntarget\n=\ntorch\n.\nones\n([\n10\n,\n64\n],\ndtype\n=\ntorch\n.\nfloat32\n)\n# 64 classes, batch size = 10\n>>>\noutput\n=\ntorch\n.\nfull\n([\n10\n,\n64\n],\n1.5\n)\n# A prediction (logit)\n>>>\npos_weight\n=\ntorch\n.\nones\n([\n64\n])\n# All weights are equal to 1\n>>>\ncriterion\n=\ntorch\n.\nnn\n.\nBCEWithLogitsLoss\n(\npos_weight\n=\npos_weight\n)\n>>>\ncriterion\n(\noutput\n,\ntarget\n)\n# -log(sigmoid(1.5))\ntensor(0.20...)\nIn the above example, the\npos_weight\ntensor’s elements correspond to the 64 distinct classes\nin a multi-label binary classification scenario. Each element in\npos_weight\nis designed to adjust the\nloss function based on the imbalance between negative and positive samples for the respective class.\nThis approach is useful in datasets with varying levels of class imbalance, ensuring that the loss\ncalculation accurately accounts for the distribution in each class.\nParameters\nweight\n(\nTensor\n,\noptional\n) – a manual rescaling weight given to the loss\nof each batch element. If given, has to be a Tensor of size\nnbatch\n.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\npos_weight\n(\nTensor\n,\noptional\n) – a weight of positive examples to be broadcasted with target.\nMust be a tensor with equal size along the class dimension to the number of classes.\nPay close attention to PyTorch’s broadcasting semantics in order to achieve the desired\noperations. For a target of size [B, C, H, W] (where B is batch size) pos_weight of\nsize [B, C, H, W] will apply different pos_weights to each element of the batch or\n[C, H, W] the same pos_weights across the batch. To apply the same positive weight\nalong all spacial dimensions for a 2D multi-class target [C, H, W] use: [C, 1, 1].\nDefault:\nNone\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nOutput: scalar. If\nreduction\nis\n'none'\n, then\n(\n∗\n)\n(*)\n(\n∗\n)\n, same\nshape as input.\nExamples:\n>>>\nloss\n=\nnn\n.\nBCEWithLogitsLoss\n()\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n3\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nempty\n(\n3\n)\n.\nrandom_\n(\n2\n)\n>>>\noutput\n=\nloss\n(\ninput\n,\ntarget\n)\n>>>\noutput\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#bcewithlogitsloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#BCEWithLogitsLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L704",
    "https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MarginRankingLoss",
  "page_text": "MarginRankingLoss\n¶\nclass\ntorch.nn.\nMarginRankingLoss\n(\nmargin\n=\n0.0\n,\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that measures the loss given\ninputs\nx\n1\nx1\nx\n1\n,\nx\n2\nx2\nx\n2\n, two 1D mini-batch or 0D\nTensors\n,\nand a label 1D mini-batch or 0D\nTensor\ny\ny\ny\n(containing 1 or -1).\nIf\ny\n=\n1\ny = 1\ny\n=\n1\nthen it assumed the first input should be ranked higher\n(have a larger value) than the second input, and vice-versa for\ny\n=\n−\n1\ny = -1\ny\n=\n−\n1\n.\nThe loss function for each pair of samples in the mini-batch is:\nloss\n(\nx\n1\n,\nx\n2\n,\ny\n)\n=\nmax\n⁡\n(\n0\n,\n−\ny\n∗\n(\nx\n1\n−\nx\n2\n)\n+\nmargin\n)\n\\text{loss}(x1, x2, y) = \\max(0, -y * (x1 - x2) + \\text{margin})\nloss\n(\nx\n1\n,\nx\n2\n,\ny\n)\n=\nmax\n(\n0\n,\n−\ny\n∗\n(\nx\n1\n−\nx\n2\n)\n+\nmargin\n)\nParameters\nmargin\n(\nfloat\n,\noptional\n) – Has a default value of\n0\n0\n0\n.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput1:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\nwhere\nN\nis the batch size.\nInput2:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\n, same shape as the Input1.\nTarget:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\n, same shape as the inputs.\nOutput: scalar. If\nreduction\nis\n'none'\nand Input size is not\n(\n)\n()\n(\n)\n, then\n(\nN\n)\n(N)\n(\nN\n)\n.\nExamples:\n>>>\nloss\n=\nnn\n.\nMarginRankingLoss\n()\n>>>\ninput1\n=\ntorch\n.\nrandn\n(\n3\n,\nrequires_grad\n=\nTrue\n)\n>>>\ninput2\n=\ntorch\n.\nrandn\n(\n3\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nrandn\n(\n3\n)\n.\nsign\n()\n>>>\noutput\n=\nloss\n(\ninput1\n,\ninput2\n,\ntarget\n)\n>>>\noutput\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html#marginrankingloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#MarginRankingLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1430",
    "https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html#torch.nn.MarginRankingLoss",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.HingeEmbeddingLoss",
  "page_text": "HingeEmbeddingLoss\n¶\nclass\ntorch.nn.\nHingeEmbeddingLoss\n(\nmargin\n=\n1.0\n,\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nMeasures the loss given an input tensor\nx\nx\nx\nand a labels tensor\ny\ny\ny\n(containing 1 or -1).\nThis is usually used for measuring whether two inputs are similar or\ndissimilar, e.g. using the L1 pairwise distance as\nx\nx\nx\n, and is typically\nused for learning nonlinear embeddings or semi-supervised learning.\nThe loss function for\nn\nn\nn\n-th sample in the mini-batch is\nl\nn\n=\n{\nx\nn\n,\nif\ny\nn\n=\n1\n,\nmax\n⁡\n{\n0\n,\nm\na\nr\ng\ni\nn\n−\nx\nn\n}\n,\nif\ny\nn\n=\n−\n1\n,\nl_n = \\begin{cases}\n    x_n, & \\text{if}\\; y_n = 1,\\\\\n    \\max \\{0, margin - x_n\\}, & \\text{if}\\; y_n = -1,\n\\end{cases}\nl\nn\n​\n=\n{\nx\nn\n​\n,\nmax\n{\n0\n,\nma\nr\ng\nin\n−\nx\nn\n​\n}\n,\n​\nif\ny\nn\n​\n=\n1\n,\nif\ny\nn\n​\n=\n−\n1\n,\n​\nand the total loss functions is\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘mean’;\nsum\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) = \\begin{cases}\n    \\operatorname{mean}(L), & \\text{if reduction} = \\text{`mean';}\\\\\n    \\operatorname{sum}(L),  & \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n(\nL\n)\n,\nsum\n(\nL\n)\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nwhere\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\nL = \\{l_1,\\dots,l_N\\}^\\top\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n.\nParameters\nmargin\n(\nfloat\n,\noptional\n) – Has a default value of\n1\n.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\nwhere\n∗\n*\n∗\nmeans, any number of dimensions. The sum operation\noperates over all the elements.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input\nOutput: scalar. If\nreduction\nis\n'none'\n, then same shape as the input\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html#hingeembeddingloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#HingeEmbeddingLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L830",
    "https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html#torch.nn.HingeEmbeddingLoss",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelMarginLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MultiLabelMarginLoss",
  "page_text": "MultiLabelMarginLoss\n¶\nclass\ntorch.nn.\nMultiLabelMarginLoss\n(\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that optimizes a multi-class multi-classification\nhinge loss (margin-based loss) between input\nx\nx\nx\n(a 2D mini-batch\nTensor\n)\nand output\ny\ny\ny\n(which is a 2D\nTensor\nof target class indices).\nFor each sample in the mini-batch:\nloss\n(\nx\n,\ny\n)\n=\n∑\ni\nj\nmax\n⁡\n(\n0\n,\n1\n−\n(\nx\n[\ny\n[\nj\n]\n]\n−\nx\n[\ni\n]\n)\n)\nx.size\n(\n0\n)\n\\text{loss}(x, y) = \\sum_{ij}\\frac{\\max(0, 1 - (x[y[j]] - x[i]))}{\\text{x.size}(0)}\nloss\n(\nx\n,\ny\n)\n=\nij\n∑\n​\nx.size\n(\n0\n)\nmax\n(\n0\n,\n1\n−\n(\nx\n[\ny\n[\nj\n]]\n−\nx\n[\ni\n]))\n​\nwhere\nx\n∈\n{\n0\n,\n⋯\n,\nx.size\n(\n0\n)\n−\n1\n}\nx \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}\nx\n∈\n{\n0\n,\n⋯\n,\nx.size\n(\n0\n)\n−\n1\n}\n,\ny\n∈\n{\n0\n,\n⋯\n,\ny.size\n(\n0\n)\n−\n1\n}\ny \\in \\left\\{0, \\; \\cdots , \\; \\text{y.size}(0) - 1\\right\\}\ny\n∈\n{\n0\n,\n⋯\n,\ny.size\n(\n0\n)\n−\n1\n}\n,\n0\n≤\ny\n[\nj\n]\n≤\nx.size\n(\n0\n)\n−\n1\n0 \\leq y[j] \\leq \\text{x.size}(0)-1\n0\n≤\ny\n[\nj\n]\n≤\nx.size\n(\n0\n)\n−\n1\n, and\ni\n≠\ny\n[\nj\n]\ni \\neq y[j]\ni\n\n=\ny\n[\nj\n]\nfor all\ni\ni\ni\nand\nj\nj\nj\n.\ny\ny\ny\nand\nx\nx\nx\nmust have the same size.\nThe criterion only considers a contiguous block of non-negative targets that\nstarts at the front.\nThis allows for different samples to have variable amounts of target classes.\nParameters\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\nC\n)\n(C)\n(\nC\n)\nor\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\nwhere\nN\nis the batch size and\nC\nis the number of classes.\nTarget:\n(\nC\n)\n(C)\n(\nC\n)\nor\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\n, label targets padded by -1 ensuring same shape as the input.\nOutput: scalar. If\nreduction\nis\n'none'\n, then\n(\nN\n)\n(N)\n(\nN\n)\n.\nExamples:\n>>>\nloss\n=\nnn\n.\nMultiLabelMarginLoss\n()\n>>>\nx\n=\ntorch\n.\nFloatTensor\n([[\n0.1\n,\n0.2\n,\n0.4\n,\n0.8\n]])\n>>>\n# for target y, only consider labels 3 and 0, not after label -1\n>>>\ny\n=\ntorch\n.\nLongTensor\n([[\n3\n,\n0\n,\n-\n1\n,\n1\n]])\n>>>\n# 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n>>>\nloss\n(\nx\n,\ny\n)\ntensor(0.85...)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelMarginLoss.html#multilabelmarginloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#MultiLabelMarginLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L898",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelMarginLoss.html#torch.nn.MultiLabelMarginLoss",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.HuberLoss",
  "page_text": "HuberLoss\n¶\nclass\ntorch.nn.\nHuberLoss\n(\nreduction\n=\n'mean'\n,\ndelta\n=\n1.0\n)\n[source]\n[source]\n¶\nCreates a criterion that uses a squared term if the absolute\nelement-wise error falls below delta and a delta-scaled L1 term otherwise.\nThis loss combines advantages of both\nL1Loss\nand\nMSELoss\n; the\ndelta-scaled L1 region makes the loss less sensitive to outliers than\nMSELoss\n,\nwhile the L2 region provides smoothness over\nL1Loss\nnear 0. See\nHuber loss\nfor more information.\nFor a batch of size\nN\nN\nN\n, the unreduced loss can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n.\n.\n.\n,\nl\nN\n}\nT\n\\ell(x, y) = L = \\{l_1, ..., l_N\\}^T\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n...\n,\nl\nN\n​\n}\nT\nwith\nl\nn\n=\n{\n0.5\n(\nx\nn\n−\ny\nn\n)\n2\n,\nif\n∣\nx\nn\n−\ny\nn\n∣\n<\nd\ne\nl\nt\na\nd\ne\nl\nt\na\n∗\n(\n∣\nx\nn\n−\ny\nn\n∣\n−\n0.5\n∗\nd\ne\nl\nt\na\n)\n,\notherwise\nl_n = \\begin{cases}\n0.5 (x_n - y_n)^2, & \\text{if } |x_n - y_n| < delta \\\\\ndelta * (|x_n - y_n| - 0.5 * delta), & \\text{otherwise }\n\\end{cases}\nl\nn\n​\n=\n{\n0.5\n(\nx\nn\n​\n−\ny\nn\n​\n)\n2\n,\nd\ne\nlt\na\n∗\n(\n∣\nx\nn\n​\n−\ny\nn\n​\n∣\n−\n0.5\n∗\nd\ne\nlt\na\n)\n,\n​\nif\n∣\nx\nn\n​\n−\ny\nn\n​\n∣\n<\nd\ne\nlt\na\notherwise\n​\nIf\nreduction\nis not\nnone\n, then:\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘mean’;\nsum\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) =\n\\begin{cases}\n    \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n    \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n(\nL\n)\n,\nsum\n(\nL\n)\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nNote\nWhen delta is set to 1, this loss is equivalent to\nSmoothL1Loss\n.\nIn general, this loss differs from\nSmoothL1Loss\nby a factor of delta (AKA beta\nin Smooth L1).\nSee\nSmoothL1Loss\nfor additional discussion on the differences in behavior\nbetween the two losses.\nParameters\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Default:\n'mean'\ndelta\n(\nfloat\n,\noptional\n) – Specifies the threshold at which to change between delta-scaled L1 and L2 loss.\nThe value must be positive.  Default: 1.0\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\nwhere\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nOutput: scalar. If\nreduction\nis\n'none'\n, then\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html#huberloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#HuberLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1045",
    "https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss",
    "https://en.wikipedia.org/wiki/Huber_loss",
    "https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html#torch.nn.SmoothL1Loss",
    "https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html#torch.nn.SmoothL1Loss",
    "https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html#torch.nn.SmoothL1Loss",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelMarginLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.SmoothL1Loss",
  "page_text": "SmoothL1Loss\n¶\nclass\ntorch.nn.\nSmoothL1Loss\n(\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n,\nbeta\n=\n1.0\n)\n[source]\n[source]\n¶\nCreates a criterion that uses a squared term if the absolute\nelement-wise error falls below beta and an L1 term otherwise.\nIt is less sensitive to outliers than\ntorch.nn.MSELoss\nand in some cases\nprevents exploding gradients (e.g. see the paper\nFast R-CNN\nby Ross Girshick).\nFor a batch of size\nN\nN\nN\n, the unreduced loss can be described as:\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n,\n.\n.\n.\n,\nl\nN\n}\nT\n\\ell(x, y) = L = \\{l_1, ..., l_N\\}^T\nℓ\n(\nx\n,\ny\n)\n=\nL\n=\n{\nl\n1\n​\n,\n...\n,\nl\nN\n​\n}\nT\nwith\nl\nn\n=\n{\n0.5\n(\nx\nn\n−\ny\nn\n)\n2\n/\nb\ne\nt\na\n,\nif\n∣\nx\nn\n−\ny\nn\n∣\n<\nb\ne\nt\na\n∣\nx\nn\n−\ny\nn\n∣\n−\n0.5\n∗\nb\ne\nt\na\n,\notherwise\nl_n = \\begin{cases}\n0.5 (x_n - y_n)^2 / beta, & \\text{if } |x_n - y_n| < beta \\\\\n|x_n - y_n| - 0.5 * beta, & \\text{otherwise }\n\\end{cases}\nl\nn\n​\n=\n{\n0.5\n(\nx\nn\n​\n−\ny\nn\n​\n)\n2\n/\nb\ne\nt\na\n,\n∣\nx\nn\n​\n−\ny\nn\n​\n∣\n−\n0.5\n∗\nb\ne\nt\na\n,\n​\nif\n∣\nx\nn\n​\n−\ny\nn\n​\n∣\n<\nb\ne\nt\na\notherwise\n​\nIf\nreduction\nis not\nnone\n, then:\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘mean’;\nsum\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) =\n\\begin{cases}\n    \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n    \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n(\nL\n)\n,\nsum\n(\nL\n)\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nNote\nSmooth L1 loss can be seen as exactly\nL1Loss\n, but with the\n∣\nx\n−\ny\n∣\n<\nb\ne\nt\na\n|x - y| < beta\n∣\nx\n−\ny\n∣\n<\nb\ne\nt\na\nportion replaced with a quadratic function such that its slope is 1 at\n∣\nx\n−\ny\n∣\n=\nb\ne\nt\na\n|x - y| = beta\n∣\nx\n−\ny\n∣\n=\nb\ne\nt\na\n.\nThe quadratic segment smooths the L1 loss near\n∣\nx\n−\ny\n∣\n=\n0\n|x - y| = 0\n∣\nx\n−\ny\n∣\n=\n0\n.\nNote\nSmooth L1 loss is closely related to\nHuberLoss\n, being\nequivalent to\nh\nu\nb\ne\nr\n(\nx\n,\ny\n)\n/\nb\ne\nt\na\nhuber(x, y) / beta\nh\nu\nb\ner\n(\nx\n,\ny\n)\n/\nb\ne\nt\na\n(note that Smooth L1’s beta hyper-parameter is\nalso known as delta for Huber). This leads to the following differences:\nAs beta -> 0, Smooth L1 loss converges to\nL1Loss\n, while\nHuberLoss\nconverges to a constant 0 loss. When beta is 0, Smooth L1 loss is equivalent to L1 loss.\nAs beta ->\n+\n∞\n+\\infty\n+\n∞\n, Smooth L1 loss converges to a constant 0 loss, while\nHuberLoss\nconverges to\nMSELoss\n.\nFor Smooth L1 loss, as beta varies, the L1 segment of the loss has a constant slope of 1.\nFor\nHuberLoss\n, the slope of the L1 segment is beta.\nParameters\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nbeta\n(\nfloat\n,\noptional\n) – Specifies the threshold at which to change between L1 and L2 loss.\nThe value must be non-negative. Default: 1.0\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nOutput: scalar. If\nreduction\nis\n'none'\n, then\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html#smoothl1loss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#SmoothL1Loss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L962",
    "https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html#torch.nn.SmoothL1Loss",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss",
    "https://arxiv.org/abs/1504.08083",
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss",
    "https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss",
    "https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.SoftMarginLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.SoftMarginLoss",
  "page_text": "SoftMarginLoss\n¶\nclass\ntorch.nn.\nSoftMarginLoss\n(\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that optimizes a two-class classification\nlogistic loss between input tensor\nx\nx\nx\nand target tensor\ny\ny\ny\n(containing 1 or -1).\nloss\n(\nx\n,\ny\n)\n=\n∑\ni\nlog\n⁡\n(\n1\n+\nexp\n⁡\n(\n−\ny\n[\ni\n]\n∗\nx\n[\ni\n]\n)\n)\nx.nelement\n(\n)\n\\text{loss}(x, y) = \\sum_i \\frac{\\log(1 + \\exp(-y[i]*x[i]))}{\\text{x.nelement}()}\nloss\n(\nx\n,\ny\n)\n=\ni\n∑\n​\nx.nelement\n(\n)\nlo\ng\n(\n1\n+\nexp\n(\n−\ny\n[\ni\n]\n∗\nx\n[\ni\n]))\n​\nParameters\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\n∗\n)\n(*)\n(\n∗\n)\n, where\n∗\n*\n∗\nmeans any number of dimensions.\nTarget:\n(\n∗\n)\n(*)\n(\n∗\n)\n, same shape as the input.\nOutput: scalar. If\nreduction\nis\n'none'\n, then\n(\n∗\n)\n(*)\n(\n∗\n)\n, same\nshape as input.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.SoftMarginLoss.html#softmarginloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#SoftMarginLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1105",
    "https://pytorch.org/docs/stable/generated/torch.nn.SoftMarginLoss.html#torch.nn.SoftMarginLoss",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelSoftMarginLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MultiLabelSoftMarginLoss",
  "page_text": "MultiLabelSoftMarginLoss\n¶\nclass\ntorch.nn.\nMultiLabelSoftMarginLoss\n(\nweight\n=\nNone\n,\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that optimizes a multi-label one-versus-all\nloss based on max-entropy, between input\nx\nx\nx\nand target\ny\ny\ny\nof size\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\n.\nFor each sample in the minibatch:\nl\no\ns\ns\n(\nx\n,\ny\n)\n=\n−\n1\nC\n∗\n∑\ni\ny\n[\ni\n]\n∗\nlog\n⁡\n(\n(\n1\n+\nexp\n⁡\n(\n−\nx\n[\ni\n]\n)\n)\n−\n1\n)\n+\n(\n1\n−\ny\n[\ni\n]\n)\n∗\nlog\n⁡\n(\nexp\n⁡\n(\n−\nx\n[\ni\n]\n)\n(\n1\n+\nexp\n⁡\n(\n−\nx\n[\ni\n]\n)\n)\n)\nloss(x, y) = - \\frac{1}{C} * \\sum_i y[i] * \\log((1 + \\exp(-x[i]))^{-1})\n                 + (1-y[i]) * \\log\\left(\\frac{\\exp(-x[i])}{(1 + \\exp(-x[i]))}\\right)\nl\noss\n(\nx\n,\ny\n)\n=\n−\nC\n1\n​\n∗\ni\n∑\n​\ny\n[\ni\n]\n∗\nlo\ng\n((\n1\n+\nexp\n(\n−\nx\n[\ni\n])\n)\n−\n1\n)\n+\n(\n1\n−\ny\n[\ni\n])\n∗\nlo\ng\n(\n(\n1\n+\nexp\n(\n−\nx\n[\ni\n]))\nexp\n(\n−\nx\n[\ni\n])\n​\n)\nwhere\ni\n∈\n{\n0\n,\n⋯\n,\nx.nElement\n(\n)\n−\n1\n}\ni \\in \\left\\{0, \\; \\cdots , \\; \\text{x.nElement}() - 1\\right\\}\ni\n∈\n{\n0\n,\n⋯\n,\nx.nElement\n(\n)\n−\n1\n}\n,\ny\n[\ni\n]\n∈\n{\n0\n,\n1\n}\ny[i] \\in \\left\\{0, \\; 1\\right\\}\ny\n[\ni\n]\n∈\n{\n0\n,\n1\n}\n.\nParameters\nweight\n(\nTensor\n,\noptional\n) – a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size\nC\n. Otherwise, it is\ntreated as if having all ones.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\nwhere\nN\nis the batch size and\nC\nis the number of classes.\nTarget:\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\n, label targets must have the same shape as the input.\nOutput: scalar. If\nreduction\nis\n'none'\n, then\n(\nN\n)\n(N)\n(\nN\n)\n.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelSoftMarginLoss.html#multilabelsoftmarginloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#MultiLabelSoftMarginLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1305",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelSoftMarginLoss.html#torch.nn.MultiLabelSoftMarginLoss",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.SoftMarginLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.CosineEmbeddingLoss",
  "page_text": "CosineEmbeddingLoss\n¶\nclass\ntorch.nn.\nCosineEmbeddingLoss\n(\nmargin\n=\n0.0\n,\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that measures the loss given input tensors\nx\n1\nx_1\nx\n1\n​\n,\nx\n2\nx_2\nx\n2\n​\nand a\nTensor\nlabel\ny\ny\ny\nwith values 1 or -1.\nUse (\ny\n=\n1\ny=1\ny\n=\n1\n) to maximize the cosine similarity of two inputs, and (\ny\n=\n−\n1\ny=-1\ny\n=\n−\n1\n) otherwise.\nThis is typically used for learning nonlinear\nembeddings or semi-supervised learning.\nThe loss function for each sample is:\nloss\n(\nx\n,\ny\n)\n=\n{\n1\n−\ncos\n⁡\n(\nx\n1\n,\nx\n2\n)\n,\nif\ny\n=\n1\nmax\n⁡\n(\n0\n,\ncos\n⁡\n(\nx\n1\n,\nx\n2\n)\n−\nmargin\n)\n,\nif\ny\n=\n−\n1\n\\text{loss}(x, y) =\n\\begin{cases}\n1 - \\cos(x_1, x_2), & \\text{if } y = 1 \\\\\n\\max(0, \\cos(x_1, x_2) - \\text{margin}), & \\text{if } y = -1\n\\end{cases}\nloss\n(\nx\n,\ny\n)\n=\n{\n1\n−\ncos\n(\nx\n1\n​\n,\nx\n2\n​\n)\n,\nmax\n(\n0\n,\ncos\n(\nx\n1\n​\n,\nx\n2\n​\n)\n−\nmargin\n)\n,\n​\nif\ny\n=\n1\nif\ny\n=\n−\n1\n​\nParameters\nmargin\n(\nfloat\n,\noptional\n) – Should be a number from\n−\n1\n-1\n−\n1\nto\n1\n1\n1\n,\n0\n0\n0\nto\n0.5\n0.5\n0.5\nis suggested. If\nmargin\nis missing, the\ndefault value is\n0\n0\n0\n.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput1:\n(\nN\n,\nD\n)\n(N, D)\n(\nN\n,\nD\n)\nor\n(\nD\n)\n(D)\n(\nD\n)\n, where\nN\nis the batch size and\nD\nis the embedding dimension.\nInput2:\n(\nN\n,\nD\n)\n(N, D)\n(\nN\n,\nD\n)\nor\n(\nD\n)\n(D)\n(\nD\n)\n, same shape as Input1.\nTarget:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\n.\nOutput: If\nreduction\nis\n'none'\n, then\n(\nN\n)\n(N)\n(\nN\n)\n, otherwise scalar.\nExamples:\n>>>\nloss\n=\nnn\n.\nCosineEmbeddingLoss\n()\n>>>\ninput1\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n,\nrequires_grad\n=\nTrue\n)\n>>>\ninput2\n=\ntorch\n.\nrandn\n(\n3\n,\n5\n,\nrequires_grad\n=\nTrue\n)\n>>>\ntarget\n=\ntorch\n.\nones\n(\n3\n)\n>>>\noutput\n=\nloss\n(\ninput1\n,\ninput2\n,\ntarget\n)\n>>>\noutput\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html#cosineembeddingloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#CosineEmbeddingLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1360",
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html#torch.nn.CosineEmbeddingLoss",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiMarginLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelSoftMarginLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.MultiMarginLoss",
  "page_text": "MultiMarginLoss\n¶\nclass\ntorch.nn.\nMultiMarginLoss\n(\np\n=\n1\n,\nmargin\n=\n1.0\n,\nweight\n=\nNone\n,\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that optimizes a multi-class classification hinge\nloss (margin-based loss) between input\nx\nx\nx\n(a 2D mini-batch\nTensor\n) and\noutput\ny\ny\ny\n(which is a 1D tensor of target class indices,\n0\n≤\ny\n≤\nx.size\n(\n1\n)\n−\n1\n0 \\leq y \\leq \\text{x.size}(1)-1\n0\n≤\ny\n≤\nx.size\n(\n1\n)\n−\n1\n):\nFor each mini-batch sample, the loss in terms of the 1D input\nx\nx\nx\nand scalar\noutput\ny\ny\ny\nis:\nloss\n(\nx\n,\ny\n)\n=\n∑\ni\nmax\n⁡\n(\n0\n,\nmargin\n−\nx\n[\ny\n]\n+\nx\n[\ni\n]\n)\np\nx.size\n(\n0\n)\n\\text{loss}(x, y) = \\frac{\\sum_i \\max(0, \\text{margin} - x[y] + x[i])^p}{\\text{x.size}(0)}\nloss\n(\nx\n,\ny\n)\n=\nx.size\n(\n0\n)\n∑\ni\n​\nmax\n(\n0\n,\nmargin\n−\nx\n[\ny\n]\n+\nx\n[\ni\n]\n)\np\n​\nwhere\ni\n∈\n{\n0\n,\n⋯\n,\nx.size\n(\n0\n)\n−\n1\n}\ni \\in \\left\\{0, \\; \\cdots , \\; \\text{x.size}(0) - 1\\right\\}\ni\n∈\n{\n0\n,\n⋯\n,\nx.size\n(\n0\n)\n−\n1\n}\nand\ni\n≠\ny\ni \\neq y\ni\n\n=\ny\n.\nOptionally, you can give non-equal weighting on the classes by passing\na 1D\nweight\ntensor into the constructor.\nThe loss function then becomes:\nloss\n(\nx\n,\ny\n)\n=\n∑\ni\nw\n[\ny\n]\n∗\nmax\n⁡\n(\n0\n,\nmargin\n−\nx\n[\ny\n]\n+\nx\n[\ni\n]\n)\np\nx.size\n(\n0\n)\n\\text{loss}(x, y) = \\frac{\\sum_i w[y] * \\max(0, \\text{margin} - x[y] + x[i])^p}{\\text{x.size}(0)}\nloss\n(\nx\n,\ny\n)\n=\nx.size\n(\n0\n)\n∑\ni\n​\nw\n[\ny\n]\n∗\nmax\n(\n0\n,\nmargin\n−\nx\n[\ny\n]\n+\nx\n[\ni\n]\n)\np\n​\nParameters\np\n(\nint\n,\noptional\n) – Has a default value of\n1\n1\n1\n.\n1\n1\n1\nand\n2\n2\n2\nare the only supported values.\nmargin\n(\nfloat\n,\noptional\n) – Has a default value of\n1\n1\n1\n.\nweight\n(\nTensor\n,\noptional\n) – a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size\nC\n. Otherwise, it is\ntreated as if having all ones.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\nN\n,\nC\n)\n(N, C)\n(\nN\n,\nC\n)\nor\n(\nC\n)\n(C)\n(\nC\n)\n, where\nN\nN\nN\nis the batch size and\nC\nC\nC\nis the number of classes.\nTarget:\n(\nN\n)\n(N)\n(\nN\n)\nor\n(\n)\n()\n(\n)\n, where each value is\n0\n≤\ntargets\n[\ni\n]\n≤\nC\n−\n1\n0 \\leq \\text{targets}[i] \\leq C-1\n0\n≤\ntargets\n[\ni\n]\n≤\nC\n−\n1\n.\nOutput: scalar. If\nreduction\nis\n'none'\n, then same shape as the target.\nExamples:\n>>>\nloss\n=\nnn\n.\nMultiMarginLoss\n()\n>>>\nx\n=\ntorch\n.\ntensor\n([[\n0.1\n,\n0.2\n,\n0.4\n,\n0.8\n]])\n>>>\ny\n=\ntorch\n.\ntensor\n([\n3\n])\n>>>\n# 0.25 * ((1-(0.8-0.1)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))\n>>>\nloss\n(\nx\n,\ny\n)\ntensor(0.32...)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiMarginLoss.html#multimarginloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#MultiMarginLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1495",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiMarginLoss.html#torch.nn.MultiMarginLoss",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.TripletMarginLoss",
  "page_text": "TripletMarginLoss\n¶\nclass\ntorch.nn.\nTripletMarginLoss\n(\nmargin\n=\n1.0\n,\np\n=\n2.0\n,\neps\n=\n1e-06\n,\nswap\n=\nFalse\n,\nsize_average\n=\nNone\n,\nreduce\n=\nNone\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that measures the triplet loss given an input\ntensors\nx\n1\nx1\nx\n1\n,\nx\n2\nx2\nx\n2\n,\nx\n3\nx3\nx\n3\nand a margin with a value greater than\n0\n0\n0\n.\nThis is used for measuring a relative similarity between samples. A triplet\nis composed by\na\n,\np\nand\nn\n(i.e.,\nanchor\n,\npositive examples\nand\nnegative\nexamples\nrespectively). The shapes of all input tensors should be\n(\nN\n,\nD\n)\n(N, D)\n(\nN\n,\nD\n)\n.\nThe distance swap is described in detail in the paper\nLearning shallow\nconvolutional feature descriptors with triplet losses\nby\nV. Balntas, E. Riba et al.\nThe loss function for each sample in the mini-batch is:\nL\n(\na\n,\np\n,\nn\n)\n=\nmax\n⁡\n{\nd\n(\na\ni\n,\np\ni\n)\n−\nd\n(\na\ni\n,\nn\ni\n)\n+\nm\na\nr\ng\ni\nn\n,\n0\n}\nL(a, p, n) = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\}\nL\n(\na\n,\np\n,\nn\n)\n=\nmax\n{\nd\n(\na\ni\n​\n,\np\ni\n​\n)\n−\nd\n(\na\ni\n​\n,\nn\ni\n​\n)\n+\nmargin\n,\n0\n}\nwhere\nd\n(\nx\ni\n,\ny\ni\n)\n=\n∥\nx\ni\n−\ny\ni\n∥\np\nd(x_i, y_i) = \\left\\lVert {\\bf x}_i - {\\bf y}_i \\right\\rVert_p\nd\n(\nx\ni\n​\n,\ny\ni\n​\n)\n=\n∥\nx\ni\n​\n−\ny\ni\n​\n∥\np\n​\nThe norm is calculated using the specified p value and a small constant\nε\n\\varepsilon\nε\nis\nadded for numerical stability.\nSee also\nTripletMarginWithDistanceLoss\n, which computes the\ntriplet margin loss for input tensors using a custom distance function.\nParameters\nmargin\n(\nfloat\n,\noptional\n) – Default:\n1\n1\n1\n.\np\n(\nint\n,\noptional\n) – The norm degree for pairwise distance. Default:\n2\n2\n2\n.\neps\n(\nfloat\n,\noptional\n) – Small constant for numerical stability. Default:\n1\ne\n−\n6\n1e-6\n1\ne\n−\n6\n.\nswap\n(\nbool\n,\noptional\n) – The distance swap is described in detail in the paper\nLearning shallow convolutional feature descriptors with triplet losses\nby\nV. Balntas, E. Riba et al. Default:\nFalse\n.\nsize_average\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field\nsize_average\nis set to\nFalse\n, the losses are instead summed for each minibatch. Ignored\nwhen\nreduce\nis\nFalse\n. Default:\nTrue\nreduce\n(\nbool\n,\noptional\n) – Deprecated (see\nreduction\n). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non\nsize_average\n. When\nreduce\nis\nFalse\n, returns a loss per\nbatch element instead and ignores\nsize_average\n. Default:\nTrue\nreduction\n(\nstr\n,\noptional\n) – Specifies the reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Note:\nsize_average\nand\nreduce\nare in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override\nreduction\n. Default:\n'mean'\nShape:\nInput:\n(\nN\n,\nD\n)\n(N, D)\n(\nN\n,\nD\n)\nor\n(\nD\n)\n(D)\n(\nD\n)\nwhere\nD\nD\nD\nis the vector dimension.\nOutput: A Tensor of shape\n(\nN\n)\n(N)\n(\nN\n)\nif\nreduction\nis\n'none'\nand\ninput shape is\n(\nN\n,\nD\n)\n(N, D)\n(\nN\n,\nD\n)\n; a scalar otherwise.\nExamples:\n>>>\ntriplet_loss\n=\nnn\n.\nTripletMarginLoss\n(\nmargin\n=\n1.0\n,\np\n=\n2\n,\neps\n=\n1e-7\n)\n>>>\nanchor\n=\ntorch\n.\nrandn\n(\n100\n,\n128\n,\nrequires_grad\n=\nTrue\n)\n>>>\npositive\n=\ntorch\n.\nrandn\n(\n100\n,\n128\n,\nrequires_grad\n=\nTrue\n)\n>>>\nnegative\n=\ntorch\n.\nrandn\n(\n100\n,\n128\n,\nrequires_grad\n=\nTrue\n)\n>>>\noutput\n=\ntriplet_loss\n(\nanchor\n,\npositive\n,\nnegative\n)\n>>>\noutput\n.\nbackward\n()\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html#tripletmarginloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#TripletMarginLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1589",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html#torch.nn.TripletMarginLoss",
    "https://bmva-archive.org.uk/bmvc/2016/papers/paper119/index.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginWithDistanceLoss.html#torch.nn.TripletMarginWithDistanceLoss",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginWithDistanceLoss.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.MultiMarginLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.TripletMarginWithDistanceLoss",
  "page_text": "TripletMarginWithDistanceLoss\n¶\nclass\ntorch.nn.\nTripletMarginWithDistanceLoss\n(\n*\n,\ndistance_function\n=\nNone\n,\nmargin\n=\n1.0\n,\nswap\n=\nFalse\n,\nreduction\n=\n'mean'\n)\n[source]\n[source]\n¶\nCreates a criterion that measures the triplet loss given input\ntensors\na\na\na\n,\np\np\np\n, and\nn\nn\nn\n(representing anchor,\npositive, and negative examples, respectively), and a nonnegative,\nreal-valued function (“distance function”) used to compute the relationship\nbetween the anchor and positive example (“positive distance”) and the\nanchor and negative example (“negative distance”).\nThe unreduced loss (i.e., with\nreduction\nset to\n'none'\n)\ncan be described as:\nℓ\n(\na\n,\np\n,\nn\n)\n=\nL\n=\n{\nl\n1\n,\n…\n,\nl\nN\n}\n⊤\n,\nl\ni\n=\nmax\n⁡\n{\nd\n(\na\ni\n,\np\ni\n)\n−\nd\n(\na\ni\n,\nn\ni\n)\n+\nm\na\nr\ng\ni\nn\n,\n0\n}\n\\ell(a, p, n) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\nl_i = \\max \\{d(a_i, p_i) - d(a_i, n_i) + {\\rm margin}, 0\\}\nℓ\n(\na\n,\np\n,\nn\n)\n=\nL\n=\n{\nl\n1\n​\n,\n…\n,\nl\nN\n​\n}\n⊤\n,\nl\ni\n​\n=\nmax\n{\nd\n(\na\ni\n​\n,\np\ni\n​\n)\n−\nd\n(\na\ni\n​\n,\nn\ni\n​\n)\n+\nmargin\n,\n0\n}\nwhere\nN\nN\nN\nis the batch size;\nd\nd\nd\nis a nonnegative, real-valued function\nquantifying the closeness of two tensors, referred to as the\ndistance_function\n;\nand\nm\na\nr\ng\ni\nn\nmargin\nma\nr\ng\nin\nis a nonnegative margin representing the minimum difference\nbetween the positive and negative distances that is required for the loss to\nbe 0.  The input tensors have\nN\nN\nN\nelements each and can be of any shape\nthat the distance function can handle.\nIf\nreduction\nis not\n'none'\n(default\n'mean'\n), then:\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘mean’;\nsum\n⁡\n(\nL\n)\n,\nif reduction\n=\n‘sum’.\n\\ell(x, y) =\n\\begin{cases}\n    \\operatorname{mean}(L), &  \\text{if reduction} = \\text{`mean';}\\\\\n    \\operatorname{sum}(L),  &  \\text{if reduction} = \\text{`sum'.}\n\\end{cases}\nℓ\n(\nx\n,\ny\n)\n=\n{\nmean\n(\nL\n)\n,\nsum\n(\nL\n)\n,\n​\nif reduction\n=\n‘mean’;\nif reduction\n=\n‘sum’.\n​\nSee also\nTripletMarginLoss\n, which computes the triplet\nloss for input tensors using the\nl\np\nl_p\nl\np\n​\ndistance as the distance function.\nParameters\ndistance_function\n(\nCallable\n,\noptional\n) – A nonnegative, real-valued function that\nquantifies the closeness of two tensors. If not specified,\nnn.PairwiseDistance\nwill be used.  Default:\nNone\nmargin\n(\nfloat\n,\noptional\n) – A nonnegative margin representing the minimum difference\nbetween the positive and negative distances required for the loss to be 0. Larger\nmargins penalize cases where the negative examples are not distant enough from the\nanchors, relative to the positives. Default:\n1\n1\n1\n.\nswap\n(\nbool\n,\noptional\n) – Whether to use the distance swap described in the paper\nLearning shallow convolutional feature descriptors with triplet losses\nby\nV. Balntas, E. Riba et al. If True, and if the positive example is closer to the\nnegative example than the anchor is, swaps the positive example and the anchor in\nthe loss computation. Default:\nFalse\n.\nreduction\n(\nstr\n,\noptional\n) – Specifies the (optional) reduction to apply to the output:\n'none'\n|\n'mean'\n|\n'sum'\n.\n'none'\n: no reduction will be applied,\n'mean'\n: the sum of the output will be divided by the number of\nelements in the output,\n'sum'\n: the output will be summed. Default:\n'mean'\nShape:\nInput:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\nwhere\n∗\n*\n∗\nrepresents any number of additional dimensions\nas supported by the distance function.\nOutput: A Tensor of shape\n(\nN\n)\n(N)\n(\nN\n)\nif\nreduction\nis\n'none'\n, or a scalar\notherwise.\nExamples:\n>>>\n# Initialize embeddings\n>>>\nembedding\n=\nnn\n.\nEmbedding\n(\n1000\n,\n128\n)\n>>>\nanchor_ids\n=\ntorch\n.\nrandint\n(\n0\n,\n1000\n,\n(\n1\n,))\n>>>\npositive_ids\n=\ntorch\n.\nrandint\n(\n0\n,\n1000\n,\n(\n1\n,))\n>>>\nnegative_ids\n=\ntorch\n.\nrandint\n(\n0\n,\n1000\n,\n(\n1\n,))\n>>>\nanchor\n=\nembedding\n(\nanchor_ids\n)\n>>>\npositive\n=\nembedding\n(\npositive_ids\n)\n>>>\nnegative\n=\nembedding\n(\nnegative_ids\n)\n>>>\n>>>\n# Built-in Distance Function\n>>>\ntriplet_loss\n=\n\\\n>>>\nnn\n.\nTripletMarginWithDistanceLoss\n(\ndistance_function\n=\nnn\n.\nPairwiseDistance\n())\n>>>\noutput\n=\ntriplet_loss\n(\nanchor\n,\npositive\n,\nnegative\n)\n>>>\noutput\n.\nbackward\n()\n>>>\n>>>\n# Custom Distance Function\n>>>\ndef\nl_infinity\n(\nx1\n,\nx2\n):\n>>>\nreturn\ntorch\n.\nmax\n(\ntorch\n.\nabs\n(\nx1\n-\nx2\n),\ndim\n=\n1\n)\n.\nvalues\n>>>\n>>>\ntriplet_loss\n=\n(\n>>>\nnn\n.\nTripletMarginWithDistanceLoss\n(\ndistance_function\n=\nl_infinity\n,\nmargin\n=\n1.5\n))\n>>>\noutput\n=\ntriplet_loss\n(\nanchor\n,\npositive\n,\nnegative\n)\n>>>\noutput\n.\nbackward\n()\n>>>\n>>>\n# Custom Distance Function (Lambda)\n>>>\ntriplet_loss\n=\n(\n>>>\nnn\n.\nTripletMarginWithDistanceLoss\n(\n>>>\ndistance_function\n=\nlambda\nx\n,\ny\n:\n1.0\n-\nF\n.\ncosine_similarity\n(\nx\n,\ny\n)))\n>>>\noutput\n=\ntriplet_loss\n(\nanchor\n,\npositive\n,\nnegative\n)\n>>>\noutput\n.\nbackward\n()\nReference:\nV. Balntas, et al.: Learning shallow convolutional feature descriptors with triplet losses:\nhttps://bmva-archive.org.uk/bmvc/2016/papers/paper119/index.html\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginWithDistanceLoss.html#tripletmarginwithdistanceloss",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#TripletMarginWithDistanceLoss",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/loss.py#L1697",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginWithDistanceLoss.html#torch.nn.TripletMarginWithDistanceLoss",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html#torch.nn.TripletMarginLoss",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://bmva-archive.org.uk/bmvc/2016/papers/paper119/index.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.PixelShuffle",
  "page_text": "PixelShuffle\n¶\nclass\ntorch.nn.\nPixelShuffle\n(\nupscale_factor\n)\n[source]\n[source]\n¶\nRearrange elements in a tensor according to an upscaling factor.\nRearranges elements in a tensor of shape\n(\n∗\n,\nC\n×\nr\n2\n,\nH\n,\nW\n)\n(*, C \\times r^2, H, W)\n(\n∗\n,\nC\n×\nr\n2\n,\nH\n,\nW\n)\nto a tensor of shape\n(\n∗\n,\nC\n,\nH\n×\nr\n,\nW\n×\nr\n)\n(*, C, H \\times r, W \\times r)\n(\n∗\n,\nC\n,\nH\n×\nr\n,\nW\n×\nr\n)\n, where r is an upscale factor.\nThis is useful for implementing efficient sub-pixel convolution\nwith a stride of\n1\n/\nr\n1/r\n1/\nr\n.\nSee the paper:\nReal-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\nby Shi et al. (2016) for more details.\nParameters\nupscale_factor\n(\nint\n) – factor to increase spatial resolution by\nShape:\nInput:\n(\n∗\n,\nC\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(*, C_{in}, H_{in}, W_{in})\n(\n∗\n,\nC\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n, where * is zero or more batch dimensions\nOutput:\n(\n∗\n,\nC\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(*, C_{out}, H_{out}, W_{out})\n(\n∗\n,\nC\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nC\no\nu\nt\n=\nC\ni\nn\n÷\nupscale_factor\n2\nC_{out} = C_{in} \\div \\text{upscale\\_factor}^2\nC\no\nu\nt\n​\n=\nC\nin\n​\n÷\nupscale_factor\n2\nH\no\nu\nt\n=\nH\ni\nn\n×\nupscale_factor\nH_{out} = H_{in} \\times \\text{upscale\\_factor}\nH\no\nu\nt\n​\n=\nH\nin\n​\n×\nupscale_factor\nW\no\nu\nt\n=\nW\ni\nn\n×\nupscale_factor\nW_{out} = W_{in} \\times \\text{upscale\\_factor}\nW\no\nu\nt\n​\n=\nW\nin\n​\n×\nupscale_factor\nExamples:\n>>>\npixel_shuffle\n=\nnn\n.\nPixelShuffle\n(\n3\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n9\n,\n4\n,\n4\n)\n>>>\noutput\n=\npixel_shuffle\n(\ninput\n)\n>>>\nprint\n(\noutput\n.\nsize\n())\ntorch.Size([1, 1, 12, 12])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html#pixelshuffle",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pixelshuffle.html#PixelShuffle",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pixelshuffle.py#L10",
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html#torch.nn.PixelShuffle",
    "https://arxiv.org/abs/1609.05158",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelUnshuffle.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginWithDistanceLoss.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.PixelUnshuffle",
  "page_text": "PixelUnshuffle\n¶\nclass\ntorch.nn.\nPixelUnshuffle\n(\ndownscale_factor\n)\n[source]\n[source]\n¶\nReverse the PixelShuffle operation.\nReverses the\nPixelShuffle\noperation by rearranging elements\nin a tensor of shape\n(\n∗\n,\nC\n,\nH\n×\nr\n,\nW\n×\nr\n)\n(*, C, H \\times r, W \\times r)\n(\n∗\n,\nC\n,\nH\n×\nr\n,\nW\n×\nr\n)\nto a tensor of shape\n(\n∗\n,\nC\n×\nr\n2\n,\nH\n,\nW\n)\n(*, C \\times r^2, H, W)\n(\n∗\n,\nC\n×\nr\n2\n,\nH\n,\nW\n)\n, where r is a downscale factor.\nSee the paper:\nReal-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\nby Shi et al. (2016) for more details.\nParameters\ndownscale_factor\n(\nint\n) – factor to decrease spatial resolution by\nShape:\nInput:\n(\n∗\n,\nC\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(*, C_{in}, H_{in}, W_{in})\n(\n∗\n,\nC\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\n, where * is zero or more batch dimensions\nOutput:\n(\n∗\n,\nC\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(*, C_{out}, H_{out}, W_{out})\n(\n∗\n,\nC\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nC\no\nu\nt\n=\nC\ni\nn\n×\ndownscale_factor\n2\nC_{out} = C_{in} \\times \\text{downscale\\_factor}^2\nC\no\nu\nt\n​\n=\nC\nin\n​\n×\ndownscale_factor\n2\nH\no\nu\nt\n=\nH\ni\nn\n÷\ndownscale_factor\nH_{out} = H_{in} \\div \\text{downscale\\_factor}\nH\no\nu\nt\n​\n=\nH\nin\n​\n÷\ndownscale_factor\nW\no\nu\nt\n=\nW\ni\nn\n÷\ndownscale_factor\nW_{out} = W_{in} \\div \\text{downscale\\_factor}\nW\no\nu\nt\n​\n=\nW\nin\n​\n÷\ndownscale_factor\nExamples:\n>>>\npixel_unshuffle\n=\nnn\n.\nPixelUnshuffle\n(\n3\n)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n1\n,\n1\n,\n12\n,\n12\n)\n>>>\noutput\n=\npixel_unshuffle\n(\ninput\n)\n>>>\nprint\n(\noutput\n.\nsize\n())\ntorch.Size([1, 9, 4, 4])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelUnshuffle.html#pixelunshuffle",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/pixelshuffle.html#PixelUnshuffle",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/pixelshuffle.py#L65",
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelUnshuffle.html#torch.nn.PixelUnshuffle",
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html#torch.nn.PixelShuffle",
    "https://arxiv.org/abs/1609.05158",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Upsample",
  "page_text": "Upsample\n¶\nclass\ntorch.nn.\nUpsample\n(\nsize\n=\nNone\n,\nscale_factor\n=\nNone\n,\nmode\n=\n'nearest'\n,\nalign_corners\n=\nNone\n,\nrecompute_scale_factor\n=\nNone\n)\n[source]\n[source]\n¶\nUpsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.\nThe input data is assumed to be of the form\nminibatch x channels x [optional depth] x [optional height] x width\n.\nHence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.\nThe algorithms available for upsampling are nearest neighbor and linear,\nbilinear, bicubic and trilinear for 3D, 4D and 5D input Tensor,\nrespectively.\nOne can either give a\nscale_factor\nor the target output\nsize\nto\ncalculate the output size. (You cannot give both, as it is ambiguous)\nParameters\nsize\n(\nint\nor\nTuple\n[\nint\n] or\nTuple\n[\nint\n,\nint\n] or\nTuple\n[\nint\n,\nint\n,\nint\n]\n,\noptional\n) – output spatial sizes\nscale_factor\n(\nfloat\nor\nTuple\n[\nfloat\n] or\nTuple\n[\nfloat\n,\nfloat\n] or\nTuple\n[\nfloat\n,\nfloat\n,\nfloat\n]\n,\noptional\n) – multiplier for spatial size. Has to match input size if it is a tuple.\nmode\n(\nstr\n,\noptional\n) – the upsampling algorithm: one of\n'nearest'\n,\n'linear'\n,\n'bilinear'\n,\n'bicubic'\nand\n'trilinear'\n.\nDefault:\n'nearest'\nalign_corners\n(\nbool\n,\noptional\n) – if\nTrue\n, the corner pixels of the input\nand output tensors are aligned, and thus preserving the values at\nthose pixels. This only has effect when\nmode\nis\n'linear'\n,\n'bilinear'\n,\n'bicubic'\n, or\n'trilinear'\n.\nDefault:\nFalse\nrecompute_scale_factor\n(\nbool\n,\noptional\n) – recompute the scale_factor for use in the\ninterpolation calculation. If\nrecompute_scale_factor\nis\nTrue\n, then\nscale_factor\nmust be passed in and\nscale_factor\nis used to compute the\noutput\nsize\n. The computed output\nsize\nwill be used to infer new scales for\nthe interpolation. Note that when\nscale_factor\nis floating-point, it may differ\nfrom the recomputed\nscale_factor\ndue to rounding and precision issues.\nIf\nrecompute_scale_factor\nis\nFalse\n, then\nsize\nor\nscale_factor\nwill\nbe used directly for interpolation.\nShape:\nInput:\n(\nN\n,\nC\n,\nW\ni\nn\n)\n(N, C, W_{in})\n(\nN\n,\nC\n,\nW\nin\n​\n)\n,\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nor\n(\nN\n,\nC\n,\nD\ni\nn\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, D_{in}, H_{in}, W_{in})\n(\nN\n,\nC\n,\nD\nin\n​\n,\nH\nin\n​\n,\nW\nin\n​\n)\nOutput:\n(\nN\n,\nC\n,\nW\no\nu\nt\n)\n(N, C, W_{out})\n(\nN\n,\nC\n,\nW\no\nu\nt\n​\n)\n,\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nor\n(\nN\n,\nC\n,\nD\no\nu\nt\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, D_{out}, H_{out}, W_{out})\n(\nN\n,\nC\n,\nD\no\nu\nt\n​\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\n, where\nD\no\nu\nt\n=\n⌊\nD\ni\nn\n×\nscale_factor\n⌋\nD_{out} = \\left\\lfloor D_{in} \\times \\text{scale\\_factor} \\right\\rfloor\nD\no\nu\nt\n​\n=\n⌊\nD\nin\n​\n×\nscale_factor\n⌋\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n×\nscale_factor\n⌋\nH_{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nH\nin\n​\n×\nscale_factor\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n×\nscale_factor\n⌋\nW_{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nW\nin\n​\n×\nscale_factor\n⌋\nWarning\nWith\nalign_corners\n=\nTrue\n, the linearly interpolating modes\n(\nlinear\n,\nbilinear\n,\nbicubic\n, and\ntrilinear\n) don’t proportionally\nalign the output and input pixels, and thus the output values can depend\non the input size. This was the default behavior for these modes up to\nversion 0.3.1. Since then, the default behavior is\nalign_corners\n=\nFalse\n. See below for concrete examples on how this\naffects the outputs.\nNote\nIf you want downsampling/general resizing, you should use\ninterpolate()\n.\nExamples:\n>>>\ninput\n=\ntorch\n.\narange\n(\n1\n,\n5\n,\ndtype\n=\ntorch\n.\nfloat32\n)\n.\nview\n(\n1\n,\n1\n,\n2\n,\n2\n)\n>>>\ninput\ntensor([[[[1., 2.],\n[3., 4.]]]])\n>>>\nm\n=\nnn\n.\nUpsample\n(\nscale_factor\n=\n2\n,\nmode\n=\n'nearest'\n)\n>>>\nm\n(\ninput\n)\ntensor([[[[1., 1., 2., 2.],\n[1., 1., 2., 2.],\n[3., 3., 4., 4.],\n[3., 3., 4., 4.]]]])\n>>>\nm\n=\nnn\n.\nUpsample\n(\nscale_factor\n=\n2\n,\nmode\n=\n'bilinear'\n)\n# align_corners=False\n>>>\nm\n(\ninput\n)\ntensor([[[[1.0000, 1.2500, 1.7500, 2.0000],\n[1.5000, 1.7500, 2.2500, 2.5000],\n[2.5000, 2.7500, 3.2500, 3.5000],\n[3.0000, 3.2500, 3.7500, 4.0000]]]])\n>>>\nm\n=\nnn\n.\nUpsample\n(\nscale_factor\n=\n2\n,\nmode\n=\n'bilinear'\n,\nalign_corners\n=\nTrue\n)\n>>>\nm\n(\ninput\n)\ntensor([[[[1.0000, 1.3333, 1.6667, 2.0000],\n[1.6667, 2.0000, 2.3333, 2.6667],\n[2.3333, 2.6667, 3.0000, 3.3333],\n[3.0000, 3.3333, 3.6667, 4.0000]]]])\n>>>\n# Try scaling the same data in a larger tensor\n>>>\ninput_3x3\n=\ntorch\n.\nzeros\n(\n3\n,\n3\n)\n.\nview\n(\n1\n,\n1\n,\n3\n,\n3\n)\n>>>\ninput_3x3\n[:,\n:,\n:\n2\n,\n:\n2\n]\n.\ncopy_\n(\ninput\n)\ntensor([[[[1., 2.],\n[3., 4.]]]])\n>>>\ninput_3x3\ntensor([[[[1., 2., 0.],\n[3., 4., 0.],\n[0., 0., 0.]]]])\n>>>\nm\n=\nnn\n.\nUpsample\n(\nscale_factor\n=\n2\n,\nmode\n=\n'bilinear'\n)\n# align_corners=False\n>>>\n# Notice that values in top left corner are the same with the small input (except at boundary)\n>>>\nm\n(\ninput_3x3\n)\ntensor([[[[1.0000, 1.2500, 1.7500, 1.5000, 0.5000, 0.0000],\n[1.5000, 1.7500, 2.2500, 1.8750, 0.6250, 0.0000],\n[2.5000, 2.7500, 3.2500, 2.6250, 0.8750, 0.0000],\n[2.2500, 2.4375, 2.8125, 2.2500, 0.7500, 0.0000],\n[0.7500, 0.8125, 0.9375, 0.7500, 0.2500, 0.0000],\n[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n>>>\nm\n=\nnn\n.\nUpsample\n(\nscale_factor\n=\n2\n,\nmode\n=\n'bilinear'\n,\nalign_corners\n=\nTrue\n)\n>>>\n# Notice that values in top left corner are now changed\n>>>\nm\n(\ninput_3x3\n)\ntensor([[[[1.0000, 1.4000, 1.8000, 1.6000, 0.8000, 0.0000],\n[1.8000, 2.2000, 2.6000, 2.2400, 1.1200, 0.0000],\n[2.6000, 3.0000, 3.4000, 2.8800, 1.4400, 0.0000],\n[2.4000, 2.7200, 3.0400, 2.5600, 1.2800, 0.0000],\n[1.2000, 1.3600, 1.5200, 1.2800, 0.6400, 0.0000],\n[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html#upsample",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/upsampling.html#Upsample",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/upsampling.py#L14",
    "https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html#torch.nn.Upsample",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingNearest2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.PixelUnshuffle.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.UpsamplingNearest2d",
  "page_text": "UpsamplingNearest2d\n¶\nclass\ntorch.nn.\nUpsamplingNearest2d\n(\nsize\n=\nNone\n,\nscale_factor\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 2D nearest neighbor upsampling to an input signal composed of several input channels.\nTo specify the scale, it takes either the\nsize\nor the\nscale_factor\nas it’s constructor argument.\nWhen\nsize\nis given, it is the output size of the image\n(h, w)\n.\nParameters\nsize\n(\nint\nor\nTuple\n[\nint\n,\nint\n]\n,\noptional\n) – output spatial sizes\nscale_factor\n(\nfloat\nor\nTuple\n[\nfloat\n,\nfloat\n]\n,\noptional\n) – multiplier for\nspatial size.\nWarning\nThis class is deprecated in favor of\ninterpolate()\n.\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nwhere\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n×\nscale_factor\n⌋\nH_{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nH\nin\n​\n×\nscale_factor\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n×\nscale_factor\n⌋\nW_{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nW\nin\n​\n×\nscale_factor\n⌋\nExamples:\n>>>\ninput\n=\ntorch\n.\narange\n(\n1\n,\n5\n,\ndtype\n=\ntorch\n.\nfloat32\n)\n.\nview\n(\n1\n,\n1\n,\n2\n,\n2\n)\n>>>\ninput\ntensor([[[[1., 2.],\n[3., 4.]]]])\n>>>\nm\n=\nnn\n.\nUpsamplingNearest2d\n(\nscale_factor\n=\n2\n)\n>>>\nm\n(\ninput\n)\ntensor([[[[1., 1., 2., 2.],\n[1., 1., 2., 2.],\n[3., 3., 4., 4.],\n[3., 3., 4., 4.]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingNearest2d.html#upsamplingnearest2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/upsampling.html#UpsamplingNearest2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/upsampling.py#L196",
    "https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingNearest2d.html#torch.nn.UpsamplingNearest2d",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingBilinear2d.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.UpsamplingBilinear2d",
  "page_text": "UpsamplingBilinear2d\n¶\nclass\ntorch.nn.\nUpsamplingBilinear2d\n(\nsize\n=\nNone\n,\nscale_factor\n=\nNone\n)\n[source]\n[source]\n¶\nApplies a 2D bilinear upsampling to an input signal composed of several input channels.\nTo specify the scale, it takes either the\nsize\nor the\nscale_factor\nas it’s constructor argument.\nWhen\nsize\nis given, it is the output size of the image\n(h, w)\n.\nParameters\nsize\n(\nint\nor\nTuple\n[\nint\n,\nint\n]\n,\noptional\n) – output spatial sizes\nscale_factor\n(\nfloat\nor\nTuple\n[\nfloat\n,\nfloat\n]\n,\noptional\n) – multiplier for\nspatial size.\nWarning\nThis class is deprecated in favor of\ninterpolate()\n. It is\nequivalent to\nnn.functional.interpolate(...,\nmode='bilinear',\nalign_corners=True)\n.\nShape:\nInput:\n(\nN\n,\nC\n,\nH\ni\nn\n,\nW\ni\nn\n)\n(N, C, H_{in}, W_{in})\n(\nN\n,\nC\n,\nH\nin\n​\n,\nW\nin\n​\n)\nOutput:\n(\nN\n,\nC\n,\nH\no\nu\nt\n,\nW\no\nu\nt\n)\n(N, C, H_{out}, W_{out})\n(\nN\n,\nC\n,\nH\no\nu\nt\n​\n,\nW\no\nu\nt\n​\n)\nwhere\nH\no\nu\nt\n=\n⌊\nH\ni\nn\n×\nscale_factor\n⌋\nH_{out} = \\left\\lfloor H_{in} \\times \\text{scale\\_factor} \\right\\rfloor\nH\no\nu\nt\n​\n=\n⌊\nH\nin\n​\n×\nscale_factor\n⌋\nW\no\nu\nt\n=\n⌊\nW\ni\nn\n×\nscale_factor\n⌋\nW_{out} = \\left\\lfloor W_{in} \\times \\text{scale\\_factor} \\right\\rfloor\nW\no\nu\nt\n​\n=\n⌊\nW\nin\n​\n×\nscale_factor\n⌋\nExamples:\n>>>\ninput\n=\ntorch\n.\narange\n(\n1\n,\n5\n,\ndtype\n=\ntorch\n.\nfloat32\n)\n.\nview\n(\n1\n,\n1\n,\n2\n,\n2\n)\n>>>\ninput\ntensor([[[[1., 2.],\n[3., 4.]]]])\n>>>\nm\n=\nnn\n.\nUpsamplingBilinear2d\n(\nscale_factor\n=\n2\n)\n>>>\nm\n(\ninput\n)\ntensor([[[[1.0000, 1.3333, 1.6667, 2.0000],\n[1.6667, 2.0000, 2.3333, 2.6667],\n[2.3333, 2.6667, 3.0000, 3.3333],\n[3.0000, 3.3333, 3.6667, 4.0000]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingBilinear2d.html#upsamplingbilinear2d",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/upsampling.html#UpsamplingBilinear2d",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/upsampling.py#L245",
    "https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingBilinear2d.html#torch.nn.UpsamplingBilinear2d",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.ChannelShuffle.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingNearest2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.ChannelShuffle",
  "page_text": "ChannelShuffle\n¶\nclass\ntorch.nn.\nChannelShuffle\n(\ngroups\n)\n[source]\n[source]\n¶\nDivides and rearranges the channels in a tensor.\nThis operation divides the channels in a tensor of shape\n(\nN\n,\nC\n,\n∗\n)\n(N, C, *)\n(\nN\n,\nC\n,\n∗\n)\ninto g groups as\n(\nN\n,\nC\ng\n,\ng\n,\n∗\n)\n(N, \\frac{C}{g}, g, *)\n(\nN\n,\ng\nC\n​\n,\ng\n,\n∗\n)\nand shuffles them,\nwhile retaining the original tensor shape in the final output.\nParameters\ngroups\n(\nint\n) – number of groups to divide channels in.\nExamples:\n>>>\nchannel_shuffle\n=\nnn\n.\nChannelShuffle\n(\n2\n)\n>>>\ninput\n=\ntorch\n.\narange\n(\n1\n,\n17\n,\ndtype\n=\ntorch\n.\nfloat32\n)\n.\nview\n(\n1\n,\n4\n,\n2\n,\n2\n)\n>>>\ninput\ntensor([[[[ 1.,  2.],\n[ 3.,  4.]],\n[[ 5.,  6.],\n[ 7.,  8.]],\n[[ 9., 10.],\n[11., 12.]],\n[[13., 14.],\n[15., 16.]]]])\n>>>\noutput\n=\nchannel_shuffle\n(\ninput\n)\n>>>\noutput\ntensor([[[[ 1.,  2.],\n[ 3.,  4.]],\n[[ 9., 10.],\n[11., 12.]],\n[[ 5.,  6.],\n[ 7.,  8.]],\n[[13., 14.],\n[15., 16.]]]])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.ChannelShuffle.html#channelshuffle",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/channelshuffle.html#ChannelShuffle",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/channelshuffle.py#L10",
    "https://pytorch.org/docs/stable/generated/torch.nn.ChannelShuffle.html#torch.nn.ChannelShuffle",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingBilinear2d.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.DataParallel",
  "page_text": "DataParallel\n¶\nclass\ntorch.nn.\nDataParallel\n(\nmodule\n,\ndevice_ids\n=\nNone\n,\noutput_device\n=\nNone\n,\ndim\n=\n0\n)\n[source]\n[source]\n¶\nImplements data parallelism at the module level.\nThis container parallelizes the application of the given\nmodule\nby\nsplitting the input across the specified devices by chunking in the batch\ndimension (other objects will be copied once per device). In the forward\npass, the module is replicated on each device, and each replica handles a\nportion of the input. During the backwards pass, gradients from each replica\nare summed into the original module.\nThe batch size should be larger than the number of GPUs used.\nWarning\nIt is recommended to use\nDistributedDataParallel\n,\ninstead of this class, to do multi-GPU training, even if there is only a single\nnode. See:\nUse nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel\nand\nDistributed Data Parallel\n.\nArbitrary positional and keyword inputs are allowed to be passed into\nDataParallel but some types are specially handled. tensors will be\nscattered\non dim specified (default 0). tuple, list and dict types will\nbe shallow copied. The other types will be shared among different threads\nand can be corrupted if written to in the model’s forward pass.\nThe parallelized\nmodule\nmust have its parameters and buffers on\ndevice_ids[0]\nbefore running this\nDataParallel\nmodule.\nWarning\nIn each forward,\nmodule\nis\nreplicated\non each device, so any\nupdates to the running module in\nforward\nwill be lost. For example,\nif\nmodule\nhas a counter attribute that is incremented in each\nforward\n, it will always stay at the initial value because the update\nis done on the replicas which are destroyed after\nforward\n. However,\nDataParallel\nguarantees that the replica on\ndevice[0]\nwill have its parameters and buffers sharing storage with\nthe base parallelized\nmodule\n. So\nin-place\nupdates to the\nparameters or buffers on\ndevice[0]\nwill be recorded. E.g.,\nBatchNorm2d\nand\nspectral_norm()\nrely on this behavior to update the buffers.\nWarning\nForward and backward hooks defined on\nmodule\nand its submodules\nwill be invoked\nlen(device_ids)\ntimes, each with inputs located on\na particular device. Particularly, the hooks are only guaranteed to be\nexecuted in correct order with respect to operations on corresponding\ndevices. For example, it is not guaranteed that hooks set via\nregister_forward_pre_hook()\nbe executed before\nall\nlen(device_ids)\nforward()\ncalls, but\nthat each such hook be executed before the corresponding\nforward()\ncall of that device.\nWarning\nWhen\nmodule\nreturns a scalar (i.e., 0-dimensional tensor) in\nforward()\n, this wrapper will return a vector of length equal to\nnumber of devices used in data parallelism, containing the result from\neach device.\nNote\nThere is a subtlety in using the\npack\nsequence\n->\nrecurrent\nnetwork\n->\nunpack\nsequence\npattern in a\nModule\nwrapped in\nDataParallel\n.\nSee\nMy recurrent network doesn’t work with data parallelism\nsection in FAQ for\ndetails.\nParameters\nmodule\n(\nModule\n) – module to be parallelized\ndevice_ids\n(\nlist\nof\nint\nor\ntorch.device\n) – CUDA devices (default: all devices)\noutput_device\n(\nint\nor\ntorch.device\n) – device location of output (default: device_ids[0])\nVariables\nmodule\n(\nModule\n) – the module to be parallelized\nExample:\n>>>\nnet\n=\ntorch\n.\nnn\n.\nDataParallel\n(\nmodel\n,\ndevice_ids\n=\n[\n0\n,\n1\n,\n2\n])\n>>>\noutput\n=\nnet\n(\ninput_var\n)\n# input_var can be on any device, including CPU\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#dataparallel",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parallel/data_parallel.html#DataParallel",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parallel/data_parallel.py#L52",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel",
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel",
    "https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead",
    "https://pytorch.org/docs/stable/notes/ddp.html#ddp",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel",
    "https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.spectral_norm.html#torch.nn.utils.spectral_norm",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_forward_pre_hook",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel",
    "https://pytorch.org/docs/stable/notes/faq.html#pack-rnn-unpack-with-data-parallelism",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.ChannelShuffle.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.parallel.DistributedDataParallel",
  "page_text": "DistributedDataParallel\n¶\nclass\ntorch.nn.parallel.\nDistributedDataParallel\n(\nmodule\n,\ndevice_ids\n=\nNone\n,\noutput_device\n=\nNone\n,\ndim\n=\n0\n,\nbroadcast_buffers\n=\nTrue\n,\nprocess_group\n=\nNone\n,\nbucket_cap_mb\n=\nNone\n,\nfind_unused_parameters\n=\nFalse\n,\ncheck_reduction\n=\nFalse\n,\ngradient_as_bucket_view\n=\nFalse\n,\nstatic_graph\n=\nFalse\n,\ndelay_all_reduce_named_params\n=\nNone\n,\nparam_to_hook_all_reduce\n=\nNone\n,\nmixed_precision\n=\nNone\n,\ndevice_mesh\n=\nNone\n)\n[source]\n[source]\n¶\nImplement distributed data parallelism based on\ntorch.distributed\nat module level.\nThis container provides data parallelism by synchronizing gradients\nacross each model replica. The devices to synchronize across are\nspecified by the input\nprocess_group\n, which is the entire world\nby default. Note that\nDistributedDataParallel\ndoes not chunk or\notherwise shard the input across participating GPUs; the user is\nresponsible for defining how to do so, for example through the use\nof a\nDistributedSampler\n.\nSee also:\nBasics\nand\nUse nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel\n.\nThe same constraints on input as in\ntorch.nn.DataParallel\napply.\nCreation of this class requires that\ntorch.distributed\nto be already\ninitialized, by calling\ntorch.distributed.init_process_group()\n.\nDistributedDataParallel\nis proven to be significantly faster than\ntorch.nn.DataParallel\nfor single-node multi-GPU data\nparallel training.\nTo use\nDistributedDataParallel\non a host with N GPUs, you should spawn\nup\nN\nprocesses, ensuring that each process exclusively works on a single\nGPU from 0 to N-1. This can be done by either setting\nCUDA_VISIBLE_DEVICES\nfor every process or by calling:\n>>>\ntorch\n.\ncuda\n.\nset_device\n(\ni\n)\nwhere i is from 0 to N-1. In each process, you should refer the following\nto construct this module:\n>>>\ntorch\n.\ndistributed\n.\ninit_process_group\n(\n>>>\nbackend\n=\n'nccl'\n,\nworld_size\n=\nN\n,\ninit_method\n=\n'...'\n>>>\n)\n>>>\nmodel\n=\nDistributedDataParallel\n(\nmodel\n,\ndevice_ids\n=\n[\ni\n],\noutput_device\n=\ni\n)\nIn order to spawn up multiple processes per node, you can use either\ntorch.distributed.launch\nor\ntorch.multiprocessing.spawn\n.\nNote\nPlease refer to\nPyTorch Distributed Overview\nfor a brief introduction to all features related to distributed training.\nNote\nDistributedDataParallel\ncan be used in conjunction with\ntorch.distributed.optim.ZeroRedundancyOptimizer\nto reduce\nper-rank optimizer states memory footprint. Please refer to\nZeroRedundancyOptimizer recipe\nfor more details.\nNote\nnccl\nbackend is currently the fastest and highly recommended\nbackend when using GPUs. This applies to both single-node and\nmulti-node distributed training.\nNote\nThis module also supports mixed-precision distributed training.\nThis means that your model can have different types of parameters such\nas mixed types of\nfp16\nand\nfp32\n, the gradient reduction on these\nmixed types of parameters will just work fine.\nNote\nIf you use\ntorch.save\non one process to checkpoint the module,\nand\ntorch.load\non some other processes to recover it, make sure that\nmap_location\nis configured properly for every process. Without\nmap_location\n,\ntorch.load\nwould recover the module to devices\nwhere the module was saved from.\nNote\nWhen a model is trained on\nM\nnodes with\nbatch=N\n, the\ngradient will be\nM\ntimes smaller when compared to the same model\ntrained on a single node with\nbatch=M*N\nif the loss is summed (NOT\naveraged as usual) across instances in a batch (because the gradients\nbetween different nodes are averaged). You should take this into\nconsideration when you want to obtain a mathematically equivalent\ntraining process compared to the local training counterpart. But in most\ncases, you can just treat a DistributedDataParallel wrapped model, a\nDataParallel wrapped model and an ordinary model on a single GPU as the\nsame (E.g. using the same learning rate for equivalent batch size).\nNote\nParameters are never broadcast between processes. The module performs\nan all-reduce step on gradients and assumes that they will be modified\nby the optimizer in all processes in the same way. Buffers\n(e.g. BatchNorm stats) are broadcast from the module in process of rank\n0, to all other replicas in the system in every iteration.\nNote\nIf you are using DistributedDataParallel in conjunction with the\nDistributed RPC Framework\n, you should always use\ntorch.distributed.autograd.backward()\nto compute gradients and\ntorch.distributed.optim.DistributedOptimizer\nfor optimizing\nparameters.\nExample:\n>>>\nimport\ntorch.distributed.autograd\nas\ndist_autograd\n>>>\nfrom\ntorch.nn.parallel\nimport\nDistributedDataParallel\nas\nDDP\n>>>\nimport\ntorch\n>>>\nfrom\ntorch\nimport\noptim\n>>>\nfrom\ntorch.distributed.optim\nimport\nDistributedOptimizer\n>>>\nimport\ntorch.distributed.rpc\nas\nrpc\n>>>\nfrom\ntorch.distributed.rpc\nimport\nRRef\n>>>\n>>>\nt1\n=\ntorch\n.\nrand\n((\n3\n,\n3\n),\nrequires_grad\n=\nTrue\n)\n>>>\nt2\n=\ntorch\n.\nrand\n((\n3\n,\n3\n),\nrequires_grad\n=\nTrue\n)\n>>>\nrref\n=\nrpc\n.\nremote\n(\n\"worker1\"\n,\ntorch\n.\nadd\n,\nargs\n=\n(\nt1\n,\nt2\n))\n>>>\nddp_model\n=\nDDP\n(\nmy_model\n)\n>>>\n>>>\n# Setup optimizer\n>>>\noptimizer_params\n=\n[\nrref\n]\n>>>\nfor\nparam\nin\nddp_model\n.\nparameters\n():\n>>>\noptimizer_params\n.\nappend\n(\nRRef\n(\nparam\n))\n>>>\n>>>\ndist_optim\n=\nDistributedOptimizer\n(\n>>>\noptim\n.\nSGD\n,\n>>>\noptimizer_params\n,\n>>>\nlr\n=\n0.05\n,\n>>>\n)\n>>>\n>>>\nwith\ndist_autograd\n.\ncontext\n()\nas\ncontext_id\n:\n>>>\npred\n=\nddp_model\n(\nrref\n.\nto_here\n())\n>>>\nloss\n=\nloss_func\n(\npred\n,\ntarget\n)\n>>>\ndist_autograd\n.\nbackward\n(\ncontext_id\n,\n[\nloss\n])\n>>>\ndist_optim\n.\nstep\n(\ncontext_id\n)\nNote\nDistributedDataParallel currently offers limited support for gradient\ncheckpointing with\ntorch.utils.checkpoint()\n.\nIf the checkpoint is done with use_reentrant=False (recommended), DDP\nwill work as expected without any limitations.\nIf, however, the checkpoint is done with use_reentrant=True (the default),\nDDP will work as expected when there are no unused parameters in the model\nand each layer is checkpointed at most once (make sure you are not passing\nfind_unused_parameters=True\nto DDP). We currently do not support the\ncase where a layer is checkpointed multiple times, or when there unused\nparameters in the checkpointed model.\nNote\nTo let a non-DDP model load a state dict from a DDP model,\nconsume_prefix_in_state_dict_if_present()\nneeds to be applied to strip the prefix “module.” in the DDP state dict before loading.\nWarning\nConstructor, forward method, and differentiation of the output (or a\nfunction of the output of this module) are distributed synchronization\npoints. Take that into account in case different processes might be\nexecuting different code.\nWarning\nThis module assumes all parameters are registered in the model by the\ntime it is created. No parameters should be added nor removed later.\nSame applies to buffers.\nWarning\nThis module assumes all parameters are registered in the model of each\ndistributed processes are in the same order. The module itself will\nconduct gradient\nallreduce\nfollowing the reverse order of the\nregistered parameters of the model. In other words, it is users’\nresponsibility to ensure that each distributed process has the exact\nsame model and thus the exact same parameter registration order.\nWarning\nThis module allows parameters with non-rowmajor-contiguous strides.\nFor example, your model may contain some parameters whose\ntorch.memory_format\nis\ntorch.contiguous_format\nand others whose format is\ntorch.channels_last\n.  However,\ncorresponding parameters in different processes must have the\nsame strides.\nWarning\nThis module doesn’t work with\ntorch.autograd.grad()\n(i.e. it will\nonly work if gradients are to be accumulated in\n.grad\nattributes of\nparameters).\nWarning\nIf you plan on using this module with a\nnccl\nbackend or a\ngloo\nbackend (that uses Infiniband), together with a DataLoader that uses\nmultiple workers, please change the multiprocessing start method to\nforkserver\n(Python 3 only) or\nspawn\n. Unfortunately\nGloo (that uses Infiniband) and NCCL2 are not fork safe, and you will\nlikely experience deadlocks if you don’t change this setting.\nWarning\nYou should never try to change your model’s parameters after wrapping\nup your model with\nDistributedDataParallel\n. Because, when\nwrapping up your model with\nDistributedDataParallel\n, the constructor\nof\nDistributedDataParallel\nwill register the additional gradient\nreduction functions on all the parameters of the model itself at the\ntime of construction. If you change the model’s parameters afterwards,\ngradient reduction functions no longer match the correct set of\nparameters.\nWarning\nUsing\nDistributedDataParallel\nin conjunction with the\nDistributed RPC Framework\nis experimental and subject to change.\nParameters\nmodule\n(\nModule\n) – module to be parallelized\ndevice_ids\n(\nlist\nof\nint\nor\ntorch.device\n) –\nCUDA devices.\n1) For single-device modules,\ndevice_ids\ncan\ncontain exactly one device id, which represents the only\nCUDA device where the input module corresponding to this process resides.\nAlternatively,\ndevice_ids\ncan also be\nNone\n.\n2) For multi-device modules and CPU modules,\ndevice_ids\nmust be\nNone\n.\nWhen\ndevice_ids\nis\nNone\nfor both cases,\nboth the input data for the forward pass and the actual module\nmust be placed on the correct device.\n(default:\nNone\n)\noutput_device\n(\nint\nor\ntorch.device\n) – Device location of output for\nsingle-device CUDA modules. For multi-device modules and\nCPU modules, it must be\nNone\n, and the module itself\ndictates the output location. (default:\ndevice_ids[0]\nfor single-device modules)\nbroadcast_buffers\n(\nbool\n) – Flag that enables syncing (broadcasting)\nbuffers of the module at beginning of the\nforward\nfunction. (default:\nTrue\n)\nprocess_group\n– The process group to be used for distributed data\nall-reduction. If\nNone\n, the default process group, which\nis created by\ntorch.distributed.init_process_group()\n,\nwill be used. (default:\nNone\n)\nbucket_cap_mb\n–\nDistributedDataParallel\nwill bucket parameters into\nmultiple buckets so that gradient reduction of each\nbucket can potentially overlap with backward computation.\nbucket_cap_mb\ncontrols the bucket size in\nMebiBytes (MiB). If\nNone\n, a default size of 25 MiB\nwill be used. (default:\nNone\n)\nfind_unused_parameters\n(\nbool\n) – Traverse the autograd graph from all\ntensors contained in the return value of the\nwrapped module’s\nforward\nfunction. Parameters\nthat don’t receive gradients as part of this\ngraph are preemptively marked as being ready to\nbe reduced. In addition, parameters that may have\nbeen used in the wrapped module’s\nforward\nfunction but were not part of loss computation and\nthus would also not receive gradients are\npreemptively marked as ready to be reduced.\n(default:\nFalse\n)\ncheck_reduction\n– This argument is deprecated.\ngradient_as_bucket_view\n(\nbool\n) – When set to\nTrue\n, gradients will be views\npointing to different offsets of\nallreduce\ncommunication\nbuckets. This can reduce peak memory usage, where the\nsaved memory size will be equal to the total gradients\nsize. Moreover, it avoids the overhead of copying between\ngradients and\nallreduce\ncommunication buckets. When\ngradients are views,\ndetach_()\ncannot be called on the\ngradients. If hitting such errors, please fix it by\nreferring to the\nzero_grad()\nfunction in\ntorch/optim/optimizer.py\nas a solution.\nNote that gradients will be views after first iteration, so\nthe peak memory saving should be checked after first iteration.\nstatic_graph\n(\nbool\n) –\nWhen set to\nTrue\n, DDP knows the trained graph is\nstatic. Static graph means 1) The set of used and unused\nparameters will not change during the whole training loop; in\nthis case, it does not matter whether users set\nfind_unused_parameters\n=\nTrue\nor not. 2) How the graph is trained\nwill not change during the whole training loop (meaning there is\nno control flow depending on iterations).\nWhen static_graph is set to be\nTrue\n, DDP will support cases that\ncan not be supported in the past:\n1) Reentrant backwards.\n2) Activation checkpointing multiple times.\n3) Activation checkpointing when model has unused parameters.\n4) There are model parameters that are outside of forward function.\n5) Potentially improve performance when there are unused parameters,\nas DDP will not search graph in each iteration to detect unused\nparameters when static_graph is set to be\nTrue\n.\nTo check whether you can set static_graph to be\nTrue\n, one way is to\ncheck ddp logging data at the end of your previous model training,\nif\nddp_logging_data.get(\"can_set_static_graph\")\n==\nTrue\n, mostly you\ncan set\nstatic_graph\n=\nTrue\nas well.\nExample::\n>>>\nmodel_DDP\n=\ntorch\n.\nnn\n.\nparallel\n.\nDistributedDataParallel\n(\nmodel\n)\n>>>\n# Training loop\n>>>\n...\n>>>\nddp_logging_data\n=\nmodel_DDP\n.\n_get_ddp_logging_data\n()\n>>>\nstatic_graph\n=\nddp_logging_data\n.\nget\n(\n\"can_set_static_graph\"\n)\ndelay_all_reduce_named_params\n(\nlist\nof\ntuple\nof\nstr and torch.nn.Parameter\n) – a list\nof named parameters whose all reduce will be delayed when the gradient of\nthe parameter specified in\nparam_to_hook_all_reduce\nis ready. Other\narguments of DDP do not apply to named params specified in this argument\nas these named params will be ignored by DDP reducer.\nparam_to_hook_all_reduce\n(\ntorch.nn.Parameter\n) – a parameter to hook delayed all reduce\nof parameters specified in\ndelay_all_reduce_named_params\n.\nVariables\nmodule\n(\nModule\n) – the module to be parallelized.\nExample:\n>>>\ntorch\n.\ndistributed\n.\ninit_process_group\n(\nbackend\n=\n'nccl'\n,\nworld_size\n=\n4\n,\ninit_method\n=\n'...'\n)\n>>>\nnet\n=\ntorch\n.\nnn\n.\nparallel\n.\nDistributedDataParallel\n(\nmodel\n)\njoin\n(\ndivide_by_initial_world_size\n=\nTrue\n,\nenable\n=\nTrue\n,\nthrow_on_early_termination\n=\nFalse\n)\n[source]\n[source]\n¶\nContext manager for training with uneven inputs across processes in DDP.\nThis context manager will keep track of already-joined DDP processes,\nand “shadow” the forward and backward passes by inserting collective\ncommunication operations to match with the ones created by non-joined\nDDP processes. This will ensure each collective call has a corresponding\ncall by already-joined DDP processes, preventing hangs or errors that\nwould otherwise happen when training with uneven inputs across\nprocesses. Alternatively, if the flag\nthrow_on_early_termination\nis\nspecified to be\nTrue\n, all trainers will throw an error once one rank\nruns out of inputs, allowing these errors to be caught and handled\naccording to application logic.\nOnce all DDP processes have joined, the context manager will broadcast\nthe model corresponding to the last joined process to all processes to\nensure the model is the same across all processes\n(which is guaranteed by DDP).\nTo use this to enable training with uneven inputs across processes,\nsimply wrap this context manager around your training loop. No further\nmodifications to the model or data loading is required.\nWarning\nIf the model or training loop this context manager is wrapped around\nhas additional distributed collective operations, such as\nSyncBatchNorm\nin the model’s forward pass, then the flag\nthrow_on_early_termination\nmust be enabled. This is because this\ncontext manager is not aware of non-DDP collective communication.\nThis flag will cause all ranks to throw when any one rank\nexhausts inputs, allowing these errors to be caught and recovered\nfrom across all ranks.\nParameters\ndivide_by_initial_world_size\n(\nbool\n) – If\nTrue\n, will divide\ngradients by the initial\nworld_size\nDDP training was launched\nwith. If\nFalse\n, will compute the effective world size\n(number of ranks that have not depleted their inputs yet) and\ndivide gradients by that during allreduce. Set\ndivide_by_initial_world_size=True\nto ensure every input\nsample including the uneven inputs have equal weight in terms of\nhow much they contribute to the global gradient. This is\nachieved by always dividing the gradient by the initial\nworld_size\neven when we encounter uneven inputs. If you set\nthis to\nFalse\n, we divide the gradient by the remaining\nnumber of nodes. This ensures parity with training on a smaller\nworld_size\nalthough it also means the uneven inputs would\ncontribute more towards the global gradient. Typically, you\nwould want to set this to\nTrue\nfor cases where the last few\ninputs of your training job are uneven. In extreme cases, where\nthere is a large discrepancy in the number of inputs, setting\nthis to\nFalse\nmight provide better results.\nenable\n(\nbool\n) – Whether to enable uneven input detection or not. Pass\nin\nenable=False\nto disable in cases where you know that\ninputs are even across participating processes. Default is\nTrue\n.\nthrow_on_early_termination\n(\nbool\n) – Whether to throw an error\nor continue training when at least one rank has exhausted\ninputs. If\nTrue\n, will throw upon the first rank reaching end\nof data. If\nFalse\n, will continue training with a smaller\neffective world size until all ranks are joined. Note that if\nthis flag is specified, then the flag\ndivide_by_initial_world_size\nwould be ignored. Default\nis\nFalse\n.\nExample:\n>>>\nimport\ntorch\n>>>\nimport\ntorch.distributed\nas\ndist\n>>>\nimport\nos\n>>>\nimport\ntorch.multiprocessing\nas\nmp\n>>>\nimport\ntorch.nn\nas\nnn\n>>>\n# On each spawned worker\n>>>\ndef\nworker\n(\nrank\n):\n>>>\ndist\n.\ninit_process_group\n(\n\"nccl\"\n,\nrank\n=\nrank\n,\nworld_size\n=\n2\n)\n>>>\ntorch\n.\ncuda\n.\nset_device\n(\nrank\n)\n>>>\nmodel\n=\nnn\n.\nLinear\n(\n1\n,\n1\n,\nbias\n=\nFalse\n)\n.\nto\n(\nrank\n)\n>>>\nmodel\n=\ntorch\n.\nnn\n.\nparallel\n.\nDistributedDataParallel\n(\n>>>\nmodel\n,\ndevice_ids\n=\n[\nrank\n],\noutput_device\n=\nrank\n>>>\n)\n>>>\n# Rank 1 gets one more input than rank 0.\n>>>\ninputs\n=\n[\ntorch\n.\ntensor\n([\n1\n])\n.\nfloat\n()\nfor\n_\nin\nrange\n(\n10\n+\nrank\n)]\n>>>\nwith\nmodel\n.\njoin\n():\n>>>\nfor\n_\nin\nrange\n(\n5\n):\n>>>\nfor\ninp\nin\ninputs\n:\n>>>\nloss\n=\nmodel\n(\ninp\n)\n.\nsum\n()\n>>>\nloss\n.\nbackward\n()\n>>>\n# Without the join() API, the below synchronization will hang\n>>>\n# blocking for rank 1's allreduce to complete.\n>>>\ntorch\n.\ncuda\n.\nsynchronize\n(\ndevice\n=\nrank\n)\njoin_hook\n(\n**\nkwargs\n)\n[source]\n[source]\n¶\nDDP join hook enables training on uneven inputs by mirroring communications in forward and backward passes.\nParameters\nkwargs\n(\ndict\n) – a\ndict\ncontaining any keyword arguments\nto modify the behavior of the join hook at run time; all\nJoinable\ninstances sharing the same join context\nmanager are forwarded the same value for\nkwargs\n.\nThe hook supports the following keyword arguments:\ndivide_by_initial_world_size (bool, optional):\nIf\nTrue\n, then gradients are divided by the initial world\nsize that DDP was launched with.\nIf\nFalse\n, then gradients are divided by the effective world\nsize (i.e. the number of non-joined processes), meaning that\nthe uneven inputs contribute more toward the global gradient.\nTypically, this should be set to\nTrue\nif the degree of\nunevenness is small but can be set to\nFalse\nin extreme\ncases for possibly better results.\nDefault is\nTrue\n.\nno_sync\n(\n)\n[source]\n[source]\n¶\nContext manager to disable gradient synchronizations across DDP processes.\nWithin this context, gradients will be accumulated on module\nvariables, which will later be synchronized in the first\nforward-backward pass exiting the context.\nExample:\n>>>\nddp\n=\ntorch\n.\nnn\n.\nparallel\n.\nDistributedDataParallel\n(\nmodel\n,\npg\n)\n>>>\nwith\nddp\n.\nno_sync\n():\n>>>\nfor\ninput\nin\ninputs\n:\n>>>\nddp\n(\ninput\n)\n.\nbackward\n()\n# no synchronization, accumulate grads\n>>>\nddp\n(\nanother_input\n)\n.\nbackward\n()\n# synchronize grads\nWarning\nThe forward pass should be included inside the context manager, or\nelse gradients will still be synchronized.\nregister_comm_hook\n(\nstate\n,\nhook\n)\n[source]\n[source]\n¶\nRegister communication hook for user-defined DDP aggregation of gradients across multiple workers.\nThis hook would be very useful for researchers to try out new ideas. For\nexample, this hook can be used to implement several algorithms like GossipGrad\nand gradient compression which involve different communication strategies for\nparameter syncs while running Distributed DataParallel training.\nParameters\nstate\n(\nobject\n) –\nPassed to the hook to maintain any state information during the training process.\nExamples include error feedback in gradient compression,\npeers to communicate with next in GossipGrad, etc.\nIt is locally stored by each worker\nand shared by all the gradient tensors on the worker.\nhook\n(\nCallable\n) –\nCallable with the following signature:\nhook(state:\nobject,\nbucket:\ndist.GradBucket)\n->\ntorch.futures.Future[torch.Tensor]\n:\nThis function is called once the bucket is ready. The\nhook can perform whatever processing is needed and return\na Future indicating completion of any async work (ex: allreduce).\nIf the hook doesn’t perform any communication, it still\nmust return a completed Future. The Future should hold the\nnew value of grad bucket’s tensors. Once a bucket is ready,\nc10d reducer would call this hook and use the tensors returned\nby the Future and copy grads to individual parameters.\nNote that the future’s return type must be a single tensor.\nWe also provide an API called\nget_future\nto retrieve a\nFuture associated with the completion of\nc10d.ProcessGroup.Work\n.\nget_future\nis currently supported for NCCL and also supported for most\noperations on GLOO and MPI, except for peer to peer operations (send/recv).\nWarning\nGrad bucket’s tensors will not be predivided by world_size. User is responsible\nto divide by the world_size in case of operations like allreduce.\nWarning\nDDP communication hook can only be registered once and should be registered\nbefore calling backward.\nWarning\nThe Future object that hook returns should contain a single tensor\nthat has the same shape with the tensors inside grad bucket.\nWarning\nget_future\nAPI supports NCCL, and partially GLOO and MPI backends (no support\nfor peer-to-peer operations like send/recv) and will return a\ntorch.futures.Future\n.\nExample::\nBelow is an example of a noop hook that returns the same tensor.\n>>>\ndef\nnoop\n(\nstate\n:\nobject\n,\nbucket\n:\ndist\n.\nGradBucket\n)\n->\ntorch\n.\nfutures\n.\nFuture\n[\ntorch\n.\nTensor\n]:\n>>>\nfut\n=\ntorch\n.\nfutures\n.\nFuture\n()\n>>>\nfut\n.\nset_result\n(\nbucket\n.\nbuffer\n())\n>>>\nreturn\nfut\n>>>\nddp\n.\nregister_comm_hook\n(\nstate\n=\nNone\n,\nhook\n=\nnoop\n)\nExample::\nBelow is an example of a Parallel SGD algorithm where gradients are encoded before\nallreduce, and then decoded after allreduce.\n>>>\ndef\nencode_and_decode\n(\nstate\n:\nobject\n,\nbucket\n:\ndist\n.\nGradBucket\n)\n->\ntorch\n.\nfutures\n.\nFuture\n[\ntorch\n.\nTensor\n]:\n>>>\nencoded_tensor\n=\nencode\n(\nbucket\n.\nbuffer\n())\n# encode gradients\n>>>\nfut\n=\ntorch\n.\ndistributed\n.\nall_reduce\n(\nencoded_tensor\n)\n.\nget_future\n()\n>>>\n# Define the then callback to decode.\n>>>\ndef\ndecode\n(\nfut\n):\n>>>\ndecoded_tensor\n=\ndecode\n(\nfut\n.\nvalue\n()[\n0\n])\n# decode gradients\n>>>\nreturn\ndecoded_tensor\n>>>\nreturn\nfut\n.\nthen\n(\ndecode\n)\n>>>\nddp\n.\nregister_comm_hook\n(\nstate\n=\nNone\n,\nhook\n=\nencode_and_decode\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#distributeddataparallel",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parallel/distributed.html#DistributedDataParallel",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parallel/distributed.py#L326",
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel",
    "https://pytorch.org/docs/stable/distributed.html#distributed-basics",
    "https://pytorch.org/docs/stable/notes/cuda.html#cuda-nn-ddp-instead",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel",
    "https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel",
    "https://pytorch.org/tutorials/beginner/dist_overview.html",
    "https://pytorch.org/docs/stable/distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer",
    "https://pytorch.org/tutorials/recipes/zero_redundancy_optimizer.html",
    "https://pytorch.org/docs/stable/rpc.html#distributed-rpc-framework",
    "https://pytorch.org/docs/stable/rpc.html#torch.distributed.autograd.backward",
    "https://pytorch.org/docs/stable/distributed.optim.html#torch.distributed.optim.DistributedOptimizer",
    "https://pytorch.org/docs/stable/utils.html#module-torch.utils.checkpoint",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.memory_format",
    "https://pytorch.org/docs/stable/generated/torch.autograd.grad.html#torch.autograd.grad",
    "https://pytorch.org/docs/stable/rpc.html#distributed-rpc-framework",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/distributed.html#torch.distributed.init_process_group",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parallel/distributed.html#DistributedDataParallel.join",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parallel/distributed.py#L1742",
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.join",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parallel/distributed.html#DistributedDataParallel.join_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parallel/distributed.py#L1848",
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.join_hook",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parallel/distributed.html#DistributedDataParallel.no_sync",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parallel/distributed.py#L1408",
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.no_sync",
    "https://pytorch.org/docs/stable/_modules/torch/nn/parallel/distributed.html#DistributedDataParallel.register_comm_hook",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/parallel/distributed.py#L1930",
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.register_comm_hook",
    "https://docs.python.org/3/library/functions.html#object",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "clip_grad_norm_",
  "page_text": "torch.nn.utils.clip_grad_norm_\n¶\ntorch.nn.utils.\nclip_grad_norm_\n(\nparameters\n,\nmax_norm\n,\nnorm_type\n=\n2.0\n,\nerror_if_nonfinite\n=\nFalse\n,\nforeach\n=\nNone\n)\n[source]\n[source]\n¶\nClip the gradient norm of an iterable of parameters.\nThe norm is computed over the norms of the individual gradients of all parameters,\nas if the norms of the individual gradients were concatenated into a single vector.\nGradients are modified in-place.\nThis function is equivalent to\ntorch.nn.utils.get_total_norm()\nfollowed by\ntorch.nn.utils.clip_grads_with_norm_()\nwith the\ntotal_norm\nreturned by\nget_total_norm\n.\nParameters\nparameters\n(\nIterable\n[\nTensor\n] or\nTensor\n) – an iterable of Tensors or a\nsingle Tensor that will have gradients normalized\nmax_norm\n(\nfloat\n) – max norm of the gradients\nnorm_type\n(\nfloat\n) – type of the used p-norm. Can be\n'inf'\nfor\ninfinity norm.\nerror_if_nonfinite\n(\nbool\n) – if True, an error is thrown if the total\nnorm of the gradients from\nparameters\nis\nnan\n,\ninf\n, or\n-inf\n. Default: False (will switch to True in the future)\nforeach\n(\nbool\n) – use the faster foreach-based implementation.\nIf\nNone\n, use the foreach implementation for CUDA and CPU native tensors and silently\nfall back to the slow implementation for other device types.\nDefault:\nNone\nReturns\nTotal norm of the parameter gradients (viewed as a single vector).\nReturn type\nTensor\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch-nn-utils-clip-grad-norm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/clip_grad.html#clip_grad_norm_",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/clip_grad.py#L175",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.get_total_norm.html#torch.nn.utils.get_total_norm",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grads_with_norm_.html#torch.nn.utils.clip_grads_with_norm_",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "clip_grad_norm",
  "page_text": "torch.nn.utils.clip_grad_norm\n¶\ntorch.nn.utils.\nclip_grad_norm\n(\nparameters\n,\nmax_norm\n,\nnorm_type\n=\n2.0\n,\nerror_if_nonfinite\n=\nFalse\n,\nforeach\n=\nNone\n)\n[source]\n[source]\n¶\nClip the gradient norm of an iterable of parameters.\nWarning\nThis method is now deprecated in favor of\ntorch.nn.utils.clip_grad_norm_()\n.\nReturn type\nTensor\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm.html#torch-nn-utils-clip-grad-norm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/clip_grad.html#clip_grad_norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/clip_grad.py#L220",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm.html#torch.nn.utils.clip_grad_norm",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_value_.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "clip_grad_value_",
  "page_text": "torch.nn.utils.clip_grad_value_\n¶\ntorch.nn.utils.\nclip_grad_value_\n(\nparameters\n,\nclip_value\n,\nforeach\n=\nNone\n)\n[source]\n[source]\n¶\nClip the gradients of an iterable of parameters at specified value.\nGradients are modified in-place.\nParameters\nparameters\n(\nIterable\n[\nTensor\n] or\nTensor\n) – an iterable of Tensors or a\nsingle Tensor that will have gradients normalized\nclip_value\n(\nfloat\n) – maximum allowed value of the gradients.\nThe gradients are clipped in the range\n[\n-clip_value\n,\nclip_value\n]\n\\left[\\text{-clip\\_value}, \\text{clip\\_value}\\right]\n[\n-clip_value\n,\nclip_value\n]\nforeach\n(\nbool\n) – use the faster foreach-based implementation\nIf\nNone\n, use the foreach implementation for CUDA and CPU native tensors and\nsilently fall back to the slow implementation for other device types.\nDefault:\nNone\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_value_.html#torch-nn-utils-clip-grad-value",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/clip_grad.html#clip_grad_value_",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/clip_grad.py#L241",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_value_.html#torch.nn.utils.clip_grad_value_",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.get_total_norm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "get_total_norm",
  "page_text": "torch.nn.utils.get_total_norm\n¶\ntorch.nn.utils.\nget_total_norm\n(\ntensors\n,\nnorm_type\n=\n2.0\n,\nerror_if_nonfinite\n=\nFalse\n,\nforeach\n=\nNone\n)\n[source]\n¶\nCompute the norm of an iterable of tensors.\nThe norm is computed over the norms of the individual tensors, as if the norms of\nthe individual tensors were concatenated into a single vector.\nParameters\ntensors\n(\nIterable\n[\nTensor\n] or\nTensor\n) – an iterable of Tensors or a\nsingle Tensor that will be normalized\nnorm_type\n(\nfloat\n) – type of the used p-norm. Can be\n'inf'\nfor\ninfinity norm.\nerror_if_nonfinite\n(\nbool\n) – if True, an error is thrown if the total\nnorm of\ntensors\nis\nnan\n,\ninf\n, or\n-inf\n.\nDefault:\nFalse\nforeach\n(\nbool\n) – use the faster foreach-based implementation.\nIf\nNone\n, use the foreach implementation for CUDA and CPU native tensors and silently\nfall back to the slow implementation for other device types.\nDefault:\nNone\nReturns\nTotal norm of the tensors (viewed as a single vector).\nReturn type\nTensor\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.get_total_norm.html#torch-nn-utils-get-total-norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/clip_grad.py#L40",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.get_total_norm.html#torch.nn.utils.get_total_norm",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grads_with_norm_.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_value_.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "clip_grads_with_norm_",
  "page_text": "torch.nn.utils.clip_grads_with_norm_\n¶\ntorch.nn.utils.\nclip_grads_with_norm_\n(\nparameters\n,\nmax_norm\n,\ntotal_norm\n,\nforeach\n=\nNone\n)\n[source]\n¶\nScale the gradients of an iterable of parameters given a pre-calculated total norm and desired max norm.\nThe gradients will be scaled by the following calculation\ng\nr\na\nd\n=\ng\nr\na\nd\n∗\nm\na\nx\n_\nn\no\nr\nm\nt\no\nt\na\nl\n_\nn\no\nr\nm\n+\n1\ne\n−\n6\ngrad = grad * \\frac{max\\_norm}{total\\_norm + 1e-6}\ng\nr\na\nd\n=\ng\nr\na\nd\n∗\nt\no\nt\na\nl\n_\nn\nor\nm\n+\n1\ne\n−\n6\nma\nx\n_\nn\nor\nm\n​\nGradients are modified in-place.\nThis function is equivalent to\ntorch.nn.utils.clip_grad_norm_()\nwith a pre-calculated\ntotal norm.\nParameters\nparameters\n(\nIterable\n[\nTensor\n] or\nTensor\n) – an iterable of Tensors or a\nsingle Tensor that will have gradients normalized\nmax_norm\n(\nfloat\n) – max norm of the gradients\ntotal_norm\n(\nTensor\n) – total norm of the gradients to use for clipping\nforeach\n(\nbool\n) – use the faster foreach-based implementation.\nIf\nNone\n, use the foreach implementation for CUDA and CPU native tensors and silently\nfall back to the slow implementation for other device types.\nDefault:\nNone\nReturns\nNone\nReturn type\nNone\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grads_with_norm_.html#torch-nn-utils-clip-grads-with-norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/clip_grad.py#L111",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grads_with_norm_.html#torch.nn.utils.clip_grads_with_norm_",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parameters_to_vector.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.get_total_norm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parameters_to_vector",
  "page_text": "torch.nn.utils.parameters_to_vector\n¶\ntorch.nn.utils.\nparameters_to_vector\n(\nparameters\n)\n[source]\n[source]\n¶\nFlatten an iterable of parameters into a single vector.\nParameters\nparameters\n(\nIterable\n[\nTensor\n]\n) – an iterable of Tensors that are the\nparameters of a model.\nReturns\nThe parameters represented by a single vector\nReturn type\nTensor\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parameters_to_vector.html#torch-nn-utils-parameters-to-vector",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/convert_parameters.html#parameters_to_vector",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/convert_parameters.py#L6",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parameters_to_vector.html#torch.nn.utils.parameters_to_vector",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.vector_to_parameters.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grads_with_norm_.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "vector_to_parameters",
  "page_text": "torch.nn.utils.vector_to_parameters\n¶\ntorch.nn.utils.\nvector_to_parameters\n(\nvec\n,\nparameters\n)\n[source]\n[source]\n¶\nCopy slices of a vector into an iterable of parameters.\nParameters\nvec\n(\nTensor\n) – a single vector representing the parameters of a model.\nparameters\n(\nIterable\n[\nTensor\n]\n) – an iterable of Tensors that are the\nparameters of a model.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.vector_to_parameters.html#torch-nn-utils-vector-to-parameters",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/convert_parameters.html#vector_to_parameters",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/convert_parameters.py#L28",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.vector_to_parameters.html#torch.nn.utils.vector_to_parameters",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_conv_bn_eval.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parameters_to_vector.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "fuse_conv_bn_eval",
  "page_text": "torch.nn.utils.fuse_conv_bn_eval\n¶\ntorch.nn.utils.\nfuse_conv_bn_eval\n(\nconv\n,\nbn\n,\ntranspose\n=\nFalse\n)\n[source]\n[source]\n¶\nFuse a convolutional module and a BatchNorm module into a single, new convolutional module.\nParameters\nconv\n(\ntorch.nn.modules.conv._ConvNd\n) – A convolutional module.\nbn\n(\ntorch.nn.modules.batchnorm._BatchNorm\n) – A BatchNorm module.\ntranspose\n(\nbool\n,\noptional\n) – If True, transpose the convolutional weight. Defaults to False.\nReturns\nThe fused convolutional module.\nReturn type\ntorch.nn.modules.conv._ConvNd\nNote\nBoth\nconv\nand\nbn\nmust be in eval mode, and\nbn\nmust have its running buffers computed.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_conv_bn_eval.html#torch-nn-utils-fuse-conv-bn-eval",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/fusion.html#fuse_conv_bn_eval",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/fusion.py#L20",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_conv_bn_eval.html#torch.nn.utils.fuse_conv_bn_eval",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_conv_bn_weights.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.vector_to_parameters.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "fuse_conv_bn_weights",
  "page_text": "torch.nn.utils.fuse_conv_bn_weights\n¶\ntorch.nn.utils.\nfuse_conv_bn_weights\n(\nconv_w\n,\nconv_b\n,\nbn_rm\n,\nbn_rv\n,\nbn_eps\n,\nbn_w\n,\nbn_b\n,\ntranspose\n=\nFalse\n)\n[source]\n[source]\n¶\nFuse convolutional module parameters and BatchNorm module parameters into new convolutional module parameters.\nParameters\nconv_w\n(\ntorch.Tensor\n) – Convolutional weight.\nconv_b\n(\nOptional\n[\ntorch.Tensor\n]\n) – Convolutional bias.\nbn_rm\n(\ntorch.Tensor\n) – BatchNorm running mean.\nbn_rv\n(\ntorch.Tensor\n) – BatchNorm running variance.\nbn_eps\n(\nfloat\n) – BatchNorm epsilon.\nbn_w\n(\nOptional\n[\ntorch.Tensor\n]\n) – BatchNorm weight.\nbn_b\n(\nOptional\n[\ntorch.Tensor\n]\n) – BatchNorm bias.\ntranspose\n(\nbool\n,\noptional\n) – If True, transpose the conv weight. Defaults to False.\nReturns\nFused convolutional weight and bias.\nReturn type\nTuple[torch.nn.Parameter, torch.nn.Parameter]\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_conv_bn_weights.html#torch-nn-utils-fuse-conv-bn-weights",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/fusion.html#fuse_conv_bn_weights",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/fusion.py#L56",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_conv_bn_weights.html#torch.nn.utils.fuse_conv_bn_weights",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_linear_bn_eval.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_conv_bn_eval.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "fuse_linear_bn_eval",
  "page_text": "torch.nn.utils.fuse_linear_bn_eval\n¶\ntorch.nn.utils.\nfuse_linear_bn_eval\n(\nlinear\n,\nbn\n)\n[source]\n[source]\n¶\nFuse a linear module and a BatchNorm module into a single, new linear module.\nParameters\nlinear\n(\ntorch.nn.Linear\n) – A Linear module.\nbn\n(\ntorch.nn.modules.batchnorm._BatchNorm\n) – A BatchNorm module.\nReturns\nThe fused linear module.\nReturn type\ntorch.nn.Linear\nNote\nBoth\nlinear\nand\nbn\nmust be in eval mode, and\nbn\nmust have its running buffers computed.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_linear_bn_eval.html#torch-nn-utils-fuse-linear-bn-eval",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/fusion.html#fuse_linear_bn_eval",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/fusion.py#L109",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_linear_bn_eval.html#torch.nn.utils.fuse_linear_bn_eval",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_linear_bn_weights.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_conv_bn_weights.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "fuse_linear_bn_weights",
  "page_text": "torch.nn.utils.fuse_linear_bn_weights\n¶\ntorch.nn.utils.\nfuse_linear_bn_weights\n(\nlinear_w\n,\nlinear_b\n,\nbn_rm\n,\nbn_rv\n,\nbn_eps\n,\nbn_w\n,\nbn_b\n)\n[source]\n[source]\n¶\nFuse linear module parameters and BatchNorm module parameters into new linear module parameters.\nParameters\nlinear_w\n(\ntorch.Tensor\n) – Linear weight.\nlinear_b\n(\nOptional\n[\ntorch.Tensor\n]\n) – Linear bias.\nbn_rm\n(\ntorch.Tensor\n) – BatchNorm running mean.\nbn_rv\n(\ntorch.Tensor\n) – BatchNorm running variance.\nbn_eps\n(\nfloat\n) – BatchNorm epsilon.\nbn_w\n(\ntorch.Tensor\n) – BatchNorm weight.\nbn_b\n(\ntorch.Tensor\n) – BatchNorm bias.\nReturns\nFused linear weight and bias.\nReturn type\nTuple[torch.nn.Parameter, torch.nn.Parameter]\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_linear_bn_weights.html#torch-nn-utils-fuse-linear-bn-weights",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/fusion.html#fuse_linear_bn_weights",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/fusion.py#L156",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_linear_bn_weights.html#torch.nn.utils.fuse_linear_bn_weights",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.convert_conv2d_weight_memory_format.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_linear_bn_eval.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "convert_conv2d_weight_memory_format",
  "page_text": "torch.nn.utils.convert_conv2d_weight_memory_format\n¶\ntorch.nn.utils.\nconvert_conv2d_weight_memory_format\n(\nmodule\n,\nmemory_format\n)\n[source]\n[source]\n¶\nConvert\nmemory_format\nof\nnn.Conv2d.weight\nto\nmemory_format\n.\nThe conversion recursively applies to nested\nnn.Module\n, including\nmodule\n.\nNote that it only changes the memory_format, but not the semantics of each dimensions.\nThis function is used to facilitate the computation to adopt NHWC kernels, which\nprovides considerable speed up for fp16 data on CUDA devices with compute capability >= 7.0\nNote\nCalling\nmodel.to(memory_format=torch.channels_last)\nis more aggressive\nthan the utility function\nconvert_conv2d_weight_memory_format\n. Any\nlayer with 4d weight will be affected by\nmodel.to\n, which does not\nnecessarily benefit from conversion to specified\nmemory_format\n.\nOne place we are confident in is that NHWC(channels_last) conversion for\nconvolution in cuDNN, as it is beneficial to run convolution in NHWC,\neven in cases where we have to apply permutation to input tensors.\nHence our strategy here is to convert only the weight of convolution to\nchannels_last. This ensures that;\n1. Fast convolution kernels will be used, the benefit of which could\noutweigh overhead of permutation (if input is not in the same format).\n2. No unnecessary permutations are applied on layers that do not benefit\nfrom memory_format conversion.\nThe optimal case is that, layers between convolution layers are channels\nlast compatible. Input tensor would be permuted to channels last when it\nencounters the first convolution layer and stay in that memory format.\nHence following convolutions will not need to permute its input tensor.\nIn case where a channels last incompatible layer is between convolution\nlayers, we need to permute the input tensor back to contiguous format\nfor that layer. The input tensor will go through the remaining layers in\ncontiguous format and be permuted to channels last when it encounters\nanother convolution layer. There’s no point in propagating that\npermutation to an earlier layer, as most layers are quite agnostic to\nmemory_format\n.\nThis claim might change when PyTorch supports fusion of permutation, as\nthere might have been a better spot to fuse the permutation other than\nimmediately before a convolution.\nParameters\nmodule\n(\nnn.Module\n) –\nnn.Conv2d\n&\nnn.ConvTranspose2d\nor container\nnn.Module\nmemory_format\n– user specified\nmemory_format\n,\ne.g.\ntorch.channels_last\nor\ntorch.contiguous_format\nReturns\nThe original module with updated\nnn.Conv2d\nExample\n>>>\ninput\n=\ntorch\n.\nrandint\n(\n1\n,\n10\n,\n(\n2\n,\n8\n,\n4\n,\n4\n),\ndtype\n=\ntorch\n.\nfloat16\n,\ndevice\n=\n\"cuda\"\n)\n>>>\nmodel\n=\nnn\n.\nSequential\n(\n>>>\nnn\n.\nConv2d\n(\n8\n,\n4\n,\n3\n))\n.\ncuda\n()\n.\nhalf\n()\n>>>\n# This is identical to:\n>>>\n# nn.utils.convert_conv2d_weight_memory_format(model, torch.channels_last)\n>>>\nmodel\n=\nnn\n.\nutils\n.\nconvert_conv2d_weight_memory_format\n(\nmodel\n,\ntorch\n.\nchannels_last\n)\n>>>\nout\n=\nmodel\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.convert_conv2d_weight_memory_format.html#torch-nn-utils-convert-conv2d-weight-memory-format",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/memory_format.html#convert_conv2d_weight_memory_format",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/memory_format.py#L5",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.convert_conv2d_weight_memory_format.html#torch.nn.utils.convert_conv2d_weight_memory_format",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.convert_conv3d_weight_memory_format.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.fuse_linear_bn_weights.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "convert_conv3d_weight_memory_format",
  "page_text": "torch.nn.utils.convert_conv3d_weight_memory_format\n¶\ntorch.nn.utils.\nconvert_conv3d_weight_memory_format\n(\nmodule\n,\nmemory_format\n)\n[source]\n[source]\n¶\nConvert\nmemory_format\nof\nnn.Conv3d.weight\nto\nmemory_format\nThe conversion recursively applies to nested\nnn.Module\n, including\nmodule\n.\nNote that it only changes the memory_format, but not the semantics of each dimensions.\nThis function is used to facilitate the computation to adopt NHWC kernels, which\nprovides considerable speed up for fp16 data on CUDA devices with compute capability >= 7.0\nNote\nCalling\nmodel.to(memory_format=torch.channels_last_3d)\nis more aggressive\nthan the utility function\nconvert_conv3d_weight_memory_format\n. Any\nlayer with 4d weight will be affected by\nmodel.to\n, which does not\nnecessarily benefit from conversion to specified\nmemory_format\n.\nOne place we are confident in is that NDHWC(channels_last_3d) conversion for\nconvolution in cuDNN, as it is beneficial to run convolution in NDHWC,\neven in cases where we have to apply permutation to input tensors.\nHence our strategy here is to convert only the weight of convolution to\nchannels_last_3d. This ensures that;\n1. Fast convolution kernels will be used, the benefit of which could\noutweigh overhead of permutation (if input is not in the same format).\n2. No unnecessary permutations are applied on layers that do not benefit\nfrom memory_format conversion.\nThe optimal case is that, layers between convolution layers are channels\nlast compatible. Input tensor would be permuted to channels last when it\nencounters the first convolution layer and stay in that memory format.\nHence following convolutions will not need to permute its input tensor.\nIn case where a channels last incompatible layer is between convolution\nlayers, we need to permute the input tensor back to contiguous format\nfor that layer. The input tensor will go through the remaining layers in\ncontiguous format and be permuted to channels last when it encounters\nanother convolution layer. There’s no point in propagating that\npermutation to an earlier layer, as most layers are quite agnostic to\nmemory_format\n.\nThis claim might change when PyTorch supports fusion of permutation, as\nthere might have been a better spot to fuse the permutation other than\nimmediately before a convolution.\nParameters\nmodule\n(\nnn.Module\n) –\nnn.Conv3d\n&\nnn.ConvTranspose3d\nor container\nnn.Module\nmemory_format\n– user specified\nmemory_format\n,\ne.g.\ntorch.channels_last\nor\ntorch.contiguous_format\nReturns\nThe original module with updated\nnn.Conv3d\nExample\n>>>\ninput\n=\ntorch\n.\nrandint\n(\n1\n,\n10\n,\n(\n2\n,\n8\n,\n4\n,\n4\n,\n4\n),\ndtype\n=\ntorch\n.\nfloat16\n,\ndevice\n=\n\"cuda\"\n)\n>>>\nmodel\n=\nnn\n.\nSequential\n(\n>>>\nnn\n.\nConv3d\n(\n8\n,\n4\n,\n3\n))\n.\ncuda\n()\n.\nhalf\n()\n>>>\n# This is identical to:\n>>>\n# nn.utils.convert_conv3d_weight_memory_format(model, torch.channels_last_3d)\n>>>\nmodel\n=\nnn\n.\nutils\n.\nconvert_conv3d_weight_memory_format\n(\nmodel\n,\ntorch\n.\nchannels_last_3d\n)\n>>>\nout\n=\nmodel\n(\ninput\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.convert_conv3d_weight_memory_format.html#torch-nn-utils-convert-conv3d-weight-memory-format",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/memory_format.html#convert_conv3d_weight_memory_format",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/memory_format.py#L80",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.convert_conv3d_weight_memory_format.html#torch.nn.utils.convert_conv3d_weight_memory_format",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.weight_norm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.convert_conv2d_weight_memory_format.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "weight_norm",
  "page_text": "torch.nn.utils.weight_norm\n¶\ntorch.nn.utils.\nweight_norm\n(\nmodule\n,\nname\n=\n'weight'\n,\ndim\n=\n0\n)\n[source]\n[source]\n¶\nApply weight normalization to a parameter in the given module.\nw\n=\ng\nv\n∥\nv\n∥\n\\mathbf{w} = g \\dfrac{\\mathbf{v}}{\\|\\mathbf{v}\\|}\nw\n=\ng\n∥\nv\n∥\nv\n​\nWeight normalization is a reparameterization that decouples the magnitude\nof a weight tensor from its direction. This replaces the parameter specified\nby\nname\n(e.g.\n'weight'\n) with two parameters: one specifying the magnitude\n(e.g.\n'weight_g'\n) and one specifying the direction (e.g.\n'weight_v'\n).\nWeight normalization is implemented via a hook that recomputes the weight\ntensor from the magnitude and direction before every\nforward()\ncall.\nBy default, with\ndim=0\n, the norm is computed independently per output\nchannel/plane. To compute a norm over the entire weight tensor, use\ndim=None\n.\nSee\nhttps://arxiv.org/abs/1602.07868\nWarning\nThis function is deprecated.  Use\ntorch.nn.utils.parametrizations.weight_norm()\nwhich uses the modern parametrization API.  The new\nweight_norm\nis compatible\nwith\nstate_dict\ngenerated from old\nweight_norm\n.\nMigration guide:\nThe magnitude (\nweight_g\n) and direction (\nweight_v\n) are now expressed\nas\nparametrizations.weight.original0\nand\nparametrizations.weight.original1\nrespectively.  If this is bothering you, please comment on\nhttps://github.com/pytorch/pytorch/issues/102999\nTo remove the weight normalization reparametrization, use\ntorch.nn.utils.parametrize.remove_parametrizations()\n.\nThe weight is no longer recomputed once at module forward; instead, it will\nbe recomputed on every access.  To restore the old behavior, use\ntorch.nn.utils.parametrize.cached()\nbefore invoking the module\nin question.\nParameters\nmodule\n(\nModule\n) – containing module\nname\n(\nstr\n,\noptional\n) – name of weight parameter\ndim\n(\nint\n,\noptional\n) – dimension over which to compute the norm\nReturns\nThe original module with the weight norm hook\nReturn type\nT_module\nExample:\n>>>\nm\n=\nweight_norm\n(\nnn\n.\nLinear\n(\n20\n,\n40\n),\nname\n=\n'weight'\n)\n>>>\nm\nLinear(in_features=20, out_features=40, bias=True)\n>>>\nm\n.\nweight_g\n.\nsize\n()\ntorch.Size([40, 1])\n>>>\nm\n.\nweight_v\n.\nsize\n()\ntorch.Size([40, 20])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.weight_norm.html#torch-nn-utils-weight-norm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/weight_norm.html#weight_norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/weight_norm.py#L83",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.weight_norm.html#torch.nn.utils.weight_norm",
    "https://arxiv.org/abs/1602.07868",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.weight_norm.html#torch.nn.utils.parametrizations.weight_norm",
    "https://github.com/pytorch/pytorch/issues/102999",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.remove_parametrizations.html#torch.nn.utils.parametrize.remove_parametrizations",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.cached.html#torch.nn.utils.parametrize.cached",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.remove_weight_norm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.convert_conv3d_weight_memory_format.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "remove_weight_norm",
  "page_text": "torch.nn.utils.remove_weight_norm\n¶\ntorch.nn.utils.\nremove_weight_norm\n(\nmodule\n,\nname\n=\n'weight'\n)\n[source]\n[source]\n¶\nRemove the weight normalization reparameterization from a module.\nParameters\nmodule\n(\nModule\n) – containing module\nname\n(\nstr\n,\noptional\n) – name of weight parameter\nReturn type\nT_module\nExample\n>>>\nm\n=\nweight_norm\n(\nnn\n.\nLinear\n(\n20\n,\n40\n))\n>>>\nremove_weight_norm\n(\nm\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.remove_weight_norm.html#torch-nn-utils-remove-weight-norm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/weight_norm.html#remove_weight_norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/weight_norm.py#L147",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.remove_weight_norm.html#torch.nn.utils.remove_weight_norm",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.spectral_norm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.weight_norm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "spectral_norm",
  "page_text": "torch.nn.utils.spectral_norm\n¶\ntorch.nn.utils.\nspectral_norm\n(\nmodule\n,\nname\n=\n'weight'\n,\nn_power_iterations\n=\n1\n,\neps\n=\n1e-12\n,\ndim\n=\nNone\n)\n[source]\n[source]\n¶\nApply spectral normalization to a parameter in the given module.\nW\nS\nN\n=\nW\nσ\n(\nW\n)\n,\nσ\n(\nW\n)\n=\nmax\n⁡\nh\n:\nh\n≠\n0\n∥\nW\nh\n∥\n2\n∥\nh\n∥\n2\n\\mathbf{W}_{SN} = \\dfrac{\\mathbf{W}}{\\sigma(\\mathbf{W})},\n\\sigma(\\mathbf{W}) = \\max_{\\mathbf{h}: \\mathbf{h} \\ne 0} \\dfrac{\\|\\mathbf{W} \\mathbf{h}\\|_2}{\\|\\mathbf{h}\\|_2}\nW\nSN\n​\n=\nσ\n(\nW\n)\nW\n​\n,\nσ\n(\nW\n)\n=\nh\n:\nh\n\n=\n0\nmax\n​\n∥\nh\n∥\n2\n​\n∥\nWh\n∥\n2\n​\n​\nSpectral normalization stabilizes the training of discriminators (critics)\nin Generative Adversarial Networks (GANs) by rescaling the weight tensor\nwith spectral norm\nσ\n\\sigma\nσ\nof the weight matrix calculated using\npower iteration method. If the dimension of the weight tensor is greater\nthan 2, it is reshaped to 2D in power iteration method to get spectral\nnorm. This is implemented via a hook that calculates spectral norm and\nrescales weight before every\nforward()\ncall.\nSee\nSpectral Normalization for Generative Adversarial Networks\n.\nParameters\nmodule\n(\nnn.Module\n) – containing module\nname\n(\nstr\n,\noptional\n) – name of weight parameter\nn_power_iterations\n(\nint\n,\noptional\n) – number of power iterations to\ncalculate spectral norm\neps\n(\nfloat\n,\noptional\n) – epsilon for numerical stability in\ncalculating norms\ndim\n(\nint\n,\noptional\n) – dimension corresponding to number of outputs,\nthe default is\n0\n, except for modules that are instances of\nConvTranspose{1,2,3}d, when it is\n1\nReturns\nThe original module with the spectral norm hook\nReturn type\nT_module\nNote\nThis function has been reimplemented as\ntorch.nn.utils.parametrizations.spectral_norm()\nusing the new\nparametrization functionality in\ntorch.nn.utils.parametrize.register_parametrization()\n. Please use\nthe newer version. This function will be deprecated in a future version\nof PyTorch.\nExample:\n>>>\nm\n=\nspectral_norm\n(\nnn\n.\nLinear\n(\n20\n,\n40\n))\n>>>\nm\nLinear(in_features=20, out_features=40, bias=True)\n>>>\nm\n.\nweight_u\n.\nsize\n()\ntorch.Size([40])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.spectral_norm.html#torch-nn-utils-spectral-norm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/spectral_norm.html#spectral_norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/spectral_norm.py#L265",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.spectral_norm.html#torch.nn.utils.spectral_norm",
    "https://arxiv.org/abs/1802.05957",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.spectral_norm.html#torch.nn.utils.parametrizations.spectral_norm",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.remove_spectral_norm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.remove_weight_norm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "remove_spectral_norm",
  "page_text": "torch.nn.utils.remove_spectral_norm\n¶\ntorch.nn.utils.\nremove_spectral_norm\n(\nmodule\n,\nname\n=\n'weight'\n)\n[source]\n[source]\n¶\nRemove the spectral normalization reparameterization from a module.\nParameters\nmodule\n(\nModule\n) – containing module\nname\n(\nstr\n,\noptional\n) – name of weight parameter\nReturn type\nT_module\nExample\n>>>\nm\n=\nspectral_norm\n(\nnn\n.\nLinear\n(\n40\n,\n10\n))\n>>>\nremove_spectral_norm\n(\nm\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.remove_spectral_norm.html#torch-nn-utils-remove-spectral-norm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/spectral_norm.html#remove_spectral_norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/spectral_norm.py#L337",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.remove_spectral_norm.html#torch.nn.utils.remove_spectral_norm",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.skip_init.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.spectral_norm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "skip_init",
  "page_text": "torch.nn.utils.skip_init\n¶\ntorch.nn.utils.\nskip_init\n(\nmodule_cls\n,\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nGiven a module class object and args / kwargs, instantiate the module without initializing parameters / buffers.\nThis can be useful if initialization is slow or if custom initialization will\nbe performed, making the default initialization unnecessary. There are some caveats to this, due to\nthe way this function is implemented:\n1. The module must accept a\ndevice\narg in its constructor that is passed to any parameters\nor buffers created during construction.\n2. The module must not perform any computation on parameters in its constructor except\ninitialization (i.e. functions from\ntorch.nn.init\n).\nIf these conditions are satisfied, the module can be instantiated with parameter / buffer values\nuninitialized, as if having been created using\ntorch.empty()\n.\nParameters\nmodule_cls\n– Class object; should be a subclass of\ntorch.nn.Module\nargs\n– args to pass to the module’s constructor\nkwargs\n– kwargs to pass to the module’s constructor\nReturns\nInstantiated module with uninitialized parameters / buffers\nExample:\n>>>\nimport\ntorch\n>>>\nm\n=\ntorch\n.\nnn\n.\nutils\n.\nskip_init\n(\ntorch\n.\nnn\n.\nLinear\n,\n5\n,\n1\n)\n>>>\nm\n.\nweight\nParameter containing:\ntensor([[0.0000e+00, 1.5846e+29, 7.8307e+00, 2.5250e-29, 1.1210e-44]],\nrequires_grad=True)\n>>>\nm2\n=\ntorch\n.\nnn\n.\nutils\n.\nskip_init\n(\ntorch\n.\nnn\n.\nLinear\n,\nin_features\n=\n6\n,\nout_features\n=\n1\n)\n>>>\nm2\n.\nweight\nParameter containing:\ntensor([[-1.4677e+24,  4.5915e-41,  1.4013e-45,  0.0000e+00, -1.4677e+24,\n4.5915e-41]], requires_grad=True)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.skip_init.html#torch-nn-utils-skip-init",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/init.html#skip_init",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/init.py#L7",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.skip_init.html#torch.nn.utils.skip_init",
    "https://pytorch.org/docs/stable/nn.html#module-torch.nn.init",
    "https://pytorch.org/docs/stable/generated/torch.empty.html#torch.empty",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.remove_spectral_norm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.BasePruningMethod",
  "page_text": "BasePruningMethod\n¶\nclass\ntorch.nn.utils.prune.\nBasePruningMethod\n[source]\n[source]\n¶\nAbstract base class for creation of new pruning techniques.\nProvides a skeleton for customization requiring the overriding of methods\nsuch as\ncompute_mask()\nand\napply()\n.\nclassmethod\napply\n(\nmodule\n,\nname\n,\n*\nargs\n,\nimportance_scores\n=\nNone\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nAdd pruning on the fly and reparametrization of a tensor.\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\nargs\n– arguments passed on to a subclass of\nBasePruningMethod\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the parameter being pruned.\nIf unspecified or None, the parameter will be used in its place.\nkwargs\n– keyword arguments passed on to a subclass of a\nBasePruningMethod\napply_mask\n(\nmodule\n)\n[source]\n[source]\n¶\nSimply handles the multiplication between the parameter being pruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nReturns\npruned version of the input tensor\nReturn type\npruned_tensor (\ntorch.Tensor\n)\nabstract\ncompute_mask\n(\nt\n,\ndefault_mask\n)\n[source]\n[source]\n¶\nCompute and returns a mask for the input tensor\nt\n.\nStarting from a base\ndefault_mask\n(which should be a mask of ones\nif the tensor has not been pruned yet), generate a random mask to\napply on top of the\ndefault_mask\naccording to the specific pruning\nmethod recipe.\nParameters\nt\n(\ntorch.Tensor\n) – tensor representing the importance scores of the\nprune.\n(\nparameter to\n) –\ndefault_mask\n(\ntorch.Tensor\n) – Base mask from previous pruning\niterations\n–\nis\n(\nthat need to be respected after the new mask\n) –\nt.\n(\napplied. Same dims as\n) –\nReturns\nmask to apply to\nt\n, of same dims as\nt\nReturn type\nmask (\ntorch.Tensor\n)\nprune\n(\nt\n,\ndefault_mask\n=\nNone\n,\nimportance_scores\n=\nNone\n)\n[source]\n[source]\n¶\nCompute and returns a pruned version of input tensor\nt\n.\nAccording to the pruning rule specified in\ncompute_mask()\n.\nParameters\nt\n(\ntorch.Tensor\n) – tensor to prune (of same dimensions as\ndefault_mask\n).\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as\nt\n) used to compute mask for pruning\nt\n.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the\nt\nthat is being pruned.\nIf unspecified or None, the tensor\nt\nwill be used in its place.\ndefault_mask\n(\ntorch.Tensor\n,\noptional\n) – mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones.\nReturns\npruned version of tensor\nt\n.\nremove\n(\nmodule\n)\n[source]\n[source]\n¶\nRemove the pruning reparameterization from a module.\nThe pruned parameter named\nname\nremains permanently pruned,\nand the parameter named\nname+'_orig'\nis removed from the parameter list.\nSimilarly, the buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#basepruningmethod",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#BasePruningMethod",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L11",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.compute_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.apply",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#BasePruningMethod.apply",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L75",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.apply",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#BasePruningMethod.apply_mask",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L53",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.apply_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#BasePruningMethod.compute_mask",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L33",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.compute_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#BasePruningMethod.prune",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.prune",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.compute_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#BasePruningMethod.remove",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.skip_init.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.PruningContainer",
  "page_text": "PruningContainer\n¶\nclass\ntorch.nn.utils.prune.\nPruningContainer\n(\n*\nargs\n)\n[source]\n[source]\n¶\nContainer holding a sequence of pruning methods for iterative pruning.\nKeeps track of the order in which pruning methods are applied and handles\ncombining successive pruning calls.\nAccepts as argument an instance of a BasePruningMethod or an iterable of\nthem.\nadd_pruning_method\n(\nmethod\n)\n[source]\n[source]\n¶\nAdd a child pruning\nmethod\nto the container.\nParameters\nmethod\n(\nsubclass\nof\nBasePruningMethod\n) – child pruning method\nto be added to the container.\nclassmethod\napply\n(\nmodule\n,\nname\n,\n*\nargs\n,\nimportance_scores\n=\nNone\n,\n**\nkwargs\n)\n[source]\n¶\nAdd pruning on the fly and reparametrization of a tensor.\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\nargs\n– arguments passed on to a subclass of\nBasePruningMethod\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the parameter being pruned.\nIf unspecified or None, the parameter will be used in its place.\nkwargs\n– keyword arguments passed on to a subclass of a\nBasePruningMethod\napply_mask\n(\nmodule\n)\n[source]\n¶\nSimply handles the multiplication between the parameter being pruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nReturns\npruned version of the input tensor\nReturn type\npruned_tensor (\ntorch.Tensor\n)\ncompute_mask\n(\nt\n,\ndefault_mask\n)\n[source]\n[source]\n¶\nApply the latest\nmethod\nby computing the new partial masks and returning its combination with the\ndefault_mask\n.\nThe new partial mask should be computed on the entries or channels\nthat were not zeroed out by the\ndefault_mask\n.\nWhich portions of the tensor\nt\nthe new mask will be calculated from\ndepends on the\nPRUNING_TYPE\n(handled by the type handler):\nfor ‘unstructured’, the mask will be computed from the raveled\nlist of nonmasked entries;\nfor ‘structured’, the mask will be computed from the nonmasked\nchannels in the tensor;\nfor ‘global’, the mask will be computed across all entries.\nParameters\nt\n(\ntorch.Tensor\n) – tensor representing the parameter to prune\n(of same dimensions as\ndefault_mask\n).\ndefault_mask\n(\ntorch.Tensor\n) – mask from previous pruning iteration.\nReturns\nnew mask that combines the effects\nof the\ndefault_mask\nand the new mask from the current\npruning\nmethod\n(of same dimensions as\ndefault_mask\nand\nt\n).\nReturn type\nmask (\ntorch.Tensor\n)\nprune\n(\nt\n,\ndefault_mask\n=\nNone\n,\nimportance_scores\n=\nNone\n)\n[source]\n¶\nCompute and returns a pruned version of input tensor\nt\n.\nAccording to the pruning rule specified in\ncompute_mask()\n.\nParameters\nt\n(\ntorch.Tensor\n) – tensor to prune (of same dimensions as\ndefault_mask\n).\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as\nt\n) used to compute mask for pruning\nt\n.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the\nt\nthat is being pruned.\nIf unspecified or None, the tensor\nt\nwill be used in its place.\ndefault_mask\n(\ntorch.Tensor\n,\noptional\n) – mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones.\nReturns\npruned version of tensor\nt\n.\nremove\n(\nmodule\n)\n[source]\n¶\nRemove the pruning reparameterization from a module.\nThe pruned parameter named\nname\nremains permanently pruned,\nand the parameter named\nname+'_orig'\nis removed from the parameter list.\nSimilarly, the buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#pruningcontainer",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#PruningContainer",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L262",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#PruningContainer.add_pruning_method",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L284",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.add_pruning_method",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L75",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.apply",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L53",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.apply_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#PruningContainer.compute_mask",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L312",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.compute_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.prune",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.compute_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.Identity.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.Identity",
  "page_text": "Identity\n¶\nclass\ntorch.nn.utils.prune.\nIdentity\n[source]\n[source]\n¶\nUtility pruning method that does not prune any units but generates the pruning parametrization with a mask of ones.\nclassmethod\napply\n(\nmodule\n,\nname\n)\n[source]\n[source]\n¶\nAdd pruning on the fly and reparametrization of a tensor.\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\napply_mask\n(\nmodule\n)\n[source]\n¶\nSimply handles the multiplication between the parameter being pruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nReturns\npruned version of the input tensor\nReturn type\npruned_tensor (\ntorch.Tensor\n)\nprune\n(\nt\n,\ndefault_mask\n=\nNone\n,\nimportance_scores\n=\nNone\n)\n[source]\n¶\nCompute and returns a pruned version of input tensor\nt\n.\nAccording to the pruning rule specified in\ncompute_mask()\n.\nParameters\nt\n(\ntorch.Tensor\n) – tensor to prune (of same dimensions as\ndefault_mask\n).\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as\nt\n) used to compute mask for pruning\nt\n.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the\nt\nthat is being pruned.\nIf unspecified or None, the tensor\nt\nwill be used in its place.\ndefault_mask\n(\ntorch.Tensor\n,\noptional\n) – mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones.\nReturns\npruned version of tensor\nt\n.\nremove\n(\nmodule\n)\n[source]\n¶\nRemove the pruning reparameterization from a module.\nThe pruned parameter named\nname\nremains permanently pruned,\nand the parameter named\nname+'_orig'\nis removed from the parameter list.\nSimilarly, the buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.Identity.html#identity",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#Identity",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L408",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#Identity.apply",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L417",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.apply",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L53",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.apply_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.prune",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomUnstructured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.PruningContainer.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.RandomUnstructured",
  "page_text": "RandomUnstructured\n¶\nclass\ntorch.nn.utils.prune.\nRandomUnstructured\n(\namount\n)\n[source]\n[source]\n¶\nPrune (currently unpruned) units in a tensor at random.\nParameters\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nclassmethod\napply\n(\nmodule\n,\nname\n,\namount\n)\n[source]\n[source]\n¶\nAdd pruning on the fly and reparametrization of a tensor.\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\napply_mask\n(\nmodule\n)\n[source]\n¶\nSimply handles the multiplication between the parameter being pruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nReturns\npruned version of the input tensor\nReturn type\npruned_tensor (\ntorch.Tensor\n)\nprune\n(\nt\n,\ndefault_mask\n=\nNone\n,\nimportance_scores\n=\nNone\n)\n[source]\n¶\nCompute and returns a pruned version of input tensor\nt\n.\nAccording to the pruning rule specified in\ncompute_mask()\n.\nParameters\nt\n(\ntorch.Tensor\n) – tensor to prune (of same dimensions as\ndefault_mask\n).\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as\nt\n) used to compute mask for pruning\nt\n.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the\nt\nthat is being pruned.\nIf unspecified or None, the tensor\nt\nwill be used in its place.\ndefault_mask\n(\ntorch.Tensor\n,\noptional\n) – mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones.\nReturns\npruned version of tensor\nt\n.\nremove\n(\nmodule\n)\n[source]\n¶\nRemove the pruning reparameterization from a module.\nThe pruned parameter named\nname\nremains permanently pruned,\nand the parameter named\nname+'_orig'\nis removed from the parameter list.\nSimilarly, the buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomUnstructured.html#randomunstructured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#RandomUnstructured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L433",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#RandomUnstructured.apply",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L472",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.apply",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L53",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.apply_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.prune",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.Identity.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.L1Unstructured",
  "page_text": "L1Unstructured\n¶\nclass\ntorch.nn.utils.prune.\nL1Unstructured\n(\namount\n)\n[source]\n[source]\n¶\nPrune (currently unpruned) units in a tensor by zeroing out the ones with the lowest L1-norm.\nParameters\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nclassmethod\napply\n(\nmodule\n,\nname\n,\namount\n,\nimportance_scores\n=\nNone\n)\n[source]\n[source]\n¶\nAdd pruning on the fly and reparametrization of a tensor.\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of same\nshape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the corresponding\nelements in the parameter being pruned.\nIf unspecified or None, the module parameter will be used in its place.\napply_mask\n(\nmodule\n)\n[source]\n¶\nSimply handles the multiplication between the parameter being pruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nReturns\npruned version of the input tensor\nReturn type\npruned_tensor (\ntorch.Tensor\n)\nprune\n(\nt\n,\ndefault_mask\n=\nNone\n,\nimportance_scores\n=\nNone\n)\n[source]\n¶\nCompute and returns a pruned version of input tensor\nt\n.\nAccording to the pruning rule specified in\ncompute_mask()\n.\nParameters\nt\n(\ntorch.Tensor\n) – tensor to prune (of same dimensions as\ndefault_mask\n).\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as\nt\n) used to compute mask for pruning\nt\n.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the\nt\nthat is being pruned.\nIf unspecified or None, the tensor\nt\nwill be used in its place.\ndefault_mask\n(\ntorch.Tensor\n,\noptional\n) – mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones.\nReturns\npruned version of tensor\nt\n.\nremove\n(\nmodule\n)\n[source]\n¶\nRemove the pruning reparameterization from a module.\nThe pruned parameter named\nname\nremains permanently pruned,\nand the parameter named\nname+'_orig'\nis removed from the parameter list.\nSimilarly, the buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html#l1unstructured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#L1Unstructured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L492",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#L1Unstructured.apply",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L531",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.apply",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L53",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.apply_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.prune",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomUnstructured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.RandomStructured",
  "page_text": "RandomStructured\n¶\nclass\ntorch.nn.utils.prune.\nRandomStructured\n(\namount\n,\ndim\n=\n-1\n)\n[source]\n[source]\n¶\nPrune entire (currently unpruned) channels in a tensor at random.\nParameters\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\ndim\n(\nint\n,\noptional\n) – index of the dim along which we define\nchannels to prune. Default: -1.\nclassmethod\napply\n(\nmodule\n,\nname\n,\namount\n,\ndim\n=\n-1\n)\n[source]\n[source]\n¶\nAdd pruning on the fly and reparametrization of a tensor.\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\ndim\n(\nint\n,\noptional\n) – index of the dim along which we define\nchannels to prune. Default: -1.\napply_mask\n(\nmodule\n)\n[source]\n¶\nSimply handles the multiplication between the parameter being pruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nReturns\npruned version of the input tensor\nReturn type\npruned_tensor (\ntorch.Tensor\n)\ncompute_mask\n(\nt\n,\ndefault_mask\n)\n[source]\n[source]\n¶\nCompute and returns a mask for the input tensor\nt\n.\nStarting from a base\ndefault_mask\n(which should be a mask of ones\nif the tensor has not been pruned yet), generate a random mask to\napply on top of the\ndefault_mask\nby randomly zeroing out channels\nalong the specified dim of the tensor.\nParameters\nt\n(\ntorch.Tensor\n) – tensor representing the parameter to prune\ndefault_mask\n(\ntorch.Tensor\n) – Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied. Same dims as\nt\n.\nReturns\nmask to apply to\nt\n, of same dims as\nt\nReturn type\nmask (\ntorch.Tensor\n)\nRaises\nIndexError\n– if\nself.dim\n>=\nlen(t.shape)\nprune\n(\nt\n,\ndefault_mask\n=\nNone\n,\nimportance_scores\n=\nNone\n)\n[source]\n¶\nCompute and returns a pruned version of input tensor\nt\n.\nAccording to the pruning rule specified in\ncompute_mask()\n.\nParameters\nt\n(\ntorch.Tensor\n) – tensor to prune (of same dimensions as\ndefault_mask\n).\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as\nt\n) used to compute mask for pruning\nt\n.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the\nt\nthat is being pruned.\nIf unspecified or None, the tensor\nt\nwill be used in its place.\ndefault_mask\n(\ntorch.Tensor\n,\noptional\n) – mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones.\nReturns\npruned version of tensor\nt\n.\nremove\n(\nmodule\n)\n[source]\n¶\nRemove the pruning reparameterization from a module.\nThe pruned parameter named\nname\nremains permanently pruned,\nand the parameter named\nname+'_orig'\nis removed from the parameter list.\nSimilarly, the buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html#randomstructured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#RandomStructured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L558",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#RandomStructured.apply",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L641",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.apply",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L53",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.apply_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#RandomStructured.compute_mask",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L578",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.compute_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/exceptions.html#IndexError",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.prune",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.compute_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.L1Unstructured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.LnStructured",
  "page_text": "LnStructured\n¶\nclass\ntorch.nn.utils.prune.\nLnStructured\n(\namount\n,\nn\n,\ndim\n=\n-1\n)\n[source]\n[source]\n¶\nPrune entire (currently unpruned) channels in a tensor based on their L\nn\n-norm.\nParameters\namount\n(\nint\nor\nfloat\n) – quantity of channels to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nn\n(\nint\n,\nfloat\n,\ninf\n,\n-inf\n,\n'fro'\n,\n'nuc'\n) – See documentation of valid\nentries for argument\np\nin\ntorch.norm()\n.\ndim\n(\nint\n,\noptional\n) – index of the dim along which we define\nchannels to prune. Default: -1.\nclassmethod\napply\n(\nmodule\n,\nname\n,\namount\n,\nn\n,\ndim\n,\nimportance_scores\n=\nNone\n)\n[source]\n[source]\n¶\nAdd pruning on the fly and reparametrization of a tensor.\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nn\n(\nint\n,\nfloat\n,\ninf\n,\n-inf\n,\n'fro'\n,\n'nuc'\n) – See documentation of valid\nentries for argument\np\nin\ntorch.norm()\n.\ndim\n(\nint\n) – index of the dim along which we define channels to\nprune.\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of same\nshape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the corresponding\nelements in the parameter being pruned.\nIf unspecified or None, the module parameter will be used in its place.\napply_mask\n(\nmodule\n)\n[source]\n¶\nSimply handles the multiplication between the parameter being pruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nReturns\npruned version of the input tensor\nReturn type\npruned_tensor (\ntorch.Tensor\n)\ncompute_mask\n(\nt\n,\ndefault_mask\n)\n[source]\n[source]\n¶\nCompute and returns a mask for the input tensor\nt\n.\nStarting from a base\ndefault_mask\n(which should be a mask of ones\nif the tensor has not been pruned yet), generate a mask to apply on\ntop of the\ndefault_mask\nby zeroing out the channels along the\nspecified dim with the lowest L\nn\n-norm.\nParameters\nt\n(\ntorch.Tensor\n) – tensor representing the parameter to prune\ndefault_mask\n(\ntorch.Tensor\n) – Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied.  Same dims as\nt\n.\nReturns\nmask to apply to\nt\n, of same dims as\nt\nReturn type\nmask (\ntorch.Tensor\n)\nRaises\nIndexError\n– if\nself.dim\n>=\nlen(t.shape)\nprune\n(\nt\n,\ndefault_mask\n=\nNone\n,\nimportance_scores\n=\nNone\n)\n[source]\n¶\nCompute and returns a pruned version of input tensor\nt\n.\nAccording to the pruning rule specified in\ncompute_mask()\n.\nParameters\nt\n(\ntorch.Tensor\n) – tensor to prune (of same dimensions as\ndefault_mask\n).\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as\nt\n) used to compute mask for pruning\nt\n.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the\nt\nthat is being pruned.\nIf unspecified or None, the tensor\nt\nwill be used in its place.\ndefault_mask\n(\ntorch.Tensor\n,\noptional\n) – mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones.\nReturns\npruned version of tensor\nt\n.\nremove\n(\nmodule\n)\n[source]\n¶\nRemove the pruning reparameterization from a module.\nThe pruned parameter named\nname\nremains permanently pruned,\nand the parameter named\nname+'_orig'\nis removed from the parameter list.\nSimilarly, the buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html#lnstructured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#LnStructured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L663",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#LnStructured.apply",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L756",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.apply",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L53",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.apply_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#LnStructured.compute_mask",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L686",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.compute_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/exceptions.html#IndexError",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.prune",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.compute_mask",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.CustomFromMask.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.RandomStructured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.CustomFromMask",
  "page_text": "CustomFromMask\n¶\nclass\ntorch.nn.utils.prune.\nCustomFromMask\n(\nmask\n)\n[source]\n[source]\n¶\nclassmethod\napply\n(\nmodule\n,\nname\n,\nmask\n)\n[source]\n[source]\n¶\nAdd pruning on the fly and reparametrization of a tensor.\nAdds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\napply_mask\n(\nmodule\n)\n[source]\n¶\nSimply handles the multiplication between the parameter being pruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nReturns\npruned version of the input tensor\nReturn type\npruned_tensor (\ntorch.Tensor\n)\nprune\n(\nt\n,\ndefault_mask\n=\nNone\n,\nimportance_scores\n=\nNone\n)\n[source]\n¶\nCompute and returns a pruned version of input tensor\nt\n.\nAccording to the pruning rule specified in\ncompute_mask()\n.\nParameters\nt\n(\ntorch.Tensor\n) – tensor to prune (of same dimensions as\ndefault_mask\n).\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of\nsame shape as\nt\n) used to compute mask for pruning\nt\n.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the\nt\nthat is being pruned.\nIf unspecified or None, the tensor\nt\nwill be used in its place.\ndefault_mask\n(\ntorch.Tensor\n,\noptional\n) – mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones.\nReturns\npruned version of tensor\nt\n.\nremove\n(\nmodule\n)\n[source]\n¶\nRemove the pruning reparameterization from a module.\nThe pruned parameter named\nname\nremains permanently pruned,\nand the parameter named\nname+'_orig'\nis removed from the parameter list.\nSimilarly, the buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.CustomFromMask.html#customfrommask",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#CustomFromMask",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L792",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#CustomFromMask.apply",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L803",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.apply",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L53",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.apply_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L204",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.prune",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L234",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.identity.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.LnStructured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.identity",
  "page_text": "torch.nn.utils.prune.identity\n¶\ntorch.nn.utils.prune.\nidentity\n(\nmodule\n,\nname\n)\n[source]\n[source]\n¶\nApply pruning reparametrization without pruning any units.\nApplies pruning reparametrization to the tensor corresponding to the\nparameter called\nname\nin\nmodule\nwithout actually pruning any\nunits. Modifies module in place (and also return the modified module)\nby:\nadding a named buffer called\nname+'_mask'\ncorresponding to the\nbinary mask applied to the parameter\nname\nby the pruning method.\nreplacing the parameter\nname\nby its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'\n.\nNote\nThe mask is a tensor of ones.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune.\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\nReturns\nmodified (i.e. pruned) version of the input module\nReturn type\nmodule (\nnn.Module\n)\nExamples\n>>>\nm\n=\nprune\n.\nidentity\n(\nnn\n.\nLinear\n(\n2\n,\n3\n),\n'bias'\n)\n>>>\nprint\n(\nm\n.\nbias_mask\n)\ntensor([1., 1., 1.])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.identity.html#torch-nn-utils-prune-identity",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#identity",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L819",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.identity.html#torch.nn.utils.prune.identity",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_unstructured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.CustomFromMask.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.random_unstructured",
  "page_text": "torch.nn.utils.prune.random_unstructured\n¶\ntorch.nn.utils.prune.\nrandom_unstructured\n(\nmodule\n,\nname\n,\namount\n)\n[source]\n[source]\n¶\nPrune tensor by removing random (currently unpruned) units.\nPrunes tensor corresponding to parameter called\nname\nin\nmodule\nby removing the specified\namount\nof (currently unpruned) units\nselected at random.\nModifies module in place (and also return the modified module) by:\nadding a named buffer called\nname+'_mask'\ncorresponding to the\nbinary mask applied to the parameter\nname\nby the pruning method.\nreplacing the parameter\nname\nby its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'\n.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nReturns\nmodified (i.e. pruned) version of the input module\nReturn type\nmodule (\nnn.Module\n)\nExamples\n>>>\nm\n=\nprune\n.\nrandom_unstructured\n(\nnn\n.\nLinear\n(\n2\n,\n3\n),\n'weight'\n,\namount\n=\n1\n)\n>>>\ntorch\n.\nsum\n(\nm\n.\nweight_mask\n==\n0\n)\ntensor(1)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_unstructured.html#torch-nn-utils-prune-random-unstructured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#random_unstructured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L854",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_unstructured.html#torch.nn.utils.prune.random_unstructured",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.l1_unstructured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.identity.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.l1_unstructured",
  "page_text": "torch.nn.utils.prune.l1_unstructured\n¶\ntorch.nn.utils.prune.\nl1_unstructured\n(\nmodule\n,\nname\n,\namount\n,\nimportance_scores\n=\nNone\n)\n[source]\n[source]\n¶\nPrune tensor by removing units with the lowest L1-norm.\nPrunes tensor corresponding to parameter called\nname\nin\nmodule\nby removing the specified\namount\nof (currently unpruned) units with the\nlowest L1-norm.\nModifies module in place (and also return the modified module)\nby:\nadding a named buffer called\nname+'_mask'\ncorresponding to the\nbinary mask applied to the parameter\nname\nby the pruning method.\nreplacing the parameter\nname\nby its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'\n.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of same\nshape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the corresponding\nelements in the parameter being pruned.\nIf unspecified or None, the module parameter will be used in its place.\nReturns\nmodified (i.e. pruned) version of the input module\nReturn type\nmodule (\nnn.Module\n)\nExamples\n>>>\nm\n=\nprune\n.\nl1_unstructured\n(\nnn\n.\nLinear\n(\n2\n,\n3\n),\n'weight'\n,\namount\n=\n0.2\n)\n>>>\nm\n.\nstate_dict\n()\n.\nkeys\n()\nodict_keys(['bias', 'weight_orig', 'weight_mask'])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.l1_unstructured.html#torch-nn-utils-prune-l1-unstructured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#l1_unstructured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L891",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.l1_unstructured.html#torch.nn.utils.prune.l1_unstructured",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_structured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_unstructured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.random_structured",
  "page_text": "torch.nn.utils.prune.random_structured\n¶\ntorch.nn.utils.prune.\nrandom_structured\n(\nmodule\n,\nname\n,\namount\n,\ndim\n)\n[source]\n[source]\n¶\nPrune tensor by removing random channels along the specified dimension.\nPrunes tensor corresponding to parameter called\nname\nin\nmodule\nby removing the specified\namount\nof (currently unpruned) channels\nalong the specified\ndim\nselected at random.\nModifies module in place (and also return the modified module)\nby:\nadding a named buffer called\nname+'_mask'\ncorresponding to the\nbinary mask applied to the parameter\nname\nby the pruning method.\nreplacing the parameter\nname\nby its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'\n.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\ndim\n(\nint\n) – index of the dim along which we define channels to prune.\nReturns\nmodified (i.e. pruned) version of the input module\nReturn type\nmodule (\nnn.Module\n)\nExamples\n>>>\nm\n=\nprune\n.\nrandom_structured\n(\n...\nnn\n.\nLinear\n(\n5\n,\n3\n),\n'weight'\n,\namount\n=\n3\n,\ndim\n=\n1\n...\n)\n>>>\ncolumns_pruned\n=\nint\n(\nsum\n(\ntorch\n.\nsum\n(\nm\n.\nweight\n,\ndim\n=\n0\n)\n==\n0\n))\n>>>\nprint\n(\ncolumns_pruned\n)\n3\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_structured.html#torch-nn-utils-prune-random-structured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#random_structured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L935",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_structured.html#torch.nn.utils.prune.random_structured",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.ln_structured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.l1_unstructured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.ln_structured",
  "page_text": "torch.nn.utils.prune.ln_structured\n¶\ntorch.nn.utils.prune.\nln_structured\n(\nmodule\n,\nname\n,\namount\n,\nn\n,\ndim\n,\nimportance_scores\n=\nNone\n)\n[source]\n[source]\n¶\nPrune tensor by removing channels with the lowest L\nn\n-norm along the specified dimension.\nPrunes tensor corresponding to parameter called\nname\nin\nmodule\nby removing the specified\namount\nof (currently unpruned) channels\nalong the specified\ndim\nwith the lowest L\nn\n-norm.\nModifies module in place (and also return the modified module)\nby:\nadding a named buffer called\nname+'_mask'\ncorresponding to the\nbinary mask applied to the parameter\nname\nby the pruning method.\nreplacing the parameter\nname\nby its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'\n.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\namount\n(\nint\nor\nfloat\n) – quantity of parameters to prune.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nn\n(\nint\n,\nfloat\n,\ninf\n,\n-inf\n,\n'fro'\n,\n'nuc'\n) – See documentation of valid\nentries for argument\np\nin\ntorch.norm()\n.\ndim\n(\nint\n) – index of the dim along which we define channels to prune.\nimportance_scores\n(\ntorch.Tensor\n) – tensor of importance scores (of same\nshape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the corresponding\nelements in the parameter being pruned.\nIf unspecified or None, the module parameter will be used in its place.\nReturns\nmodified (i.e. pruned) version of the input module\nReturn type\nmodule (\nnn.Module\n)\nExamples\n>>>\nfrom\ntorch.nn.utils\nimport\nprune\n>>>\nm\n=\nprune\n.\nln_structured\n(\n...\nnn\n.\nConv2d\n(\n5\n,\n3\n,\n2\n),\n'weight'\n,\namount\n=\n0.3\n,\ndim\n=\n1\n,\nn\n=\nfloat\n(\n'-inf'\n)\n...\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.ln_structured.html#torch-nn-utils-prune-ln-structured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#ln_structured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L976",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.ln_structured.html#torch.nn.utils.prune.ln_structured",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.global_unstructured.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.random_structured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.global_unstructured",
  "page_text": "torch.nn.utils.prune.global_unstructured\n¶\ntorch.nn.utils.prune.\nglobal_unstructured\n(\nparameters\n,\npruning_method\n,\nimportance_scores\n=\nNone\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nGlobally prunes tensors corresponding to all parameters in\nparameters\nby applying the specified\npruning_method\n.\nModifies modules in place by:\nadding a named buffer called\nname+'_mask'\ncorresponding to the\nbinary mask applied to the parameter\nname\nby the pruning method.\nreplacing the parameter\nname\nby its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'\n.\nParameters\nparameters\n(\nIterable\nof\n(\nmodule\n,\nname\n)\ntuples\n) – parameters of\nthe model to prune in a global fashion, i.e. by aggregating all\nweights prior to deciding which ones to prune. module must be of\ntype\nnn.Module\n, and name must be a string.\npruning_method\n(\nfunction\n) – a valid pruning function from this module,\nor a custom one implemented by the user that satisfies the\nimplementation guidelines and has\nPRUNING_TYPE='unstructured'\n.\nimportance_scores\n(\ndict\n) – a dictionary mapping (module, name) tuples to\nthe corresponding parameter’s importance scores tensor. The tensor\nshould be the same shape as the parameter, and is used for computing\nmask for pruning.\nIf unspecified or None, the parameter will be used in place of its\nimportance scores.\nkwargs\n– other keyword arguments such as:\namount (int or float): quantity of parameters to prune across the\nspecified parameters.\nIf\nfloat\n, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If\nint\n, it represents the\nabsolute number of parameters to prune.\nRaises\nTypeError\n– if\nPRUNING_TYPE\n!=\n'unstructured'\nNote\nSince global structured pruning doesn’t make much sense unless the\nnorm is normalized by the size of the parameter, we now limit the\nscope of global pruning to unstructured methods.\nExamples\n>>>\nfrom\ntorch.nn.utils\nimport\nprune\n>>>\nfrom\ncollections\nimport\nOrderedDict\n>>>\nnet\n=\nnn\n.\nSequential\n(\nOrderedDict\n([\n...\n(\n'first'\n,\nnn\n.\nLinear\n(\n10\n,\n4\n)),\n...\n(\n'second'\n,\nnn\n.\nLinear\n(\n4\n,\n1\n)),\n...\n]))\n>>>\nparameters_to_prune\n=\n(\n...\n(\nnet\n.\nfirst\n,\n'weight'\n),\n...\n(\nnet\n.\nsecond\n,\n'weight'\n),\n...\n)\n>>>\nprune\n.\nglobal_unstructured\n(\n...\nparameters_to_prune\n,\n...\npruning_method\n=\nprune\n.\nL1Unstructured\n,\n...\namount\n=\n10\n,\n...\n)\n>>>\nprint\n(\nsum\n(\ntorch\n.\nnn\n.\nutils\n.\nparameters_to_vector\n(\nnet\n.\nbuffers\n())\n==\n0\n))\ntensor(10)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.global_unstructured.html#torch-nn-utils-prune-global-unstructured",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#global_unstructured",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L1023",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.global_unstructured.html#torch.nn.utils.prune.global_unstructured",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://docs.python.org/3/library/exceptions.html#TypeError",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.custom_from_mask.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.ln_structured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.custom_from_mask",
  "page_text": "torch.nn.utils.prune.custom_from_mask\n¶\ntorch.nn.utils.prune.\ncustom_from_mask\n(\nmodule\n,\nname\n,\nmask\n)\n[source]\n[source]\n¶\nPrune tensor corresponding to parameter called\nname\nin\nmodule\nby applying the pre-computed mask in\nmask\n.\nModifies module in place (and also return the modified module) by:\nadding a named buffer called\nname+'_mask'\ncorresponding to the\nbinary mask applied to the parameter\nname\nby the pruning method.\nreplacing the parameter\nname\nby its pruned version, while the\noriginal (unpruned) parameter is stored in a new parameter named\nname+'_orig'\n.\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\nmask\n(\nTensor\n) – binary mask to be applied to the parameter.\nReturns\nmodified (i.e. pruned) version of the input module\nReturn type\nmodule (\nnn.Module\n)\nExamples\n>>>\nfrom\ntorch.nn.utils\nimport\nprune\n>>>\nm\n=\nprune\n.\ncustom_from_mask\n(\n...\nnn\n.\nLinear\n(\n5\n,\n3\n),\nname\n=\n'bias'\n,\nmask\n=\ntorch\n.\ntensor\n([\n0\n,\n1\n,\n0\n])\n...\n)\n>>>\nprint\n(\nm\n.\nbias_mask\n)\ntensor([0., 1., 0.])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.custom_from_mask.html#torch-nn-utils-prune-custom-from-mask",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#custom_from_mask",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L1142",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.custom_from_mask.html#torch.nn.utils.prune.custom_from_mask",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.remove.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.global_unstructured.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.remove",
  "page_text": "torch.nn.utils.prune.remove\n¶\ntorch.nn.utils.prune.\nremove\n(\nmodule\n,\nname\n)\n[source]\n[source]\n¶\nRemove the pruning reparameterization from a module and the pruning method from the forward hook.\nThe pruned parameter named\nname\nremains permanently pruned, and the parameter\nnamed\nname+'_orig'\nis removed from the parameter list. Similarly,\nthe buffer named\nname+'_mask'\nis removed from the buffers.\nNote\nPruning itself is NOT undone or reversed!\nParameters\nmodule\n(\nnn.Module\n) – module containing the tensor to prune\nname\n(\nstr\n) – parameter name within\nmodule\non which pruning\nwill act.\nExamples\n>>>\nm\n=\nrandom_unstructured\n(\nnn\n.\nLinear\n(\n5\n,\n7\n),\nname\n=\n'weight'\n,\namount\n=\n0.2\n)\n>>>\nm\n=\nremove\n(\nm\n,\nname\n=\n'weight'\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.remove.html#torch-nn-utils-prune-remove",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#remove",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L1175",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.remove.html#torch.nn.utils.prune.remove",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.is_pruned.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.custom_from_mask.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "prune.is_pruned",
  "page_text": "torch.nn.utils.prune.is_pruned\n¶\ntorch.nn.utils.prune.\nis_pruned\n(\nmodule\n)\n[source]\n[source]\n¶\nCheck if a module is pruned by looking for pruning pre-hooks.\nCheck whether\nmodule\nis pruned by looking for\nforward_pre_hooks\nin its modules that inherit from the\nBasePruningMethod\n.\nParameters\nmodule\n(\nnn.Module\n) – object that is either pruned or unpruned\nReturns\nbinary answer to whether\nmodule\nis pruned.\nExamples\n>>>\nfrom\ntorch.nn.utils\nimport\nprune\n>>>\nm\n=\nnn\n.\nLinear\n(\n5\n,\n7\n)\n>>>\nprint\n(\nprune\n.\nis_pruned\n(\nm\n))\nFalse\n>>>\nprune\n.\nrandom_unstructured\n(\nm\n,\nname\n=\n'weight'\n,\namount\n=\n0.2\n)\n>>>\nprint\n(\nprune\n.\nis_pruned\n(\nm\n))\nTrue\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.is_pruned.html#torch-nn-utils-prune-is-pruned",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/prune.html#is_pruned",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/prune.py#L1205",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.is_pruned.html#torch.nn.utils.prune.is_pruned",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.orthogonal.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.remove.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parametrizations.orthogonal",
  "page_text": "torch.nn.utils.parametrizations.orthogonal\n¶\ntorch.nn.utils.parametrizations.\northogonal\n(\nmodule\n,\nname\n=\n'weight'\n,\northogonal_map\n=\nNone\n,\n*\n,\nuse_trivialization\n=\nTrue\n)\n[source]\n[source]\n¶\nApply an orthogonal or unitary parametrization to a matrix or a batch of matrices.\nLetting\nK\n\\mathbb{K}\nK\nbe\nR\n\\mathbb{R}\nR\nor\nC\n\\mathbb{C}\nC\n, the parametrized\nmatrix\nQ\n∈\nK\nm\n×\nn\nQ \\in \\mathbb{K}^{m \\times n}\nQ\n∈\nK\nm\n×\nn\nis\northogonal\nas\nQ\nH\nQ\n=\nI\nn\nif\nm\n≥\nn\nQ\nQ\nH\n=\nI\nm\nif\nm\n<\nn\n\\begin{align*}\n    Q^{\\text{H}}Q &= \\mathrm{I}_n \\mathrlap{\\qquad \\text{if }m \\geq n}\\\\\n    QQ^{\\text{H}} &= \\mathrm{I}_m \\mathrlap{\\qquad \\text{if }m < n}\n\\end{align*}\nQ\nH\nQ\nQ\nQ\nH\n​\n=\nI\nn\n​\nif\nm\n≥\nn\n=\nI\nm\n​\nif\nm\n<\nn\n​\nwhere\nQ\nH\nQ^{\\text{H}}\nQ\nH\nis the conjugate transpose when\nQ\nQ\nQ\nis complex\nand the transpose when\nQ\nQ\nQ\nis real-valued, and\nI\nn\n\\mathrm{I}_n\nI\nn\n​\nis the\nn\n-dimensional identity matrix.\nIn plain words,\nQ\nQ\nQ\nwill have orthonormal columns whenever\nm\n≥\nn\nm \\geq n\nm\n≥\nn\nand orthonormal rows otherwise.\nIf the tensor has more than two dimensions, we consider it as a batch of matrices of shape\n(…, m, n)\n.\nThe matrix\nQ\nQ\nQ\nmay be parametrized via three different\northogonal_map\nin terms of the original tensor:\n\"matrix_exp\"\n/\n\"cayley\"\n:\nthe\nmatrix_exp()\nQ\n=\nexp\n⁡\n(\nA\n)\nQ = \\exp(A)\nQ\n=\nexp\n(\nA\n)\nand the\nCayley map\nQ\n=\n(\nI\nn\n+\nA\n/\n2\n)\n(\nI\nn\n−\nA\n/\n2\n)\n−\n1\nQ = (\\mathrm{I}_n + A/2)(\\mathrm{I}_n - A/2)^{-1}\nQ\n=\n(\nI\nn\n​\n+\nA\n/2\n)\n(\nI\nn\n​\n−\nA\n/2\n)\n−\n1\nare applied to a skew-symmetric\nA\nA\nA\nto give an orthogonal matrix.\n\"householder\"\n: computes a product of Householder reflectors\n(\nhouseholder_product()\n).\n\"matrix_exp\"\n/\n\"cayley\"\noften make the parametrized weight converge faster than\n\"householder\"\n, but they are slower to compute for very thin or very wide matrices.\nIf\nuse_trivialization=True\n(default), the parametrization implements the “Dynamic Trivialization Framework”,\nwhere an extra matrix\nB\n∈\nK\nn\n×\nn\nB \\in \\mathbb{K}^{n \\times n}\nB\n∈\nK\nn\n×\nn\nis stored under\nmodule.parametrizations.weight[0].base\n. This helps the\nconvergence of the parametrized layer at the expense of some extra memory use.\nSee\nTrivializations for Gradient-Based Optimization on Manifolds\n.\nInitial value of\nQ\nQ\nQ\n:\nIf the original tensor is not parametrized and\nuse_trivialization=True\n(default), the initial value\nof\nQ\nQ\nQ\nis that of the original tensor if it is orthogonal (or unitary in the complex case)\nand it is orthogonalized via the QR decomposition otherwise (see\ntorch.linalg.qr()\n).\nSame happens when it is not parametrized and\northogonal_map=\"householder\"\neven when\nuse_trivialization=False\n.\nOtherwise, the initial value is the result of the composition of all the registered\nparametrizations applied to the original tensor.\nNote\nThis function is implemented using the parametrization functionality\nin\nregister_parametrization()\n.\nParameters\nmodule\n(\nnn.Module\n) – module on which to register the parametrization.\nname\n(\nstr\n,\noptional\n) – name of the tensor to make orthogonal. Default:\n\"weight\"\n.\northogonal_map\n(\nstr\n,\noptional\n) – One of the following:\n\"matrix_exp\"\n,\n\"cayley\"\n,\n\"householder\"\n.\nDefault:\n\"matrix_exp\"\nif the matrix is square or complex,\n\"householder\"\notherwise.\nuse_trivialization\n(\nbool\n,\noptional\n) – whether to use the dynamic trivialization framework.\nDefault:\nTrue\n.\nReturns\nThe original module with an orthogonal parametrization registered to the specified\nweight\nReturn type\nModule\nExample:\n>>>\north_linear\n=\northogonal\n(\nnn\n.\nLinear\n(\n20\n,\n40\n))\n>>>\north_linear\nParametrizedLinear(\nin_features=20, out_features=40, bias=True\n(parametrizations): ModuleDict(\n(weight): ParametrizationList(\n(0): _Orthogonal()\n)\n)\n)\n>>>\nQ\n=\north_linear\n.\nweight\n>>>\ntorch\n.\ndist\n(\nQ\n.\nT\n@\nQ\n,\ntorch\n.\neye\n(\n20\n))\ntensor(4.9332e-07)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.orthogonal.html#torch-nn-utils-parametrizations-orthogonal",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrizations.html#orthogonal",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrizations.py#L191",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.orthogonal.html#torch.nn.utils.parametrizations.orthogonal",
    "https://pytorch.org/docs/stable/generated/torch.matrix_exp.html#torch.matrix_exp",
    "https://en.wikipedia.org/wiki/Cayley_transform#Matrix_map",
    "https://pytorch.org/docs/stable/generated/torch.linalg.householder_product.html#torch.linalg.householder_product",
    "https://arxiv.org/abs/1909.09501",
    "https://pytorch.org/docs/stable/generated/torch.linalg.qr.html#torch.linalg.qr",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.weight_norm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.prune.is_pruned.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parametrizations.weight_norm",
  "page_text": "torch.nn.utils.parametrizations.weight_norm\n¶\ntorch.nn.utils.parametrizations.\nweight_norm\n(\nmodule\n,\nname\n=\n'weight'\n,\ndim\n=\n0\n)\n[source]\n[source]\n¶\nApply weight normalization to a parameter in the given module.\nw\n=\ng\nv\n∥\nv\n∥\n\\mathbf{w} = g \\dfrac{\\mathbf{v}}{\\|\\mathbf{v}\\|}\nw\n=\ng\n∥\nv\n∥\nv\n​\nWeight normalization is a reparameterization that decouples the magnitude\nof a weight tensor from its direction. This replaces the parameter specified\nby\nname\nwith two parameters: one specifying the magnitude\nand one specifying the direction.\nBy default, with\ndim=0\n, the norm is computed independently per output\nchannel/plane. To compute a norm over the entire weight tensor, use\ndim=None\n.\nSee\nhttps://arxiv.org/abs/1602.07868\nParameters\nmodule\n(\nModule\n) – containing module\nname\n(\nstr\n,\noptional\n) – name of weight parameter\ndim\n(\nint\n,\noptional\n) – dimension over which to compute the norm\nReturns\nThe original module with the weight norm hook\nExample:\n>>>\nm\n=\nweight_norm\n(\nnn\n.\nLinear\n(\n20\n,\n40\n),\nname\n=\n'weight'\n)\n>>>\nm\nParametrizedLinear(\nin_features=20, out_features=40, bias=True\n(parametrizations): ModuleDict(\n(weight): ParametrizationList(\n(0): _WeightNorm()\n)\n)\n)\n>>>\nm\n.\nparametrizations\n.\nweight\n.\noriginal0\n.\nsize\n()\ntorch.Size([40, 1])\n>>>\nm\n.\nparametrizations\n.\nweight\n.\noriginal1\n.\nsize\n()\ntorch.Size([40, 20])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.weight_norm.html#torch-nn-utils-parametrizations-weight-norm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrizations.html#weight_norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrizations.py#L334",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.weight_norm.html#torch.nn.utils.parametrizations.weight_norm",
    "https://arxiv.org/abs/1602.07868",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.spectral_norm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.orthogonal.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parametrizations.spectral_norm",
  "page_text": "torch.nn.utils.parametrizations.spectral_norm\n¶\ntorch.nn.utils.parametrizations.\nspectral_norm\n(\nmodule\n,\nname\n=\n'weight'\n,\nn_power_iterations\n=\n1\n,\neps\n=\n1e-12\n,\ndim\n=\nNone\n)\n[source]\n[source]\n¶\nApply spectral normalization to a parameter in the given module.\nW\nS\nN\n=\nW\nσ\n(\nW\n)\n,\nσ\n(\nW\n)\n=\nmax\n⁡\nh\n:\nh\n≠\n0\n∥\nW\nh\n∥\n2\n∥\nh\n∥\n2\n\\mathbf{W}_{SN} = \\dfrac{\\mathbf{W}}{\\sigma(\\mathbf{W})},\n\\sigma(\\mathbf{W}) = \\max_{\\mathbf{h}: \\mathbf{h} \\ne 0} \\dfrac{\\|\\mathbf{W} \\mathbf{h}\\|_2}{\\|\\mathbf{h}\\|_2}\nW\nSN\n​\n=\nσ\n(\nW\n)\nW\n​\n,\nσ\n(\nW\n)\n=\nh\n:\nh\n\n=\n0\nmax\n​\n∥\nh\n∥\n2\n​\n∥\nWh\n∥\n2\n​\n​\nWhen applied on a vector, it simplifies to\nx\nS\nN\n=\nx\n∥\nx\n∥\n2\n\\mathbf{x}_{SN} = \\dfrac{\\mathbf{x}}{\\|\\mathbf{x}\\|_2}\nx\nSN\n​\n=\n∥\nx\n∥\n2\n​\nx\n​\nSpectral normalization stabilizes the training of discriminators (critics)\nin Generative Adversarial Networks (GANs) by reducing the Lipschitz constant\nof the model.\nσ\n\\sigma\nσ\nis approximated performing one iteration of the\npower method\nevery time the weight is accessed. If the dimension of the\nweight tensor is greater than 2, it is reshaped to 2D in power iteration\nmethod to get spectral norm.\nSee\nSpectral Normalization for Generative Adversarial Networks\n.\nNote\nThis function is implemented using the parametrization functionality\nin\nregister_parametrization()\n. It is a\nreimplementation of\ntorch.nn.utils.spectral_norm()\n.\nNote\nWhen this constraint is registered, the singular vectors associated to the largest\nsingular value are estimated rather than sampled at random. These are then updated\nperforming\nn_power_iterations\nof the\npower method\nwhenever the tensor\nis accessed with the module on\ntraining\nmode.\nNote\nIf the\n_SpectralNorm\nmodule, i.e.,\nmodule.parametrization.weight[idx]\n,\nis in training mode on removal, it will perform another power iteration.\nIf you’d like to avoid this iteration, set the module to eval mode\nbefore its removal.\nParameters\nmodule\n(\nnn.Module\n) – containing module\nname\n(\nstr\n,\noptional\n) – name of weight parameter. Default:\n\"weight\"\n.\nn_power_iterations\n(\nint\n,\noptional\n) – number of power iterations to\ncalculate spectral norm. Default:\n1\n.\neps\n(\nfloat\n,\noptional\n) – epsilon for numerical stability in\ncalculating norms. Default:\n1e-12\n.\ndim\n(\nint\n,\noptional\n) – dimension corresponding to number of outputs.\nDefault:\n0\n, except for modules that are instances of\nConvTranspose{1,2,3}d, when it is\n1\nReturns\nThe original module with a new parametrization registered to the specified\nweight\nReturn type\nModule\nExample:\n>>>\nsnm\n=\nspectral_norm\n(\nnn\n.\nLinear\n(\n20\n,\n40\n))\n>>>\nsnm\nParametrizedLinear(\nin_features=20, out_features=40, bias=True\n(parametrizations): ModuleDict(\n(weight): ParametrizationList(\n(0): _SpectralNorm()\n)\n)\n)\n>>>\ntorch\n.\nlinalg\n.\nmatrix_norm\n(\nsnm\n.\nweight\n,\n2\n)\ntensor(1.0081, grad_fn=<AmaxBackward0>)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.spectral_norm.html#torch-nn-utils-parametrizations-spectral-norm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrizations.html#spectral_norm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrizations.py#L527",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.spectral_norm.html#torch.nn.utils.parametrizations.spectral_norm",
    "https://en.wikipedia.org/wiki/Power_iteration",
    "https://arxiv.org/abs/1802.05957",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.spectral_norm.html#torch.nn.utils.spectral_norm",
    "https://en.wikipedia.org/wiki/Power_iteration",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.weight_norm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parametrize.register_parametrization",
  "page_text": "torch.nn.utils.parametrize.register_parametrization\n¶\ntorch.nn.utils.parametrize.\nregister_parametrization\n(\nmodule\n,\ntensor_name\n,\nparametrization\n,\n*\n,\nunsafe\n=\nFalse\n)\n[source]\n[source]\n¶\nRegister a parametrization to a tensor in a module.\nAssume that\ntensor_name=\"weight\"\nfor simplicity. When accessing\nmodule.weight\n,\nthe module will return the parametrized version\nparametrization(module.weight)\n.\nIf the original tensor requires a gradient, the backward pass will differentiate\nthrough\nparametrization\n, and the optimizer will update the tensor accordingly.\nThe first time that a module registers a parametrization, this function will add an attribute\nparametrizations\nto the module of type\nParametrizationList\n.\nThe list of parametrizations on the tensor\nweight\nwill be accessible under\nmodule.parametrizations.weight\n.\nThe original tensor will be accessible under\nmodule.parametrizations.weight.original\n.\nParametrizations may be concatenated by registering several parametrizations\non the same attribute.\nThe training mode of a registered parametrization is updated on registration\nto match the training mode of the host module\nParametrized parameters and buffers have an inbuilt caching system that can be activated\nusing the context manager\ncached()\n.\nA\nparametrization\nmay optionally implement a method with signature\ndef\nright_inverse\n(\nself\n,\nX\n:\nTensor\n)\n->\nUnion\n[\nTensor\n,\nSequence\n[\nTensor\n]]\nThis method is called on the unparametrized tensor when the first parametrization\nis registered to compute the initial value of the original tensor.\nIf this method is not implemented, the original tensor will be just the unparametrized tensor.\nIf all the parametrizations registered on a tensor implement\nright_inverse\nit is possible\nto initialize a parametrized tensor by assigning to it, as shown in the example below.\nIt is possible for the first parametrization to depend on several inputs.\nThis may be implemented returning a tuple of tensors from\nright_inverse\n(see the example implementation of a\nRankOne\nparametrization below).\nIn this case, the unconstrained tensors are also located under\nmodule.parametrizations.weight\nwith names\noriginal0\n,\noriginal1\n,…\nNote\nIf unsafe=False (default) both the forward and right_inverse methods will be called\nonce to perform a number of consistency checks.\nIf unsafe=True, then right_inverse will be called if the tensor is not parametrized,\nand nothing will be called otherwise.\nNote\nIn most situations,\nright_inverse\nwill be a function such that\nforward(right_inverse(X))\n==\nX\n(see\nright inverse\n).\nSometimes, when the parametrization is not surjective, it may be reasonable\nto relax this.\nWarning\nIf a parametrization depends on several inputs,\nregister_parametrization()\nwill register a number of new parameters. If such parametrization is registered\nafter the optimizer is created, these new parameters will need to be added manually\nto the optimizer. See\ntorch.Optimizer.add_param_group()\n.\nParameters\nmodule\n(\nnn.Module\n) – module on which to register the parametrization\ntensor_name\n(\nstr\n) – name of the parameter or buffer on which to register\nthe parametrization\nparametrization\n(\nnn.Module\n) – the parametrization to register\nKeyword Arguments\nunsafe\n(\nbool\n) – a boolean flag that denotes whether the parametrization\nmay change the dtype and shape of the tensor. Default:\nFalse\nWarning: the parametrization is not checked for consistency upon registration.\nEnable this flag at your own risk.\nRaises\nValueError\n– if the module does not have a parameter or a buffer named\ntensor_name\nReturn type\nModule\nExamples\n>>>\nimport\ntorch\n>>>\nimport\ntorch.nn\nas\nnn\n>>>\nimport\ntorch.nn.utils.parametrize\nas\nP\n>>>\n>>>\nclass\nSymmetric\n(\nnn\n.\nModule\n):\n>>>\ndef\nforward\n(\nself\n,\nX\n):\n>>>\nreturn\nX\n.\ntriu\n()\n+\nX\n.\ntriu\n(\n1\n)\n.\nT\n# Return a symmetric matrix\n>>>\n>>>\ndef\nright_inverse\n(\nself\n,\nA\n):\n>>>\nreturn\nA\n.\ntriu\n()\n>>>\n>>>\nm\n=\nnn\n.\nLinear\n(\n5\n,\n5\n)\n>>>\nP\n.\nregister_parametrization\n(\nm\n,\n\"weight\"\n,\nSymmetric\n())\n>>>\nprint\n(\ntorch\n.\nallclose\n(\nm\n.\nweight\n,\nm\n.\nweight\n.\nT\n))\n# m.weight is now symmetric\nTrue\n>>>\nA\n=\ntorch\n.\nrand\n(\n5\n,\n5\n)\n>>>\nA\n=\nA\n+\nA\n.\nT\n# A is now symmetric\n>>>\nm\n.\nweight\n=\nA\n# Initialize the weight to be the symmetric matrix A\n>>>\nprint\n(\ntorch\n.\nallclose\n(\nm\n.\nweight\n,\nA\n))\nTrue\n>>>\nclass\nRankOne\n(\nnn\n.\nModule\n):\n>>>\ndef\nforward\n(\nself\n,\nx\n,\ny\n):\n>>>\n# Form a rank 1 matrix multiplying two vectors\n>>>\nreturn\nx\n.\nunsqueeze\n(\n-\n1\n)\n@\ny\n.\nunsqueeze\n(\n-\n2\n)\n>>>\n>>>\ndef\nright_inverse\n(\nself\n,\nZ\n):\n>>>\n# Project Z onto the rank 1 matrices\n>>>\nU\n,\nS\n,\nVh\n=\ntorch\n.\nlinalg\n.\nsvd\n(\nZ\n,\nfull_matrices\n=\nFalse\n)\n>>>\n# Return rescaled singular vectors\n>>>\ns0_sqrt\n=\nS\n[\n0\n]\n.\nsqrt\n()\n.\nunsqueeze\n(\n-\n1\n)\n>>>\nreturn\nU\n[\n...\n,\n:,\n0\n]\n*\ns0_sqrt\n,\nVh\n[\n...\n,\n0\n,\n:]\n*\ns0_sqrt\n>>>\n>>>\nlinear_rank_one\n=\nP\n.\nregister_parametrization\n(\nnn\n.\nLinear\n(\n4\n,\n4\n),\n\"weight\"\n,\nRankOne\n())\n>>>\nprint\n(\ntorch\n.\nlinalg\n.\nmatrix_rank\n(\nlinear_rank_one\n.\nweight\n)\n.\nitem\n())\n1\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch-nn-utils-parametrize-register-parametrization",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrize.html#register_parametrization",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrize.py#L417",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.ParametrizationList.html#torch.nn.utils.parametrize.ParametrizationList",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.cached.html#torch.nn.utils.parametrize.cached",
    "https://en.wikipedia.org/wiki/Inverse_function#Right_inverses",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/exceptions.html#ValueError",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.remove_parametrizations.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrizations.spectral_norm.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parametrize.remove_parametrizations",
  "page_text": "torch.nn.utils.parametrize.remove_parametrizations\n¶\ntorch.nn.utils.parametrize.\nremove_parametrizations\n(\nmodule\n,\ntensor_name\n,\nleave_parametrized\n=\nTrue\n)\n[source]\n[source]\n¶\nRemove the parametrizations on a tensor in a module.\nIf\nleave_parametrized=True\n,\nmodule[tensor_name]\nwill be set to\nits current output. In this case, the parametrization shall not change the\ndtype\nof the tensor.\nIf\nleave_parametrized=False\n,\nmodule[tensor_name]\nwill be set to\nthe unparametrised tensor in\nmodule.parametrizations[tensor_name].original\n.\nThis is only possible when the parametrization depends on just one tensor.\nParameters\nmodule\n(\nnn.Module\n) – module from which remove the parametrization\ntensor_name\n(\nstr\n) – name of the parametrization to be removed\nleave_parametrized\n(\nbool\n,\noptional\n) – leave the attribute\ntensor_name\nparametrized.\nDefault:\nTrue\nReturns\nmodule\nReturn type\nModule\nRaises\nValueError\n– if\nmodule[tensor_name]\nis not parametrized\nValueError\n– if\nleave_parametrized=False\nand the parametrization depends on several tensors\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.remove_parametrizations.html#torch-nn-utils-parametrize-remove-parametrizations",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrize.html#remove_parametrizations",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrize.py#L653",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.remove_parametrizations.html#torch.nn.utils.parametrize.remove_parametrizations",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/exceptions.html#ValueError",
    "https://docs.python.org/3/library/exceptions.html#ValueError",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.cached.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parametrize.cached",
  "page_text": "torch.nn.utils.parametrize.cached\n¶\ntorch.nn.utils.parametrize.\ncached\n(\n)\n[source]\n[source]\n¶\nContext manager that enables the caching system within parametrizations registered with\nregister_parametrization()\n.\nThe value of the parametrized objects is computed and cached the first time\nthey are required when this context manager is active. The cached values are\ndiscarded when leaving the context manager.\nThis is useful when using a parametrized parameter more than once in the forward pass.\nAn example of this is when parametrizing the recurrent kernel of an RNN or when\nsharing weights.\nThe simplest way to activate the cache is by wrapping the forward pass of the neural network\nimport\ntorch.nn.utils.parametrize\nas\nP\n...\nwith\nP\n.\ncached\n():\noutput\n=\nmodel\n(\ninputs\n)\nin training and evaluation. One may also wrap the parts of the modules that use\nseveral times the parametrized tensors. For example, the loop of an RNN with a\nparametrized recurrent kernel:\nwith\nP\n.\ncached\n():\nfor\nx\nin\nxs\n:\nout_rnn\n=\nself\n.\nrnn_cell\n(\nx\n,\nout_rnn\n)\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.cached.html#torch-nn-utils-parametrize-cached",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrize.html#cached",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrize.py#L31",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.cached.html#torch.nn.utils.parametrize.cached",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.is_parametrized.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.remove_parametrizations.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parametrize.is_parametrized",
  "page_text": "torch.nn.utils.parametrize.is_parametrized\n¶\ntorch.nn.utils.parametrize.\nis_parametrized\n(\nmodule\n,\ntensor_name\n=\nNone\n)\n[source]\n[source]\n¶\nDetermine if a module has a parametrization.\nParameters\nmodule\n(\nnn.Module\n) – module to query\ntensor_name\n(\nstr\n,\noptional\n) – name of the parameter in the module\nDefault:\nNone\nReturns\nTrue\nif\nmodule\nhas a parametrization for the parameter named\ntensor_name\n,\nor if it has any parametrization when\ntensor_name\nis\nNone\n;\notherwise\nFalse\nReturn type\nbool\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.is_parametrized.html#torch-nn-utils-parametrize-is-parametrized",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrize.html#is_parametrized",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrize.py#L631",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.is_parametrized.html#torch.nn.utils.parametrize.is_parametrized",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.ParametrizationList.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.cached.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "parametrize.ParametrizationList",
  "page_text": "ParametrizationList\n¶\nclass\ntorch.nn.utils.parametrize.\nParametrizationList\n(\nmodules\n,\noriginal\n,\nunsafe\n=\nFalse\n)\n[source]\n[source]\n¶\nA sequential container that holds and manages the original parameters or buffers of a parametrized\ntorch.nn.Module\n.\nIt is the type of\nmodule.parametrizations[tensor_name]\nwhen\nmodule[tensor_name]\nhas been parametrized with\nregister_parametrization()\n.\nIf the first registered parametrization has a\nright_inverse\nthat returns one tensor or\ndoes not have a\nright_inverse\n(in which case we assume that\nright_inverse\nis the identity),\nit will hold the tensor under the name\noriginal\n.\nIf it has a\nright_inverse\nthat returns more than one tensor, these will be registered as\noriginal0\n,\noriginal1\n, …\nWarning\nThis class is used internally by\nregister_parametrization()\n. It is documented\nhere for completeness. It shall not be instantiated by the user.\nParameters\nmodules\n(\nsequence\n) – sequence of modules representing the parametrizations\noriginal\n(\nParameter\nor\nTensor\n) – parameter or buffer that is parametrized\nunsafe\n(\nbool\n) – a boolean flag that denotes whether the parametrization\nmay change the dtype and shape of the tensor. Default:\nFalse\nWarning: the parametrization is not checked for consistency upon registration.\nEnable this flag at your own risk.\nright_inverse\n(\nvalue\n)\n[source]\n[source]\n¶\nCall the\nright_inverse\nmethods of the parametrizations in the inverse registration order.\nThen, it stores the result in\nself.original\nif\nright_inverse\noutputs one tensor\nor in\nself.original0\n,\nself.original1\n, … if it outputs several.\nParameters\nvalue\n(\nTensor\n) – Value to which initialize the module\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.ParametrizationList.html#parametrizationlist",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrize.html#ParametrizationList",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrize.py#L92",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.ParametrizationList.html#torch.nn.utils.parametrize.ParametrizationList",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization",
    "https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/parametrize.html#ParametrizationList.right_inverse",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/parametrize.py#L232",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.ParametrizationList.html#torch.nn.utils.parametrize.ParametrizationList.right_inverse",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.stateless.functional_call.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.is_parametrized.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "stateless.functional_call",
  "page_text": "torch.nn.utils.stateless.functional_call\n¶\ntorch.nn.utils.stateless.\nfunctional_call\n(\nmodule\n,\nparameters_and_buffers\n,\nargs\n=\nNone\n,\nkwargs\n=\nNone\n,\n*\n,\ntie_weights\n=\nTrue\n,\nstrict\n=\nFalse\n)\n[source]\n[source]\n¶\nPerform a functional call on the module by replacing the module parameters and buffers with the provided ones.\nWarning\nThis API is deprecated as of PyTorch 2.0 and will be removed in a future\nversion of PyTorch. Please use\ntorch.func.functional_call()\ninstead,\nwhich is a drop-in replacement for this API.\nNote\nIf the module has active parametrizations, passing a value in the\nparameters_and_buffers\nargument with the name set to the regular parameter\nname will completely disable the parametrization.\nIf you want to apply the parametrization function to the value passed\nplease set the key as\n{submodule_name}.parametrizations.{parameter_name}.original\n.\nNote\nIf the module performs in-place operations on parameters/buffers, these will be reflected\nin the\nparameters_and_buffers\ninput.\nExample:\n>>>\na\n=\n{\n'foo'\n:\ntorch\n.\nzeros\n(())}\n>>>\nmod\n=\nFoo\n()\n# does self.foo = self.foo + 1\n>>>\nprint\n(\nmod\n.\nfoo\n)\n# tensor(0.)\n>>>\nfunctional_call\n(\nmod\n,\na\n,\ntorch\n.\nones\n(()))\n>>>\nprint\n(\nmod\n.\nfoo\n)\n# tensor(0.)\n>>>\nprint\n(\na\n[\n'foo'\n])\n# tensor(1.)\nNote\nIf the module has tied weights, whether or not functional_call respects the tying is determined by the\ntie_weights flag.\nExample:\n>>>\na\n=\n{\n'foo'\n:\ntorch\n.\nzeros\n(())}\n>>>\nmod\n=\nFoo\n()\n# has both self.foo and self.foo_tied which are tied. Returns x + self.foo + self.foo_tied\n>>>\nprint\n(\nmod\n.\nfoo\n)\n# tensor(1.)\n>>>\nmod\n(\ntorch\n.\nzeros\n(()))\n# tensor(2.)\n>>>\nfunctional_call\n(\nmod\n,\na\n,\ntorch\n.\nzeros\n(()))\n# tensor(0.) since it will change self.foo_tied too\n>>>\nfunctional_call\n(\nmod\n,\na\n,\ntorch\n.\nzeros\n(()),\ntie_weights\n=\nFalse\n)\n# tensor(1.)--self.foo_tied is not updated\n>>>\nnew_a\n=\n{\n'foo'\n:\ntorch\n.\nzeros\n(()),\n'foo_tied'\n:\ntorch\n.\nzeros\n(())}\n>>>\nfunctional_call\n(\nmod\n,\nnew_a\n,\ntorch\n.\nzeros\n())\n# tensor(0.)\nParameters\nmodule\n(\ntorch.nn.Module\n) – the module to call\nparameters_and_buffers\n(\ndict\nof\nstr and Tensor\n) – the parameters that will be used in\nthe module call.\nargs\n(\nAny\nor\ntuple\n) – arguments to be passed to the module call. If not a tuple, considered a single argument.\nkwargs\n(\ndict\n) – keyword arguments to be passed to the module call\ntie_weights\n(\nbool\n,\noptional\n) – If True, then parameters and buffers tied in the original model will be treated as\ntied in the reparamaterized version. Therefore, if True and different values are passed for the tied\nparameters and buffers, it will error. If False, it will not respect the originally tied parameters and\nbuffers unless the values passed for both weights are the same. Default: True.\nstrict\n(\nbool\n,\noptional\n) – If True, then the parameters and buffers passed in must match the parameters and\nbuffers in the original module. Therefore, if True and there are any missing or unexpected keys, it will\nerror. Default: False.\nReturns\nthe result of calling\nmodule\n.\nReturn type\nAny\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.stateless.functional_call.html#torch-nn-utils-stateless-functional-call",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/stateless.html#functional_call",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/stateless.py#L180",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.stateless.functional_call.html#torch.nn.utils.stateless.functional_call",
    "https://pytorch.org/docs/stable/generated/torch.func.functional_call.html#torch.func.functional_call",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://docs.python.org/3/library/stdtypes.html#tuple",
    "https://docs.python.org/3/library/stdtypes.html#dict",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.parametrize.ParametrizationList.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.utils.rnn.PackedSequence",
  "page_text": "PackedSequence\n¶\nclass\ntorch.nn.utils.rnn.\nPackedSequence\n(\ndata\n,\nbatch_sizes\n=\nNone\n,\nsorted_indices\n=\nNone\n,\nunsorted_indices\n=\nNone\n)\n[source]\n[source]\n¶\nHolds the data and list of\nbatch_sizes\nof a packed sequence.\nAll RNN modules accept packed sequences as inputs.\nNote\nInstances of this class should never be created manually. They are meant\nto be instantiated by functions like\npack_padded_sequence()\n.\nBatch sizes represent the number elements at each sequence step in\nthe batch, not the varying sequence lengths passed to\npack_padded_sequence()\n.  For instance, given data\nabc\nand\nx\nthe\nPackedSequence\nwould contain data\naxbc\nwith\nbatch_sizes=[2,1,1]\n.\nVariables\ndata\n(\nTensor\n) – Tensor containing packed sequence\nbatch_sizes\n(\nTensor\n) – Tensor of integers holding\ninformation about the batch size at each sequence step\nsorted_indices\n(\nTensor\n,\noptional\n) – Tensor of integers holding how this\nPackedSequence\nis constructed from sequences.\nunsorted_indices\n(\nTensor\n,\noptional\n) – Tensor of integers holding how this\nto recover the original sequences with correct order.\nReturn type\nSelf\nNote\ndata\ncan be on arbitrary device and of arbitrary dtype.\nsorted_indices\nand\nunsorted_indices\nmust be\ntorch.int64\ntensors on the same device as\ndata\n.\nHowever,\nbatch_sizes\nshould always be a CPU\ntorch.int64\ntensor.\nThis invariant is maintained throughout\nPackedSequence\nclass,\nand all functions that construct a\nPackedSequence\nin PyTorch\n(i.e., they only pass in tensors conforming to this constraint).\nbatch_sizes\n:\nTensor\n¶\nAlias for field number 1\ncount\n(\nvalue\n,\n/\n)\n¶\nReturn number of occurrences of value.\ndata\n:\nTensor\n¶\nAlias for field number 0\nindex\n(\nvalue\n,\nstart\n=\n0\n,\nstop\n=\n9223372036854775807\n,\n/\n)\n¶\nReturn first index of value.\nRaises ValueError if the value is not present.\nproperty\nis_cuda\n:\nbool\n¶\nReturn true if\nself.data\nstored on a gpu.\nis_pinned\n(\n)\n[source]\n[source]\n¶\nReturn true if\nself.data\nstored on in pinned memory.\nReturn type\nbool\nsorted_indices\n:\nOptional\n[\nTensor\n]\n¶\nAlias for field number 2\nto\n(\ndtype\n:\ndtype\n,\nnon_blocking\n:\nbool\n=\n...\n,\ncopy\n:\nbool\n=\n...\n)\n→\nSelf\n[source]\n[source]\n¶\nto\n(\ndevice\n:\nOptional\n[\nUnion\n[\nstr\n,\ndevice\n,\nint\n]\n]\n=\n...\n,\ndtype\n:\nOptional\n[\ndtype\n]\n=\n...\n,\nnon_blocking\n:\nbool\n=\n...\n,\ncopy\n:\nbool\n=\n...\n)\n→\nSelf\nto\n(\nother\n:\nTensor\n,\nnon_blocking\n:\nbool\n=\n...\n,\ncopy\n:\nbool\n=\n...\n)\n→\nSelf\nPerform dtype and/or device conversion on\nself.data\n.\nIt has similar signature as\ntorch.Tensor.to()\n, except optional\narguments like\nnon_blocking\nand\ncopy\nshould be passed as kwargs,\nnot args, or they will not apply to the index tensors.\nNote\nIf the\nself.data\nTensor already has the correct\ntorch.dtype\nand\ntorch.device\n, then\nself\nis returned.\nOtherwise, returns a copy with the desired configuration.\nunsorted_indices\n:\nOptional\n[\nTensor\n]\n¶\nAlias for field number 3\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#packedsequence",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#PackedSequence",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L48",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.batch_sizes",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.data",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.sorted_indices",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.unsorted_indices",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.data",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.batch_sizes",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.batch_sizes",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.count",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.data",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.index",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.is_cuda",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#PackedSequence.is_pinned",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L219",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.is_pinned",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.sorted_indices",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#PackedSequence.to",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L140",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.to",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/typing.html#typing.Union",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype",
    "https://pytorch.org/docs/stable/tensor_attributes.html#torch.device",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.unsorted_indices",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.stateless.functional_call.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.utils.rnn.pack_padded_sequence",
  "page_text": "torch.nn.utils.rnn.pack_padded_sequence\n¶\ntorch.nn.utils.rnn.\npack_padded_sequence\n(\ninput\n,\nlengths\n,\nbatch_first\n=\nFalse\n,\nenforce_sorted\n=\nTrue\n)\n[source]\n[source]\n¶\nPacks a Tensor containing padded sequences of variable length.\ninput\ncan be of size\nT\nx\nB\nx\n*\n(if\nbatch_first\nis\nFalse\n)\nor\nB\nx\nT\nx\n*\n(if\nbatch_first\nis\nTrue\n) where\nT\nis the length\nof the longest sequence,\nB\nis the batch size, and\n*\nis any number of dimensions\n(including 0).\nFor unsorted sequences, use\nenforce_sorted = False\n. If\nenforce_sorted\nis\nTrue\n, the sequences should be sorted by length in a decreasing order, i.e.\ninput[:,0]\nshould be the longest sequence, and\ninput[:,B-1]\nthe shortest\none.\nenforce_sorted = True\nis only necessary for ONNX export.\nIt is an inverse operation to\npad_packed_sequence()\n, and hence\npad_packed_sequence()\ncan be used to recover the underlying tensor packed in\nPackedSequence\n.\nNote\nThis function accepts any input that has at least two dimensions. You\ncan apply it to pack the labels, and use the output of the RNN with\nthem to compute the loss directly. A Tensor can be retrieved from\na\nPackedSequence\nobject by accessing its\n.data\nattribute.\nParameters\ninput\n(\nTensor\n) – padded batch of variable length sequences.\nlengths\n(\nTensor\nor\nlist\n(\nint\n)\n) – list of sequence lengths of each batch\nelement (must be on the CPU if provided as a tensor).\nbatch_first\n(\nbool\n,\noptional\n) – if\nTrue\n, the input is expected in\nB\nx\nT\nx\n*\nformat,\nT\nx\nB\nx\n*\notherwise.\nenforce_sorted\n(\nbool\n,\noptional\n) – if\nTrue\n, the input is expected to\ncontain sequences sorted by length in a decreasing order. If\nFalse\n, the input will get sorted unconditionally. Default:\nTrue\n.\nReturns\na\nPackedSequence\nobject\nReturn type\nPackedSequence\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch-nn-utils-rnn-pack-padded-sequence",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#pack_padded_sequence",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L280",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html#torch.nn.utils.rnn.pad_packed_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html#torch.nn.utils.rnn.pad_packed_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.utils.rnn.pad_packed_sequence",
  "page_text": "torch.nn.utils.rnn.pad_packed_sequence\n¶\ntorch.nn.utils.rnn.\npad_packed_sequence\n(\nsequence\n,\nbatch_first\n=\nFalse\n,\npadding_value\n=\n0.0\n,\ntotal_length\n=\nNone\n)\n[source]\n[source]\n¶\nPad a packed batch of variable length sequences.\nIt is an inverse operation to\npack_padded_sequence()\n.\nThe returned Tensor’s data will be of size\nT\nx\nB\nx\n*\n(if\nbatch_first\nis\nFalse\n)\nor\nB\nx\nT\nx\n*\n(if\nbatch_first\nis\nTrue\n) , where\nT\nis the length of the longest\nsequence and\nB\nis the batch size.\nExample\n>>>\nfrom\ntorch.nn.utils.rnn\nimport\npack_padded_sequence\n,\npad_packed_sequence\n>>>\nseq\n=\ntorch\n.\ntensor\n([[\n1\n,\n2\n,\n0\n],\n[\n3\n,\n0\n,\n0\n],\n[\n4\n,\n5\n,\n6\n]])\n>>>\nlens\n=\n[\n2\n,\n1\n,\n3\n]\n>>>\npacked\n=\npack_padded_sequence\n(\nseq\n,\nlens\n,\nbatch_first\n=\nTrue\n,\nenforce_sorted\n=\nFalse\n)\n>>>\npacked\nPackedSequence(data=tensor([4, 1, 3, 5, 2, 6]), batch_sizes=tensor([3, 2, 1]),\nsorted_indices=tensor([2, 0, 1]), unsorted_indices=tensor([1, 2, 0]))\n>>>\nseq_unpacked\n,\nlens_unpacked\n=\npad_packed_sequence\n(\npacked\n,\nbatch_first\n=\nTrue\n)\n>>>\nseq_unpacked\ntensor([[1, 2, 0],\n[3, 0, 0],\n[4, 5, 6]])\n>>>\nlens_unpacked\ntensor([2, 1, 3])\nNote\ntotal_length\nis useful to implement the\npack\nsequence\n->\nrecurrent\nnetwork\n->\nunpack\nsequence\npattern in a\nModule\nwrapped in\nDataParallel\n.\nSee\nthis FAQ section\nfor\ndetails.\nParameters\nsequence\n(\nPackedSequence\n) – batch to pad\nbatch_first\n(\nbool\n,\noptional\n) – if\nTrue\n, the output will be in\nB\nx\nT\nx\n*\nformat,\nT\nx\nB\nx\n*\notherwise.\npadding_value\n(\nfloat\n,\noptional\n) – values for padded elements.\ntotal_length\n(\nint\n,\noptional\n) – if not\nNone\n, the output will be padded to\nhave length\ntotal_length\n. This method will throw\nValueError\nif\ntotal_length\nis less than the max sequence length in\nsequence\n.\nReturns\nTuple of Tensor containing the padded sequence, and a Tensor\ncontaining the list of lengths of each sequence in the batch.\nBatch elements will be re-ordered as they were ordered originally when\nthe batch was passed to\npack_padded_sequence\nor\npack_sequence\n.\nReturn type\nTuple\n[\nTensor\n,\nTensor\n]\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html#torch-nn-utils-rnn-pad-packed-sequence",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#pad_packed_sequence",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L345",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html#torch.nn.utils.rnn.pad_packed_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module",
    "https://pytorch.org/docs/stable/generated/torch.nn.DataParallel.html#torch.nn.DataParallel",
    "https://pytorch.org/docs/stable/notes/faq.html#pack-rnn-unpack-with-data-parallelism",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/exceptions.html#ValueError",
    "https://docs.python.org/3/library/typing.html#typing.Tuple",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.utils.rnn.pad_sequence",
  "page_text": "torch.nn.utils.rnn.pad_sequence\n¶\ntorch.nn.utils.rnn.\npad_sequence\n(\nsequences\n,\nbatch_first\n=\nFalse\n,\npadding_value\n=\n0.0\n,\npadding_side\n=\n'right'\n)\n[source]\n[source]\n¶\nPad a list of variable length Tensors with\npadding_value\n.\npad_sequence\nstacks a list of Tensors along a new dimension, and pads them\nto equal length.\nsequences\ncan be list of sequences with size\nL\nx\n*\n,\nwhere\nL\nis length of the sequence and\n*\nis any number of dimensions\n(including 0). If\nbatch_first\nis\nFalse\n, the output is of size\nT\nx\nB\nx\n*\n, and\nB\nx\nT\nx\n*\notherwise, where\nB\nis the batch size\n(the number of elements in\nsequences\n),\nT\nis the length of the longest\nsequence.\nExample\n>>>\nfrom\ntorch.nn.utils.rnn\nimport\npad_sequence\n>>>\na\n=\ntorch\n.\nones\n(\n25\n,\n300\n)\n>>>\nb\n=\ntorch\n.\nones\n(\n22\n,\n300\n)\n>>>\nc\n=\ntorch\n.\nones\n(\n15\n,\n300\n)\n>>>\npad_sequence\n([\na\n,\nb\n,\nc\n])\n.\nsize\n()\ntorch.Size([25, 3, 300])\nNote\nThis function returns a Tensor of size\nT\nx\nB\nx\n*\nor\nB\nx\nT\nx\n*\nwhere\nT\nis the length of the longest sequence. This function assumes\ntrailing dimensions and type of all the Tensors in sequences are same.\nParameters\nsequences\n(\nlist\n[\nTensor\n]\n) – list of variable length sequences.\nbatch_first\n(\nbool\n,\noptional\n) – if\nTrue\n, the output will be in\nB\nx\nT\nx\n*\nformat,\nT\nx\nB\nx\n*\notherwise.\npadding_value\n(\nfloat\n,\noptional\n) – value for padded elements. Default: 0.\npadding_side\n(\nstr\n,\noptional\n) – the side to pad the sequences on.\nDefault: “right”.\nReturns\nTensor of size\nT\nx\nB\nx\n*\nif\nbatch_first\nis\nFalse\n.\nTensor of size\nB\nx\nT\nx\n*\notherwise\nReturn type\nTensor\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html#torch-nn-utils-rnn-pad-sequence",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#pad_sequence",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L421",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html#torch.nn.utils.rnn.pad_sequence",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_packed_sequence.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.utils.rnn.pack_sequence",
  "page_text": "torch.nn.utils.rnn.pack_sequence\n¶\ntorch.nn.utils.rnn.\npack_sequence\n(\nsequences\n,\nenforce_sorted\n=\nTrue\n)\n[source]\n[source]\n¶\nPacks a list of variable length Tensors.\nConsecutive call of the next functions:\npad_sequence\n,\npack_padded_sequence\n.\nsequences\nshould be a list of Tensors of size\nL\nx\n*\n, where\nL\nis\nthe length of a sequence and\n*\nis any number of trailing dimensions,\nincluding zero.\nFor unsorted sequences, use\nenforce_sorted = False\n. If\nenforce_sorted\nis\nTrue\n, the sequences should be sorted in the order of decreasing length.\nenforce_sorted\n=\nTrue\nis only necessary for ONNX export.\nExample\n>>>\nfrom\ntorch.nn.utils.rnn\nimport\npack_sequence\n>>>\na\n=\ntorch\n.\ntensor\n([\n1\n,\n2\n,\n3\n])\n>>>\nb\n=\ntorch\n.\ntensor\n([\n4\n,\n5\n])\n>>>\nc\n=\ntorch\n.\ntensor\n([\n6\n])\n>>>\npack_sequence\n([\na\n,\nb\n,\nc\n])\nPackedSequence(data=tensor([1, 4, 6, 2, 5, 3]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)\nParameters\nsequences\n(\nlist\n[\nTensor\n]\n) – A list of sequences of decreasing length.\nenforce_sorted\n(\nbool\n,\noptional\n) – if\nTrue\n, checks that the input\ncontains sequences sorted by length in a decreasing order. If\nFalse\n, this condition is not checked. Default:\nTrue\n.\nReturns\na\nPackedSequence\nobject\nReturn type\nPackedSequence\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch-nn-utils-rnn-pack-sequence",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#pack_sequence",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L535",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.unpack_sequence.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.utils.rnn.unpack_sequence",
  "page_text": "torch.nn.utils.rnn.unpack_sequence\n¶\ntorch.nn.utils.rnn.\nunpack_sequence\n(\npacked_sequences\n)\n[source]\n[source]\n¶\nUnpack PackedSequence into a list of variable length Tensors.\npacked_sequences\nshould be a PackedSequence object.\nExample\n>>>\nfrom\ntorch.nn.utils.rnn\nimport\npack_sequence\n,\nunpack_sequence\n>>>\na\n=\ntorch\n.\ntensor\n([\n1\n,\n2\n,\n3\n])\n>>>\nb\n=\ntorch\n.\ntensor\n([\n4\n,\n5\n])\n>>>\nc\n=\ntorch\n.\ntensor\n([\n6\n])\n>>>\nsequences\n=\n[\na\n,\nb\n,\nc\n]\n>>>\nprint\n(\nsequences\n)\n[tensor([1, 2, 3]), tensor([4, 5]), tensor([6])]\n>>>\npacked_sequences\n=\npack_sequence\n(\nsequences\n)\n>>>\nprint\n(\npacked_sequences\n)\nPackedSequence(data=tensor([1, 4, 6, 2, 5, 3]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n>>>\nunpacked_sequences\n=\nunpack_sequence\n(\npacked_sequences\n)\n>>>\nprint\n(\nunpacked_sequences\n)\n[tensor([1, 2, 3]), tensor([4, 5]), tensor([6])]\nParameters\npacked_sequences\n(\nPackedSequence\n) – A PackedSequence object.\nReturns\na list of\nTensor\nobjects\nReturn type\nList\n[\nTensor\n]\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.unpack_sequence.html#torch-nn-utils-rnn-unpack-sequence",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#unpack_sequence",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L574",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.unpack_sequence.html#torch.nn.utils.rnn.unpack_sequence",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence",
    "https://docs.python.org/3/library/typing.html#typing.List",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.unpad_sequence.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_sequence.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.utils.rnn.unpad_sequence",
  "page_text": "torch.nn.utils.rnn.unpad_sequence\n¶\ntorch.nn.utils.rnn.\nunpad_sequence\n(\npadded_sequences\n,\nlengths\n,\nbatch_first\n=\nFalse\n)\n[source]\n[source]\n¶\nUnpad padded Tensor into a list of variable length Tensors.\nunpad_sequence\nunstacks padded Tensor into a list of variable length Tensors.\nExample\n>>>\nfrom\ntorch.nn.utils.rnn\nimport\npad_sequence\n,\nunpad_sequence\n>>>\na\n=\ntorch\n.\nones\n(\n25\n,\n300\n)\n>>>\nb\n=\ntorch\n.\nones\n(\n22\n,\n300\n)\n>>>\nc\n=\ntorch\n.\nones\n(\n15\n,\n300\n)\n>>>\nsequences\n=\n[\na\n,\nb\n,\nc\n]\n>>>\npadded_sequences\n=\npad_sequence\n(\nsequences\n)\n>>>\nlengths\n=\ntorch\n.\nas_tensor\n([\nv\n.\nsize\n(\n0\n)\nfor\nv\nin\nsequences\n])\n>>>\nunpadded_sequences\n=\nunpad_sequence\n(\npadded_sequences\n,\nlengths\n)\n>>>\ntorch\n.\nallclose\n(\nsequences\n[\n0\n],\nunpadded_sequences\n[\n0\n])\nTrue\n>>>\ntorch\n.\nallclose\n(\nsequences\n[\n1\n],\nunpadded_sequences\n[\n1\n])\nTrue\n>>>\ntorch\n.\nallclose\n(\nsequences\n[\n2\n],\nunpadded_sequences\n[\n2\n])\nTrue\nParameters\npadded_sequences\n(\nTensor\n) – padded sequences.\nlengths\n(\nTensor\n) – length of original (unpadded) sequences.\nbatch_first\n(\nbool\n,\noptional\n) – whether batch dimension first or not. Default: False.\nReturns\na list of\nTensor\nobjects\nReturn type\nList\n[\nTensor\n]\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.unpad_sequence.html#torch-nn-utils-rnn-unpad-sequence",
    "https://pytorch.org/docs/stable/_modules/torch/nn/utils/rnn.html#unpad_sequence",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/utils/rnn.py#L486",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.unpad_sequence.html#torch.nn.utils.rnn.unpad_sequence",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://docs.python.org/3/library/typing.html#typing.List",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.unpack_sequence.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Flatten",
  "page_text": "Flatten\n¶\nclass\ntorch.nn.\nFlatten\n(\nstart_dim\n=\n1\n,\nend_dim\n=\n-1\n)\n[source]\n[source]\n¶\nFlattens a contiguous range of dims into a tensor.\nFor use with\nSequential\n, see\ntorch.flatten()\nfor details.\nShape:\nInput:\n(\n∗\n,\nS\nstart\n,\n.\n.\n.\n,\nS\ni\n,\n.\n.\n.\n,\nS\nend\n,\n∗\n)\n(*, S_{\\text{start}},..., S_{i}, ..., S_{\\text{end}}, *)\n(\n∗\n,\nS\nstart\n​\n,\n...\n,\nS\ni\n​\n,\n...\n,\nS\nend\n​\n,\n∗\n)\n,’\nwhere\nS\ni\nS_{i}\nS\ni\n​\nis the size at dimension\ni\ni\ni\nand\n∗\n*\n∗\nmeans any\nnumber of dimensions including none.\nOutput:\n(\n∗\n,\n∏\ni\n=\nstart\nend\nS\ni\n,\n∗\n)\n(*, \\prod_{i=\\text{start}}^{\\text{end}} S_{i}, *)\n(\n∗\n,\n∏\ni\n=\nstart\nend\n​\nS\ni\n​\n,\n∗\n)\n.\nParameters\nstart_dim\n(\nint\n) – first dim to flatten (default = 1).\nend_dim\n(\nint\n) – last dim to flatten (default = -1).\nExamples::\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n32\n,\n1\n,\n5\n,\n5\n)\n>>>\n# With default parameters\n>>>\nm\n=\nnn\n.\nFlatten\n()\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\noutput\n.\nsize\n()\ntorch.Size([32, 25])\n>>>\n# With non-default parameters\n>>>\nm\n=\nnn\n.\nFlatten\n(\n0\n,\n2\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\noutput\n.\nsize\n()\ntorch.Size([160, 5])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#flatten",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/flatten.html#Flatten",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/flatten.py#L13",
    "https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten",
    "https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/functions.html#int",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unflatten.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.unpad_sequence.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.Unflatten",
  "page_text": "Unflatten\n¶\nclass\ntorch.nn.\nUnflatten\n(\ndim\n,\nunflattened_size\n)\n[source]\n[source]\n¶\nUnflattens a tensor dim expanding it to a desired shape. For use with\nSequential\n.\ndim\nspecifies the dimension of the input tensor to be unflattened, and it can\nbe either\nint\nor\nstr\nwhen\nTensor\nor\nNamedTensor\nis used, respectively.\nunflattened_size\nis the new shape of the unflattened dimension of the tensor and it can be\na\ntuple\nof ints or a\nlist\nof ints or\ntorch.Size\nfor\nTensor\ninput;  a\nNamedShape\n(tuple of\n(name, size)\ntuples) for\nNamedTensor\ninput.\nShape:\nInput:\n(\n∗\n,\nS\ndim\n,\n∗\n)\n(*, S_{\\text{dim}}, *)\n(\n∗\n,\nS\ndim\n​\n,\n∗\n)\n, where\nS\ndim\nS_{\\text{dim}}\nS\ndim\n​\nis the size at\ndimension\ndim\nand\n∗\n*\n∗\nmeans any number of dimensions including none.\nOutput:\n(\n∗\n,\nU\n1\n,\n.\n.\n.\n,\nU\nn\n,\n∗\n)\n(*, U_1, ..., U_n, *)\n(\n∗\n,\nU\n1\n​\n,\n...\n,\nU\nn\n​\n,\n∗\n)\n, where\nU\nU\nU\n=\nunflattened_size\nand\n∏\ni\n=\n1\nn\nU\ni\n=\nS\ndim\n\\prod_{i=1}^n U_i = S_{\\text{dim}}\n∏\ni\n=\n1\nn\n​\nU\ni\n​\n=\nS\ndim\n​\n.\nParameters\ndim\n(\nUnion\n[\nint\n,\nstr\n]\n) – Dimension to be unflattened\nunflattened_size\n(\nUnion\n[\ntorch.Size\n,\nTuple\n,\nList\n,\nNamedShape\n]\n) – New shape of the unflattened dimension\nExamples\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n50\n)\n>>>\n# With tuple of ints\n>>>\nm\n=\nnn\n.\nSequential\n(\n>>>\nnn\n.\nLinear\n(\n50\n,\n50\n),\n>>>\nnn\n.\nUnflatten\n(\n1\n,\n(\n2\n,\n5\n,\n5\n))\n>>>\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\noutput\n.\nsize\n()\ntorch.Size([2, 2, 5, 5])\n>>>\n# With torch.Size\n>>>\nm\n=\nnn\n.\nSequential\n(\n>>>\nnn\n.\nLinear\n(\n50\n,\n50\n),\n>>>\nnn\n.\nUnflatten\n(\n1\n,\ntorch\n.\nSize\n([\n2\n,\n5\n,\n5\n]))\n>>>\n)\n>>>\noutput\n=\nm\n(\ninput\n)\n>>>\noutput\n.\nsize\n()\ntorch.Size([2, 2, 5, 5])\n>>>\n# With namedshape (tuple of tuples)\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n50\n,\nnames\n=\n(\n'N'\n,\n'features'\n))\n>>>\nunflatten\n=\nnn\n.\nUnflatten\n(\n'features'\n,\n((\n'C'\n,\n2\n),\n(\n'H'\n,\n5\n),\n(\n'W'\n,\n5\n)))\n>>>\noutput\n=\nunflatten\n(\ninput\n)\n>>>\noutput\n.\nsize\n()\ntorch.Size([2, 2, 5, 5])\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Unflatten.html#unflatten",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/flatten.html#Unflatten",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/flatten.py#L59",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unflatten.html#torch.nn.Unflatten",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/size.html#torch.Size",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.modules.lazy.LazyModuleMixin",
  "page_text": "LazyModuleMixin\n¶\nclass\ntorch.nn.modules.lazy.\nLazyModuleMixin\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nA mixin for modules that lazily initialize parameters, also known as “lazy modules”.\nModules that lazily initialize parameters, or “lazy modules”,\nderive the shapes of their parameters from the first input(s)\nto their forward method. Until that first forward they contain\ntorch.nn.UninitializedParameter\ns that should not be accessed\nor used, and afterward they contain regular\ntorch.nn.Parameter\ns.\nLazy modules are convenient since they don’t require computing some\nmodule arguments, like the\nin_features\nargument of a\ntypical\ntorch.nn.Linear\n.\nAfter construction, networks with lazy modules should first\nbe converted to the desired dtype and placed on the expected device.\nThis is because lazy modules only perform shape inference so the usual dtype\nand device placement behavior applies.\nThe lazy modules should then perform “dry runs” to initialize all the components in the module.\nThese “dry runs” send inputs of the correct size, dtype, and device through\nthe network and to each one of its lazy modules. After this the network can be used as usual.\n>>>\nclass\nLazyMLP\n(\ntorch\n.\nnn\n.\nModule\n):\n...\ndef\n__init__\n(\nself\n)\n->\nNone\n:\n...\nsuper\n()\n.\n__init__\n()\n...\nself\n.\nfc1\n=\ntorch\n.\nnn\n.\nLazyLinear\n(\n10\n)\n...\nself\n.\nrelu1\n=\ntorch\n.\nnn\n.\nReLU\n()\n...\nself\n.\nfc2\n=\ntorch\n.\nnn\n.\nLazyLinear\n(\n1\n)\n...\nself\n.\nrelu2\n=\ntorch\n.\nnn\n.\nReLU\n()\n...\n...\ndef\nforward\n(\nself\n,\ninput\n):\n...\nx\n=\nself\n.\nrelu1\n(\nself\n.\nfc1\n(\ninput\n))\n...\ny\n=\nself\n.\nrelu2\n(\nself\n.\nfc2\n(\nx\n))\n...\nreturn\ny\n>>>\n# constructs a network with lazy modules\n>>>\nlazy_mlp\n=\nLazyMLP\n()\n>>>\n# transforms the network's device and dtype\n>>>\n# NOTE: these transforms can and should be applied after construction and before any 'dry runs'\n>>>\nlazy_mlp\n=\nlazy_mlp\n.\ncuda\n()\n.\ndouble\n()\n>>>\nlazy_mlp\nLazyMLP( (fc1): LazyLinear(in_features=0, out_features=10, bias=True)\n(relu1): ReLU()\n(fc2): LazyLinear(in_features=0, out_features=1, bias=True)\n(relu2): ReLU()\n)\n>>>\n# performs a dry run to initialize the network's lazy modules\n>>>\nlazy_mlp\n(\ntorch\n.\nones\n(\n10\n,\n10\n)\n.\ncuda\n())\n>>>\n# after initialization, LazyLinear modules become regular Linear modules\n>>>\nlazy_mlp\nLazyMLP(\n(fc1): Linear(in_features=10, out_features=10, bias=True)\n(relu1): ReLU()\n(fc2): Linear(in_features=10, out_features=1, bias=True)\n(relu2): ReLU()\n)\n>>>\n# attaches an optimizer, since parameters can now be used as usual\n>>>\noptim\n=\ntorch\n.\noptim\n.\nSGD\n(\nmlp\n.\nparameters\n(),\nlr\n=\n0.01\n)\nA final caveat when using lazy modules is that the order of initialization of a network’s\nparameters may change, since the lazy modules are always initialized after other modules.\nFor example, if the LazyMLP class defined above had a\ntorch.nn.LazyLinear\nmodule\nfirst and then a regular\ntorch.nn.Linear\nsecond, the second module would be\ninitialized on construction and the first module would be initialized during the first dry run.\nThis can cause the parameters of a network using lazy modules to be initialized differently\nthan the parameters of a network without lazy modules as the order of parameter initializations,\nwhich often depends on a stateful random number generator, is different.\nCheck\nReproducibility\nfor more details.\nLazy modules can be serialized with a state dict like other modules. For example:\n>>>\nlazy_mlp\n=\nLazyMLP\n()\n>>>\n# The state dict shows the uninitialized parameters\n>>>\nlazy_mlp\n.\nstate_dict\n()\nOrderedDict([('fc1.weight', Uninitialized parameter),\n('fc1.bias',\ntensor([-1.8832e+25,  4.5636e-41, -1.8832e+25,  4.5636e-41, -6.1598e-30,\n4.5637e-41, -1.8788e+22,  4.5636e-41, -2.0042e-31,  4.5637e-41])),\n('fc2.weight', Uninitialized parameter),\n('fc2.bias', tensor([0.0019]))])\nLazy modules can load regular\ntorch.nn.Parameter\ns (i.e. you can serialize/deserialize\ninitialized LazyModules and they will remain initialized)\n>>>\nfull_mlp\n=\nLazyMLP\n()\n>>>\n# Dry run to initialize another module\n>>>\nfull_mlp\n.\nforward\n(\ntorch\n.\nones\n(\n10\n,\n1\n))\n>>>\n# Load an initialized state into a lazy module\n>>>\nlazy_mlp\n.\nload_state_dict\n(\nfull_mlp\n.\nstate_dict\n())\n>>>\n# The state dict now holds valid values\n>>>\nlazy_mlp\n.\nstate_dict\n()\nOrderedDict([('fc1.weight',\ntensor([[-0.3837],\n[ 0.0907],\n[ 0.6708],\n[-0.5223],\n[-0.9028],\n[ 0.2851],\n[-0.4537],\n[ 0.6813],\n[ 0.5766],\n[-0.8678]])),\n('fc1.bias',\ntensor([-1.8832e+25,  4.5636e-41, -1.8832e+25,  4.5636e-41, -6.1598e-30,\n4.5637e-41, -1.8788e+22,  4.5636e-41, -2.0042e-31,  4.5637e-41])),\n('fc2.weight',\ntensor([[ 0.1320,  0.2938,  0.0679,  0.2793,  0.1088, -0.1795, -0.2301,  0.2807,\n0.2479,  0.1091]])),\n('fc2.bias', tensor([0.0019]))])\nNote, however, that the loaded parameters will not be replaced when doing a “dry run” if they are initialized\nwhen the state is loaded. This prevents using initialized modules in different contexts.\nhas_uninitialized_params\n(\n)\n[source]\n[source]\n¶\nCheck if a module has parameters that are not initialized.\ninitialize_parameters\n(\n*\nargs\n,\n**\nkwargs\n)\n[source]\n[source]\n¶\nInitialize parameters according to the input batch properties.\nThis adds an interface to isolate parameter initialization from the\nforward pass when doing parameter shape inference.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#lazymodulemixin",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/lazy.html#LazyModuleMixin",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/lazy.py#L63",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear",
    "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear",
    "https://pytorch.org/docs/stable/notes/randomness.html",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/lazy.html#LazyModuleMixin.has_uninitialized_params",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/lazy.py#L250",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin.has_uninitialized_params",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/lazy.html#LazyModuleMixin.initialize_parameters",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/lazy.py#L240",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin.initialize_parameters",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.normalization.RMSNorm.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.Unflatten.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
},
{
  "title": "nn.modules.normalization.RMSNorm",
  "page_text": "RMSNorm\n¶\nclass\ntorch.nn.modules.normalization.\nRMSNorm\n(\nnormalized_shape\n,\neps\n=\nNone\n,\nelementwise_affine\n=\nTrue\n,\ndevice\n=\nNone\n,\ndtype\n=\nNone\n)\n[source]\n[source]\n¶\nApplies Root Mean Square Layer Normalization over a mini-batch of inputs.\nThis layer implements the operation as described in\nthe paper\nRoot Mean Square Layer Normalization\ny\ni\n=\nx\ni\nR\nM\nS\n(\nx\n)\n∗\nγ\ni\n,\nwhere\nRMS\n(\nx\n)\n=\nϵ\n+\n1\nn\n∑\ni\n=\n1\nn\nx\ni\n2\ny_i = \\frac{x_i}{\\mathrm{RMS}(x)} * \\gamma_i, \\quad\n\\text{where} \\quad \\text{RMS}(x) = \\sqrt{\\epsilon + \\frac{1}{n} \\sum_{i=1}^{n} x_i^2}\ny\ni\n​\n=\nRMS\n(\nx\n)\nx\ni\n​\n​\n∗\nγ\ni\n​\n,\nwhere\nRMS\n(\nx\n)\n=\nϵ\n+\nn\n1\n​\ni\n=\n1\n∑\nn\n​\nx\ni\n2\n​\n​\nThe RMS is taken over the last\nD\ndimensions, where\nD\nis the dimension of\nnormalized_shape\n. For example, if\nnormalized_shape\nis\n(3,\n5)\n(a 2-dimensional shape), the RMS is computed over\nthe last 2 dimensions of the input.\nParameters\nnormalized_shape\n(\nint\nor\nlist\nor\ntorch.Size\n) –\ninput shape from an expected input\nof size\n[\n∗\n×\nnormalized_shape\n[\n0\n]\n×\nnormalized_shape\n[\n1\n]\n×\n…\n×\nnormalized_shape\n[\n−\n1\n]\n]\n[* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n    \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n[\n∗\n×\nnormalized_shape\n[\n0\n]\n×\nnormalized_shape\n[\n1\n]\n×\n…\n×\nnormalized_shape\n[\n−\n1\n]]\nIf a single integer is used, it is treated as a singleton list, and this module will\nnormalize over the last dimension which is expected to be of that specific size.\neps\n(\nOptional\n[\nfloat\n]\n) – a value added to the denominator for numerical stability. Default:\ntorch.finfo(x.dtype).eps()\nelementwise_affine\n(\nbool\n) – a boolean value that when set to\nTrue\n, this module\nhas learnable per-element affine parameters initialized to ones (for weights). Default:\nTrue\n.\nShape:\nInput:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\nOutput:\n(\nN\n,\n∗\n)\n(N, *)\n(\nN\n,\n∗\n)\n(same shape as input)\nExamples:\n>>>\nrms_norm\n=\nnn\n.\nRMSNorm\n([\n2\n,\n3\n])\n>>>\ninput\n=\ntorch\n.\nrandn\n(\n2\n,\n2\n,\n3\n)\n>>>\nrms_norm\n(\ninput\n)\nextra_repr\n(\n)\n[source]\n[source]\n¶\nExtra information about the module.\nReturn type\nstr\nforward\n(\nx\n)\n[source]\n[source]\n¶\nRuns forward pass.\nReturn type\nTensor\nreset_parameters\n(\n)\n[source]\n[source]\n¶\nResets parameters based on their initialization used in __init__.\nNext\nPrevious\n© Copyright 2024, PyTorch Contributors.\nBuilt with\nSphinx\nusing a\ntheme\nprovided by\nRead the Docs\n.",
  "page_links": [
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.normalization.RMSNorm.html#rmsnorm",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#RMSNorm",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L321",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.normalization.RMSNorm.html#torch.nn.modules.normalization.RMSNorm",
    "https://arxiv.org/pdf/1910.07467.pdf",
    "https://docs.python.org/3/library/functions.html#int",
    "https://docs.python.org/3/library/stdtypes.html#list",
    "https://pytorch.org/docs/stable/size.html#torch.Size",
    "https://docs.python.org/3/library/typing.html#typing.Optional",
    "https://docs.python.org/3/library/functions.html#float",
    "https://docs.python.org/3/library/functions.html#bool",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#RMSNorm.extra_repr",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L403",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.normalization.RMSNorm.html#torch.nn.modules.normalization.RMSNorm.extra_repr",
    "https://docs.python.org/3/library/stdtypes.html#str",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#RMSNorm.forward",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L397",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.normalization.RMSNorm.html#torch.nn.modules.normalization.RMSNorm.forward",
    "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
    "https://pytorch.org/docs/stable/_modules/torch/nn/modules/normalization.html#RMSNorm.reset_parameters",
    "https://github.com/pytorch/pytorch/blob/v2.6.0/torch/nn/modules/normalization.py#L390",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.normalization.RMSNorm.html#torch.nn.modules.normalization.RMSNorm.reset_parameters",
    "https://pytorch.org/docs/stable/nn.functional.html",
    "https://pytorch.org/docs/stable/generated/torch.nn.modules.lazy.LazyModuleMixin.html",
    "http://sphinx-doc.org/",
    "https://github.com/rtfd/sphinx_rtd_theme",
    "https://readthedocs.org"
  ]
}
]
}